\documentclass[Crown, sagev]{sagej}

\usepackage{amssymb, amsmath, amsfonts}
\usepackage[list=off]{caption} % list=off option prevents errors when using math environments within captions


\include{GrandMacros}
\newcommand{\cdf}{{c.d.f.} }
\newcommand{\pdf}{{p.d.f.} }
\newcommand{\ind}{\mathbb{I}}

\begin{document}

\title{Infectious disease prediction with kernel conditional density
estimation}

\author{Evan L. Ray\affilnum{1},
Krzysztof Sakrejda\affilnum{1},
Stephen A. Lauer\affilnum{1} and
%Michael Johansen\affilnum{2} and
Nicholas G. Reich\affilnum{1}}

\affiliation{\affilnum{1}Department of Biostatistics and Epidemiology,
University of Massachusetts, Amherst}%\\
%\affilnum{2}CDC, Puerto Rico}

\corrauth{Evan Ray, UMass Address Here}

\email{elray@umass.edu}

\begin{abstract}
We develop a novel approach to prediction of infectious disease incidence using
Kernel Conditional Density Estimation (KCDE).  This method obtains predictive
distributions for incidence in individual weeks and uses copulas to tie those
distributions together into joint distributions in order to make
predictions for the timing of and incidence in the peak week of the season.
Our implementation of KCDE incorporates two novel kernel components: a periodic
component that captures seasonality in disease incidence, and a component that
is appropriate for use with discrete variables but also allows for a full
parameterization of the bandwidth matrix.  A simulation study
demonstrates that allowing for a fully parameterized bandwidth matrix can
improve conditional density estimates.  In applications to predicting dengue
fever and influenza, our method outperforms a baseline seasonal
autoregressive integrated moving average (SARIMA) model for predictions of
dengue incidence in individual weeks, and is comparable to the SARIMA model
on the other prediction targets.  The periodic kernel function leads to improved
predictions of incidence in both applications.  Our approach and extensions of
it could yield improved predictions for public health decision makers,
particularly in diseases with heterogeneous seasonal dynamics such as dengue
fever.
\end{abstract}
\keywords{copula, dengue fever, infectious disease, influenza, kernel
conditional density estimation, prediction}

\maketitle

<<knitrGlobalSetup, echo = FALSE>>=
library(cdcfluview)

library(stringr)

library(reshape2)
library(plyr)
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(lubridate))

library(ggplot2)
library(grid)

library(forecast)
library(kcde)
suppressMessages(suppressWarnings(library(pdtmvn)))

opts_chunk$set(cache = TRUE)
#opts_chunk$set(cache = TRUE, autodep = TRUE)
#opts_chunk$set(cache = FALSE)
@

<<LoadFluData, echo = FALSE>>=
junk <- capture.output({
    usflu <- suppressMessages(get_flu_data("national", "ilinet", years=1997:2015))
})
ili_national <- suppressWarnings(transmute(usflu,
    region.type = REGION.TYPE,
    region = REGION,
    year = YEAR,
    week = WEEK,
    weighted_ili = as.numeric(X..WEIGHTED.ILI)))
ili_national$time <- ymd(paste(ili_national$year, "01", "01", sep = "-"))
week(ili_national$time) <- ili_national$week
ili_national$time_index <- seq_len(nrow(ili_national))

## Season column: for example, weeks of 2010 up through and including week 30 get season 2009/2010;
## weeks after week 30 get season 2010/2011
ili_national$season <- ifelse(
    ili_national$week <= 30,
    paste0(ili_national$year - 1, "/", ili_national$year),
    paste0(ili_national$year, "/", ili_national$year + 1)
)

## Season week column: week number within season
ili_national$season_week <- sapply(seq_len(nrow(ili_national)), function(row_ind) {
        sum(ili_national$season == ili_national$season[row_ind] &
                ili_national$time_index <= ili_national$time_index[row_ind])
    })


## Subset to data actually used in this analysis -- up through end of 2014.
ili_national <- ili_national[ili_national$year <= 2014, , drop = FALSE]

## cutoff time for training data
ili_train_cutoff_time <- ili_national$time[max(which(ili_national$year == 2010))]
@

<<LoadDengueData, echo = FALSE>>=
dengue_sj <- read.csv("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/data-raw/San_Juan_Testing_Data.csv")

## convert dates
dengue_sj$time <- ymd(dengue_sj$week_start_date)

## cutoff time for training data
dengue_train_cutoff_time <- dengue_sj$time[max(which(dengue_sj$season == "2008/2009"))]
@


\section{Introduction}
\label{sec:Intro}

Accurate prediction of infectious disease incidence is important for public
health officials planning disease prevention and control measures such as vector
control and increased use of personal protective equipment by medical
personnel during periods of high disease incidence
\cite{wallinga2010optimizingIDInterventions,
hatchett2007interventionsIntensity1918flu}.
Several quantities have emerged as being of particular utility in making these
planning decisions; in this article we focus
on measures of weekly incidence, the timing of the season peak, and incidence
in the peak week\cite{PandemicPredictionandForecastingScienceandTechnologyInteragencyWorkingGroup2015Announcement,
EpidemicPredictionInitiative2015Index}.  Predictive distributions for these quantities are preferred
to point predictions because they communicate uncertainty in the predictions and
give decision makers more information in cases where the predictive distribution
is skewed or has multiple modes.

In this work, we employ a non-parametric approach referred to as kernel
conditional density estimation (KCDE) to obtain separate predictive
distributions for disease incidence in each week of the season.  We then
combine those marginal distributions using copulas to obtain joint predictive distributions for the
trajectory of incidence over the course of multiple weeks.  Predictive
distributions relating to the timing of and incidence at the peak week can be
obtained from this joint predictive distribution for the trajectory of
disease incidence.
In addition to the novel application of these methods to predicting disease incidence,
our contributions include the use of a periodic kernel specification to capture
seasonality in disease incidence and a method for obtaining multivariate
kernel functions that handle discrete data while allowing for a fully
parameterized bandwidth matrix.

%\lboxit{Keep only one of the following two paragraphs.
%The second is what I wrote initially, the first incorporates some revisions
%suggested by Nick.}

At its heart, KCDE is a local method in the sense that the conditional density
estimate for future incidence given conditioning variables is a weighted
combination of contributions from previous observations of incidence with
similar conditioning values.  Using such local methods is a natural idea in predicting
nonlinear dynamical systems.  For example, in the infectious disease literature
nearest neighbors regression has been used to make point predictions for incidence of
measles \cite{sugihara1990nonlinearForecasting} and
influenza\cite{viboud2003predictionInfluenzaMoA}.  The point prediction obtained from nearest neighbors
regression is equal to the expected value of the predictive distribution
obtained from KCDE if a particular kernel function is used in the formulation of
KCDE\cite{HastieTibshiraniESL}.  However, KCDE offers the advantage of providing
a complete predictive distribution rather than only a point prediction.  KCDE has not previously been applied to obtain predictive distributions for
infectious disease incidence, but it has been successfully used for prediction
in other settings such as survival time of lung cancer patients\cite{hall2004crossvalidationKCDE}, female labor force
participation\cite{hall2004crossvalidationKCDE}, bond yields and value at risk
in financial markets\cite{fan2004crossvalidationKCDE}, and wind
power\cite{jeon2012KCDEWindPower} among others.  Methods
similar to those we explore in this article can also be formulated in the
Bayesian framework.  One example along these lines is Zhou et
{al.}\cite{zhou2015DirichletProcessCopulaAmphibianDiseaseArrival}, who model the
time to arrival of a disease in amphibian populations using Dirichlet
processes and copulas.

%KCDE has not previously been applied to obtain predictive distributions for
%infectious disease incidence, but it has been successfully used for prediction
%in other settings such as survival time of lung cancer patients\cite{hall2004crossvalidationKCDE}, female labor force
%participation\cite{hall2004crossvalidationKCDE}, bond yields and value at risk
%in financial markets\cite{fan2004crossvalidationKCDE}, and wind
%power\cite{jeon2012KCDEWindPower} among others.  Although KCDE has not
%previously been applied to predicting infectious disease, closely related methods
%for obtaining point predictions have been employed for
%diseases such as measles\cite{sugihara1990nonlinearForecasting} and
%influenza\cite{viboud2003predictionInfluenzaMoA}.  In the infectious disease
%literature these methods have been referred to as state space reconstruction and
%the method of analogues, but they amount to applications of nearest neighbors
%regression.  The point prediction obtained from nearest neighbors
%regression is equal to the expected value of the predictive distribution
%obtained from KCDE if a particular kernel function is used in the formulation of
%KCDE\cite{HastieTibshiraniESL}.  However, KCDE offers the advantage of providing
%a complete predictive distribution rather than only a point prediction.  Methods
%similar to those we explore in this article can also be formulated in the
%Bayesian framework.  One example along these lines is Zhou et
%{al.}\cite{zhou2015DirichletProcessCopulaAmphibianDiseaseArrival}, who model the
%time to arrival of a disease in amphibian populations using Dirichlet
%processes and copulas.

%There is an extensive literature on KCDE, focusing mainly on estimation of
%continuous conditional densities.  Here we offer a brief overview emphasizing
%the case with mixed continuous and discrete variables; Li and
%Racine\cite{li2007nonparametricEconometrics} offer a detailed discussion of this
%case.

%KCDE is a method for estimating the conditional distribution of
%a random vector $\bY$ given observations of another vector $\bX$.  

%As we will describe in more detail below, KCDE estimates the conditional
%density of a random vector $\bY$ given another vector
%$\bX$ as a weighted sum of contributions from previously observed pairs $(\bx_t,
%\by_t)$.  In our work,
%$\bY$ is a measure of disease incidence at some future date (the
%prediction target) and $\bX$ is a vector of predictive variables that we condition
%on in order to make our prediction.  In our example applications,
%$\bX$ includes observations of incidence over several recent time
%points and variables indicating the time of year at which we are
%making a prediction.  In general, it would be possible to include other
%predictive variables such as weather covariates.

%The observation weights and the scale of the
%contribution from each observation to the final density are determined by a
%kernel function.
%To our knowledge, ll previous authors using kernel methods to estimate multivariate
To our knowledge, previous implementations of kernel methods for estimating
multivariate densities involving discrete variables have employed a kernel
function that is a product of univariate kernel functions
\cite{aitchison1976multivariateBinaryKernel, wang1981SmoothEstDiscreteDistn,
li2003nonparametricEstDistnsCategoricalContinuous,
ouyang2006crossvalidationEstDistnCategorical}.
Using a product kernel simplifies the mathemetical formulation of the kernel
function when discrete variables are present, but has the effect of forcing the
kernel function to be orientied in line with the coordinate axes.  In settings
with only continuous variables, asymptotic
analysis and experience with applications have shown that using a multivariate
kernel function with a bandwidth parameterization that allows for
other orientations can result in improved density estimates
in many cases (cite ***).  We introduce an approach to allowing for discrete
kernels with orientation by discretizing an underlying continuous kernel
function.

\lboxit{add remaining citations for first sentence in above paragraph}

%A variety of functional forms have been proposed for this purpose, including
%geometric, triangular and Poisson among others
%\cite{aitchison1976multivariateBinaryKernel, wang1981SmoothEstDiscreteDistn, li2008nonparametricConditionalCDFQuantile, li2003nonparametricEstDistnsCategoricalContinuous,
%ouyang2006crossvalidationEstDistnCategorical}.

%\cite{wang1981SmoothEstDiscreteDistn},
%\cite{li2008nonparametricConditionalCDFQuantile}\cite{li2003nonparametricEstDistnsCategoricalContinuous},
% \cite{ouyang2006crossvalidationEstDistnCategorical}].

%One possibility for introducing orientation
%to the kernel function is to use a fully parameterized
%bandwidth matrix, allowing the kernel to be oriented in any direction.  Another
%common alternative is to fix the orientation to be in the directions of the
%eigenvectors of the sample covariance matrix.

%Estimation.  Two main strategies:  cross validation and rule-based.  Targets
% for optimization in cross-validation.  For
%estimating joint densities without
%conditioning, \cite{hart1990bandwidthEstDependentData} have shown that with
%dependent data, but small gains in the mean integrated square error of the
%density estimate relative to the true conditional density can be achieved by
%leaving out observations adjacent to the time point whose density is being
%estimated.

A limitation of kernel-based density estimation methods is that their
performance may not scale well with the dimension of the vector whose
distribution is being estimated (cite cite).  This is particularly relevant in
our application, where it is desired to obtain joint predictive distributions for
disease incidence over the course of many weeks.  Copulas present one strategy
for estimating the joint distribution of moderate to high dimensional random
vectors, and work by specifying a relatively simple parametric model for the
dependence relations among those variables.  This simple dependence model
ties separate marginal distribution estimates together into a joint
distribution.  In our case, we obtain those marginal distribution estimates
through KCDE.

\lboxit{Add 1 sentence with citations for how copulas have been used
in similar settings/ways before.}

%Specifically, we model the joint distribution of $Y_1,
%\ldots, Y_D$ by $F_{Y_1, \ldots, Y_D}(y_1, \ldots, y_D) = C(F_{Y_1}(y_1),
%\ldots, F_{Y_D}(y_D) ; \bxi)$.  Here $C: [0,1]^D \rightarrow [0,1]$ is
%the copula function depending on parameters $\bxi$ and mapping the vector
%of marginal {c.d.f.} values to the joint {c.d.f.} value.

%It would be possible to handle
%this task using just the formulation of KCDE we discussed above, but a
%direct application of this approach has some limitations.  First, the
%performance of kernel-based density estimation methods scales poorly with the
%dimension of the random vector whose density is being estimated (cite ***). 
%Second, we have found that different information is available in the data at
%different prediction horizons.  For example, we will demonstrate in our
%applications below that recently observed incidence is important for
%making short-term predictions, but terms capturing seasonality are more
%important for making long-term predictions.

%We make several contributions in this article.  First, we apply KCDE to
%prediction of infectious disease (specifically, Dengue fever and Influenza), a
%novel application of the method which gives rise to several challenges and
%opportunities.  Among these challenges is the fact that infectious disease
%incidence can be quite noisy, with a lot of variation around a longer term
%trend; we will illustrate this in two real data sets in Section ***.  As we will
%see, this noise can cause difficulty for the method when applied to prediction
%of future incidence directly from recent observations of incidence.  Our
%solution is to introduce an initial low-pass filtering step on the observed
%incidence counts that are used as inputs to the predictions.

%Another challenge is in capturing seasonality in disease incidence.  In order
%to address this, we consider the use of periodic functions of the observation
%time as conditioning variables.  Effectively, this means that we can base our
%predictive density on previous observations that have been recorded at the time
%of year we are interested in.

%A third challenge is that for some applications, observations of disease
%incidence may take the form of discrete counts (i.e., the number of new cases
%in the last week).  If these incidence counts span a large range, it may be
%reasonable to approximate their predictive distribution with a continuous
%density function.  However, in our data for Dengue fever, the number of cases
%often falls within a limited range so that this continuous approximation is not
%reasonable.  We address this by discretizing an underlying continuous density
%function.  To our knowledge, this approach is novel in the KCDE literature.

The remainder of this article is organized as follows.  First, we describe our
approach to prediction using KCDE and copulas.  Next, we present the
results of a simulation study comparing the performance of KCDE for
estimating discrete distributions using a fully parameterized bandwidth
matrix and a diagonal bandwidth matrix.  We then illustrate our methods by applying them to predicting
disease incidence in two data sets: one with a measure of weekly incidence of
influenza in the United States and a second with a measure of weekly incidence
of dengue fever in San Juan, Puerto Rico.  We conclude with a discussion of
these results.

\section{Method Description}
\label{sec:Methods}

Suppose we observe a measure $z_t$ of disease incidence at evenly spaced times
indexed by $t = 1, \ldots, T$.  Our goal is to obtain predictions relating to
incidence after time $T$.  We allow the incidence measure to be either
continuous or discrete and use the term density to refer to the Radon-Nikodym
derivative of a (conditional) probability measure with respect to an
appropriately defined reference measure.  We will use a colon notation to
specify vectors: for example, $\bz_{s:t} = (z_s, \ldots, z_t)$.  The
variable $t^* \in \{1, \ldots, T\}$ will be used to represent a time at which we
desire to form a predictive distribution, using observed data up through $t^*$
to predict incidence after $t^*$.  When we apply the method to
perform prediction for incidence after time $T$, $t^*$ is equal to $T$; however, $t^*$
takes other values in the estimation procedure we describe below.  Let $W$ denote the number of time
points in a disease season (typically $W = 52$ if we have weekly data).
For each time $t^*$, let $S_{t^*}$ denote the time index of the last time
point in the \textit{previous} season, so that the times in the same season
as $t^*$ are indexed by $S_{t^*} + 1, \ldots, S_{t^*} + W$.
Finally, let $H_{t^*} = W - (t^* - S_{t^*})$ denote the number of time points
after $t^*$ that are in the same season as $t^*$.  $H_{t^*}$ gives the largest
prediction horizon for which we need to make a prediction in order to obtain
predictions for all remaining time points in the season.

We obtain predictive distributions for each of three prediction targets.
We will model the first of these prediction targets directly and frame the
second and third as suitable integrals of a predictive
distribution $f(\bz_{({t^*} + 1):({t^*} + H_{t^*})} | {t^*}, \bz_{1:{t^*}})$ for the trajectory of incidence over all remaining weeks in the season:
\begin{enumerate}
  \item Incidence in a single future week with prediction horizon $h \in \{1, ..., W\}$:
    \begin{align}
    &f(z_{{t^*} + h} | {t^*}, \bz_{1:{t^*}}) \nonumber
    \end{align} %    &\qquad = \int \cdots \int f(\bz_{(T + 1):(T + H_T)} | T, \bz_{1:T}) \, d z_{T + 1} \cdots d z_{T + h - 1} \, d z_{T + h + 1} \cdots d z_{T + H_T}
  \item Timing of the peak week of the current season, $w^* \in \{1, \ldots, W\}$:
    \begin{align}
    &P(\text{Peak Week} = w^*) = P(Z_{S_{t^*} + w^*} = \max_{w} Z_{S_{t^*} + w} | {t^*}, \bz_{1:{t^*}}) \nonumber \\
    &\qquad = \int_{\{\bz_{({t^*} + 1):({t^*} + H_{t^*})}: z_{S_{t^*} + w^*} = \max_{w} z_{S_{t^*} + w} \}} f(\bz_{({t^*} + 1):({t^*} + H_{t^*})} | {t^*}, \bz_{1:{t^*}}) \, d \bz_{({t^*} + 1):({t^*} + H_{t^*})}. \label{eqn:PeakPredTimingIntegral}
    \end{align}
  \item Binned incidence in the peak week of the current season:
    \begin{align}
    &P(\text{Incidence in Peak Week} \in [a, b]) = P(a \leq \max_{w} Z_{S_{t^*} + w} \leq b | {t^*}, \bz_{1:{t^*}}) \nonumber \\
    &\qquad = \int_{\{(\bz_{({t^*} + 1):({t^*} + H_{t^*})}): a \leq \max_{w} z_{S_{t^*} + w} \leq b\}} f(\bz_{({t^*} + 1):({t^*} + H_{t^*})} | {t^*}, \bz_{1:{t^*}}) \, d \bz_{({t^*} + 1):({t^*} + H_{t^*})}. \label{eqn:PeakPredIncidenceIntegral}
    \end{align}
\end{enumerate}
In practice, we use Monte Carlo integration to evaluate
the integrals in Equations \eqref{eqn:PeakPredTimingIntegral} and
\eqref{eqn:PeakPredIncidenceIntegral} by sampling incidence trajectories from
the joint predictive distribution.

We will introduce the overall structure of our model here and describe its
components in more detail in the following subsections.  At time $t^*$, our
model approximates $f(\bz_{(t^* + 1):(t^* + H_{t^*})} | t^*, \bz_{1:t^*})$
by conditioning only on the time at which we are making the predictions and
observed incidence at a few recent time points with lags given by the non-negative integers $l_1, \ldots, l_M$:
$f(\bz_{(t^* + 1):(t^* + H_{t^*})} | t^*, z_{t^* - l_1}, \ldots, z_{t^* -
l_M})$.  For notational simplicity, we take $l_M$ to be the largest of these
lags.  The model represents this density as follows:
\begin{align}
&f(z_{(t^* + 1):(t^* + H_{t^*})} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}) = \nonumber \\
&\qquad c^{H_{t^*}}\{f^{1}(z_{t^* + 1} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^1), \ldots, f^{H_{t^*}}(z_{t^* + H_{t^*}} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^H) ; \bxi^{H_{t^*}}\}. \label{eqn:ModelKCDECopula}
\end{align}
%In Equation~\eqref{eqn:ModelKCDECopula}, each
Here, each $f^{h}(z_{t^* + h} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M};
\btheta^h)$ is a predictive density for one prediction horizon obtained through KCDE.  The
distribution for each prediction horizon depends on a separate parameter vector $\btheta^h$.
The function $c^{H_{t^*}}(\cdot)$ is a copula
used to tie these marginal predictive densities together into a joint predictive
density, and depends on parameters $\bxi^{H_{t^*}}$.  In our
applications, we will obtain a separate copula fit for each trajectory length
$H_{t^*}$ of interest for the prediction task.

%Second, we discuss the use of a copula to tie
%these predictive distributions for individual prediction horizons into a joint
%distribution over the full range of horizons from 1 to $H$.  In order to handle
%both continuous and discrete random variables cleanly, we frame this discussion
%in terms of cumulative distribution functions.

%It would also be possible to
%condition on other covariates such as weather, but we have not pursued that line in this work.


%Throughout, we
%use the term density to refer to the Radon-Nikodym derivative of the
%cumulative distribution function with respect to an appropriately defined measure.
%In the case of random vectors where some
%components are continuous random variables and other are discrete, we take this
%measure to be a product of Lebesgue and counting measures for the corresponding
%random variables.  We use bold letters to indicate column vectors or matrices;
%capital letters are random variables and lower case letters are observations of those
%random variables.


%We estimate this joint predictive density in two stages.  First, we
%use KCDE to obtain separate predictive distributions for each prediction
%horizon $h = 1, \ldots, H$: $f(z_{T + h} | z_{1}, \ldots, z_{T}, T)$.  Next, we
%use a copula to combine these 



Broadly, estimation for the model parameters proceeds in two stages:
first we estimate the parameters for KCDE separately for each prediction
horizon $h = 1, \ldots, H_{t^*}$, and second we estimate the copula parameters while holding the KCDE
parameters fixed.  In general the two-stage approach may result in some loss
of efficiency relative to one-stage methods, but this efficiency loss is small
for some model specifications\cite{joe2005asymptoticEfficiencyTwoStageCopula}.
We pursue the two-stage strategy in this work because it results in a large
reduction in the computational cost of parameter estimation.

The estimation methods were implemented in {\tt R}\cite{RCoreLanguage} and {\tt C}.  All
source code as well as the data we used in the applications below are available
in {\tt R} packages hosted on
GitHub\cite{ReichLabGitHubDiseasePredWithKCDEPackage}.

\lboxit{Permission to put data in our package?  Also, current code just uses
the flu data package in R to pull in data.  Maybe I should get a
stable/permanent copy to put in the package?}

In the following subsections we describe the formulations of KCDE and
the copula in more detail and give our estimation strategy for each set of
model parameters.

\subsection{KCDE for Predictive Densities at Individual Prediction Horizons}
\label{subsec:Methods:KCDE}

We now discuss the methods we use to obtain the predictive density
$f^{h}(z_{t^* + h} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^h)$
for disease incidence at a particular horizon $h$ after time $t^*$.  In order to
simplify the notation we define two new variables: $Y_t^{h} = Z_{t + h}$ represents
the prediction target relative to time $t$, and $\bX_t = (t, Z_{t -
l_1}, \ldots, Z_{t - l_M})$ represents the vector of predictive
variables relative to time $t$.  With this notation, the distribution we wish to estimate is
$f^{h}(y_{t^*}^{h} | \bx_{t^*}; \btheta^h)$.

In order to estimate this distribution, we use the observed data to form the
pairs $(\bx_t, y_t^{h})$ for all $t = 1 + l_M, \ldots, T - h$
(for smaller values of $t$ there are not enough observations before $t$ to form
$\bx_t$ and for larger values of t there are not enough observations after $t$ to form
$y_t^{h}$).  We then regard these pairs as a (dependent) sample from the joint
distribution of $(\bX, Y^h)$ and estimate the conditional distribution of $Y^h | \bX$ via KCDE:
\begin{align}
\widehat{f}^h(y^h_{t^*} | \bx_{t^*}) &= \frac{\sum_{t \in \btau} K^{\bX, Y}\left\{(\bx_{t^*}, y^h_{t^*}), (\bx_t, y^h_t); \btheta^h \right\}}{\sum_{t \in \btau}K^{\bX}(\bx_{t^*}, \bx_t ; \btheta^h)} \label{eqn:KCDEDefinition} \\
\qquad &= \sum_{t \in \btau} \zeta^h_{t^*, t} K^{Y | \bX}(y^h_{t^*}, y^h_t | \bx_{t^*}, \bx_t; \btheta^h) \text{, where} \label{eqn:KDEwt} \\
\zeta^h_{t^*, t} &= \frac{ K^{\bX}(\bx_{t^*}, \bx_t; \btheta^h) }{\sum_{s \in \btau} K^{\bX}(\bx_{t^*}, \bx_{s}; \btheta^h) }. \label{eqn:KCDEWeightsDef}
\end{align}

%&\qquad = \frac{\sum_{t \in \btau} K^{Y | \bX}(y^h_{t^*}, y^h_t | \bx_{t^*},
% \bx_t; \btheta^h) K^{\bX}(\bx_{t^*}, \bx_t; \btheta^h)}{\sum_{t \in \btau} K^{\bX}(\bx_{t^*}, \bx_t; \btheta^h) } \label{eqn:KDESubKDEJtMarginal} \\

Here we are working with a slightly restricted specification in which
the kernel function $K^{\bX, Y}$ can be written as the product of $K^{\bX}$ and $K^{\bY|\bX}$.
With this restriction, we can
interpret $K^{\bX}$ as a weighting function determining how much each observation
$(\bx_t, y^h_t)$ contributes to our final density estimate according to how
similar $\bx_t$ is to the value $\bx_{t^*}$ that we are conditioning on.
For each $y^h_t$, $K^{\bY | \bX}$ is a density function that contributes
mass to the final density estimate near $y^h_t$.  The
parameters $\btheta^h$ control the locality and orientation of the weighting
function and the contributions to the density estimate from each observation.
In Equations \eqref{eqn:KCDEDefinition} through \eqref{eqn:KCDEWeightsDef},
$\btau \subseteq \{(1 + l_M), \ldots, (T - h)\}$ indexes the subset of
observations used in obtaining the conditional density estimate; we return to
how this subset of observations is defined in the discussion of estimation
below.
%In practice, we have parameterized these matrices in terms of the Cholesky
% decomposition.
%; we further take the bandwidth matrix $\bB^X$ to be a sub-matrix of $\bB^{Y,X}$
%  Hall, Racine,
%and Li \cite{hall2004crossvalidationKCDE} say that this "does not adversely affect
%the rate of convergence of estimators..."

We take the kernel function $K^{Y, \bX}$ to be a product kernel with one
component being a periodic kernel in time and the other component capturing the
remaining covariates, which are measures of disease incidence:
\begin{align}
&K^{\bX, Y}\left\{(\bx_{t^*}, y^h_{t^*}), (\bx_t, y^h_t); \btheta^h \right\} \nonumber \\
&\qquad = K^{\text{per}}(t^*, t; \btheta^h_{\text{per}}) K^{\text{inc}}\{(z_{t^* - l_1}, \ldots, z_{t^* - l_M}, z_{t^* + h}), (z_{t - l_1}, \ldots, z_{t - l_M}, z_{t + h}); \btheta^h_{\text{inc}}\}. \nonumber
\end{align}
Here we have set $\btheta^h = (\btheta^h_{\text{per}}, \btheta^h_{\text{inc}})$.
%&\qquad = K^{\bX, Y}\left\{(t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}, z_{t^* +
% h}), (t, z_{t - l_1}, \ldots, z_{t - l_M}, z_{t + h}); \btheta^h \right\} \nonumber \\

The periodic kernel function was originally developed in the
literature on Gaussian Processes\cite{mackay1998introductionGP}, and is defined by
\begin{equation}
K^{\text{per}}(t^*, t; \rho^h, \eta^h) = \exp\left[- \frac{\sin^2\{\rho^h (t^* - t)\}}{2(\eta^h)^2} \right]. \label{eqn:PeriodicKernel}
\end{equation}
We illustrate this kernel function in Figure \ref{fig:PeriodicKernelPlot}. 
It has two parameters: $\btheta^h_{\text{per}} = (\rho^h, \eta^h)$, where $\rho^h$ determines the length of the
periodicity and $\eta^h$ determines the strength and locality
of this periodic component in computing the observation weights $\zeta_{t^*, t}^h$.
In our applications, we have fixed $\rho^h = \pi / 52$, so that the kernel has
period of length 1 year with weekly data.  Using this periodic kernel provides a
mechanism to capture seasonality in disease incidence by allowing the
observation weights to depend on the similarity of the time of year that an
observation was collected and the time of year at which we are making a prediction.

%  In the final density estimate, $\btau$ typically includes all
%available time points, but proper subsets are used in the cross-validation
%procedures we discuss later for parameter estimation.

%In order to do this, we employ kernel density estimation.  Let $K^{\bY}(\by, \by^*,
%H^{\bY})$ and $K^{\bX}(\bx, \bx^*, H^{\bX})$ be kernel functions centered at
%$\by^*$ and $\bx^*$ respectively and with bandwidth matrices $H^{\bY}$ and
%$H^{\bX}$.  We estimate the conditional distribution of $\bY | \bX$ as follows:
%\begin{align}
%&\widehat{f}_{\bY|\bX}(\by | \bX = \bx) = \frac{\widehat{f}_{\bY, \bX}(\by, \bx)}{\widehat{f}_{\bX}(\bx)} \label{eqn:KDECondDef} \\
%&\qquad = \frac{\sum_{t \in \tau} K^{\bY, \bX}\{(\by, \bx), (\by_t, \bx_t), H^{\bY, \bX}\}}{\sum_{t \in \tau} K^{\bX}(\bx, \bx_t, H^{\bX}) } \label{eqn:KDESubKDEJtMarginal} \\
%&\qquad = \frac{\sum_{t \in \tau} K^{\bY | \bX}(\by, \by_t | \bx, \bx_t, H^{\bY, \bX}) K^{\bX}(\bx, \bx_t, H^{\bX})}{\sum_{t \in \tau} K^{\bX}(\bx, \bx_t, H^{\bX}) } \label{eqn:KDESubKDEJtMarginal} \\
%&\qquad = \sum_{t \in \tau} w_t K^{\bY | \bX}(\by, \by_t | \bx, \bx_t, H^{\bY, \bX}) \text{, where} \label{eqn:KDEwt} \\
%&w_t = \frac{ K^{\bX}(\bx, \bx_t, H^{\bX}) }{\sum_{t^* \in \tau} K^{\bX}(\bx, \bx_{t^*}, H^{\bX}) } \label{eqn:KDEWeightsDef}
%\end{align}

%In Equation~\eqref{eqn:KDECondDef}, we are making use of the fact that the
% conditional density for $\bY | \bX$ can be written as the quotient of the joint density for $(\bY, \bX)$ and the marginal density for $\bX$.  In Equation~\eqref{eqn:KDESubKDEJtMarginal}, we obtain separate kernel density estimates for the joint and marginal densities in this quotient.  In Equation~\eqref{eqn:KDEwt}, we rewrite this quotient by passing the denominator of Equation~\eqref{eqn:KDESubKDEJtMarginal} into the summation in the numerator.  We can interpret the result as a weighted kernel density estimate, where each observation $t \in \tau$ contributes a different amount to the final conditional density estimate.  The amount of the contribution from observation $t$ is given by the weight $w_t$, which effectively measures how similar $\bx_t$ is to the point $\bx$ at which we are estimating the conditional density.  If $\bx_t^{(\bl^{max})}$ is similar to $\bx_{t^*}^{(\bl^{max})}$, a large weight is assigned to $t$; if $\bx_t^{(\bl^{max})}$ is different from $\bx_{t^*}^{(\bl^{max})}$, a small weight is assigned to $t$.

%In kernel density estimation, it is generally required that the kernel
% functions integrate to $1$ in order to obtain valid density estimates.  However, after conditioning on $\bX$, it is no longer necessary that $K^{\bX}(\bx, \bx_t, H^{\bX})$ integrate to $1$.  In fact, as can be seen from Equation~\eqref{eqn:KDEWeightsDef}, any multiplicative constants of proportionality will cancel out when we form the observation weights.  We can therefore regard $K^{\bX}(\bx, \bx_t, H^{\bX})$ as a more general weighting function that measures the similarity between $\bx$ and $\bx_t$.  As we will see, eliminating the constraint that $K^{\bX}$ integrates to $1$ is a useful expansion the space of functions that can be used in calculating the observation weights.  However, we still require that $K^{\bY}$ integrates to $1$.

%In Equations \eqref{eqn:KDECondDef} through \eqref{eqn:KDEWeightsDef}, $\tau$
% is an index set of time points used in obtaining the density estimate.  In most settings, we can take $\tau = \{1 + P + L, \ldots, T\}$.  These are the time points for which we can form the lagged observation vector $\bx_t$ and the prediction target vector $\by_t$.  However, we will place additional restrictions on the time points included in $\tau$ in the cross-validation procedure discussed in Section \ref{sec:Estimation}.

%In Equation~\eqref{eqn:KCDEDefinition}, if both $K^{\bX, \bY}$ and $K^{\bX}$
%integrate to 1 with respect to $\bx$ and $y$ then the numerator is a kernel
%density estimate of the joint density of $\bX$ and $\bY$ and the denominator
%is a kernel density estimate of the marginal density of $\bX$; forming the quotient yields an
%estimate of the conditional density of $\bY | \bX$.  However, it is not strictly
%required that 

%\begin{equation}
%K^{\bX,\bY}\left\{(\bx', \by')', (\bx'_t, \by'_t)'; \bH^{\bX,\bY}\right\} = K^{\bX}\left\{\bx, \bx_t; \bH^{\bX}\right\} K^{\bY | \bX}\left\{\by, \by_t | \bx, \bx_t; \bH^{\bX,\bY}\right\}.
%\end{equation}



%With this restriction, we can rearrange Equation~\eqref{eqn:KCDEDefinition} to
%obtain
%\begin{align}
%\widehat{f}_{\bY|\bX}(\by | \bx) &= \sum_{t \in \btau} w_t K^{\bY | \bX}\left\{\by, \by_t | \bx, \bx_t; \bH^{\bX,\bY}\right\}, \text{ where} \label{eqn:KCDEDefinitionWeighted} \\
%w_t &= \frac{K^{\bX}\left\{\bx, \bx_t; \bH^{\bX}\right\}}{\sum_{t^* \in \btau} K^{\bX}\left\{\bx, \bx_{t^*}; \bH^{\bX}\right\}}.
%\end{align}

%In order to complete the formulation of the KCDE estimator, we must specify the
%kernel function.  We take this kernel to be a product of two components.  The
%first is a periodic kernel in the time at which we are making the prediction,
%and allows us to capture seasonality in disease incidence within the KCDE
%framework.  

\begin{figure}
\caption{The components of the kernel function.  The top panel shows the
periodic kernel function illustrated as a function of time in weeks with
$\rho = \pi / 52$ and three possible values for the bandwidth parameter
$\eta$.  The lower panel shows the log-normal kernel function in the bivariate
case.  The curves indicate contours of the continuous kernel function and the
points indicate the discrete kernel function, which is obtained by integrating
the continuous kernel function.  The kernel is centered at $(2.5, 2.5)$ and has
bandwidth matrix $\begin{bmatrix}0.2 & 0.15 \\ 0.15 & 0.2\end{bmatrix}$.}
\label{fig:PeriodicKernelPlot}
<<PeriodicKernelPlot, echo = FALSE, fig.height = 7.75>>=
plot_df <- data.frame(t=seq_len(5 * 52))

kernel_center <- plot_df$t[nrow(plot_df)]
rho <- pi / 52

h <- 0.1
plot_df$kernel_h0.1 <- exp( -0.5 * (sin(rho * (kernel_center - plot_df$t)) / h)^2)

h <- 1
plot_df$kernel_h1 <- exp( -0.5 * (sin(rho * (kernel_center - plot_df$t)) / h)^2)

h <- 10
plot_df$kernel_h10 <- exp( -0.5 * (sin(rho * (kernel_center - plot_df$t)) / h)^2)

plot_df <- melt(plot_df, id.vars = "t")
plot_df$variable <- as.character(plot_df$variable)
plot_df$bandwidth <- "0.1"
plot_df$bandwidth[plot_df$variable == "kernel_h1"] <- "1"
plot_df$bandwidth[plot_df$variable == "kernel_h10"] <- "10"

p_per <- ggplot(plot_df) +
    geom_line(aes(x = t, y = value, linetype = bandwidth, colour = bandwidth)) +
#    geom_vline(xintercept = kernel_center) +
    scale_colour_manual("Bandwidth",
        breaks = c("0.1", "1", "10"),
        labels = c("0.1", "1", "10"),
        values = c("#E69F00", "#56B4E9", "#009E73")
    ) +
    scale_linetype("Bandwidth") +
    scale_x_continuous(breaks = c(0, seq(from = 52, length = 5, by = 52))) +
    ylab("Kernel Function Value") +
    xlab("Time in Weeks") +
    ggtitle("Periodic Kernel Component for Time") +
    theme_bw(base_size = 11)


cont_grid_bounds <- c(0.01, 10)
cont_grid_size <- 101
x_cont_grid <- 
    expand.grid(
        seq(from = cont_grid_bounds[1], to = cont_grid_bounds[2], length = cont_grid_size),
        seq(from = cont_grid_bounds[1], to = cont_grid_bounds[2], length = cont_grid_size)
    ) %>%
    `colnames<-`(c("X1", "X2"))
disc_grid_bounds <- c(0.5, 9.5)
x_disc_grid <-
    expand.grid(
        seq(from = disc_grid_bounds[1], to = disc_grid_bounds[2], by = 1),
        seq(from = disc_grid_bounds[1], to = disc_grid_bounds[2], by = 1)
    ) %>%
    `colnames<-`(c("X1", "X2"))


#' Compute log(round(exp(x))) in such a way that the rounding function
#' always rounds up or down to an integer + 0.5, and
#' an integer always gets rounded up.
#' 
#' @param x numeric
#' 
#' @return floor(x) - 1
log_round_to_integer_plus_0.5_exp <- function(x) {
    exp_x <- exp(x) + 0.5
    
    inds_ceil <- exp_x - floor(exp_x) >= 0.5
    
    exp_x[inds_ceil] <- ceiling(exp_x[inds_ceil])
    exp_x[!inds_ceil] <- floor(exp_x[!inds_ceil])
    
    return(log(exp_x - 0.5))
}

var_b <- 0.2
covar_b <- 0.15


continuous_density_df_b <- x_cont_grid %>%
    as.data.frame() %>%
    `$<-`("z",
        log_pdtmvn_mode_centered_kernel(x = x_cont_grid,
            center = as.matrix(data.frame(X1 = 2.5, X2 = 2.5)),
            bw = matrix(c(var_b, covar_b, covar_b, var_b), nrow = 2, ncol = 2),
            bw_continuous = matrix(c(var_b, covar_b, covar_b, var_b), nrow = 2, ncol = 2),
            continuous_vars = c("X1", "X2"),
            discrete_vars = character(0),
            continuous_var_col_inds = 1:2,
            discrete_var_col_inds = integer(0),
            discrete_var_range_fns = NULL,
            lower = c(X1 = -Inf, X2 = -Inf),
#            lower = c(X1 = log(0.5), X2 = log(0.5)),
            upper = c(X1 = Inf, X2 = Inf),
            x_names = c("X1", "X2"),
            log = FALSE)
    )

#x_disc_grid <- data.frame(X1 = c(1, 3), X2 = c(1, 3))
#debug(pdtmvn::dpdtmvn)
discrete_density_df_b <- x_disc_grid %>%
    as.data.frame() %>%
    `$<-`("z",
#        sapply(seq_len(nrow(x_disc_grid)), function(x_grid_row_ind) {
        log_pdtmvn_mode_centered_kernel(x = x_disc_grid,
            center = as.matrix(data.frame(X1 = 2.5, X2 = 2.5)),
            bw = matrix(c(var_b, covar_b, covar_b, var_b), nrow = 2, ncol = 2),
            bw_continuous = matrix(0, nrow = 0, ncol = 0),
            continuous_vars = character(0),
            discrete_vars = c("X1", "X2"),
            continuous_var_col_inds = integer(0),
            discrete_var_col_inds = 1:2,
            discrete_var_range_fns = list(
                X1 = list(a = function(x) {
                        return(log(exp(x) - 0.5))
                    },
                    b = function(x) {
                        return(log(exp(x) + 0.5))
                    },
                    in_range = function(x, tolerance = .Machine$double.eps^0.5) {
                        return(sapply(x, function(x_i) {
                                    return(
                                        isTRUE(all.equal(
                                                x_i,
                                                log_round_to_integer_plus_0.5_exp(x_i),
                                                tolerance = tolerance
                                            ))
                                    )
                                }))
                    },
                    discretizer = log_round_to_integer_plus_0.5_exp),
                X2 = list(a = function(x) {
                        return(log(exp(x) - 0.5))
                    },
                    b = function(x) {
                        return(log(exp(x) + 0.5))
                    },
                    in_range = function(x, tolerance = .Machine$double.eps^0.5) {
                        return(sapply(x, function(x_i) {
                                    return(
                                        isTRUE(all.equal(
                                                x_i,
                                                log_round_to_integer_plus_0.5_exp(x_i),
                                                tolerance = tolerance
                                            ))
                                    )
                                }))
                    },
                    discretizer = log_round_to_integer_plus_0.5_exp)
            ),
#                    lower = c(X1 = log(0.5), X2 = log(0.5)),
            lower = c(X1 = -Inf, X2 = -Inf),
            upper = c(X1 = Inf, X2 = Inf),
            x_names = c("X1", "X2"),
            log = FALSE)
#            })
    )

p_inc <- ggplot() +
    geom_contour(aes(x = X1, y = X2, z = z, colour = ..level..), bins = 13, data = continuous_density_df_b) +
    geom_point(aes(x = X1, y = X2, colour = z), data = discrete_density_df_b) +
#    scale_colour_gradientn("Predictive\nDistribution\nProbability",
#        colours = rev(c("#333333", "#777777", "#BBBBBB", "#FFFFFF")),
    ##        colours = rev(c("#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
    ##        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
    ##        limits = c(10^{-10}, 1),
#        trans = "log",
    ##        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
    ##        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
    ##        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
#        values = c(0.0001, 0.001, 0.01, 0.1, 1),
    ##        values = c(-4, -3, -2, -1),
#        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
#        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
    ##        breaks = c(0.001, 0.01, 0.1, 1),
    ##        labels = c(expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
#        na.value = "white"
#    ) +
    scale_colour_gradientn("Kernel\nFunction   \nValue",
        colours = rev(c("#333333", "#777777", "#BBBBBB", "#FFFFFF")),
#        colours = rev(c("#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
#        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
#        limits = c(10^{-10}, 1),
        trans = "log",
#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
#        values = c(0.0001, 0.001, 0.01, 0.1, 1),
#        values = c(-4, -3, -2, -1),
        limits = c(0.00001, 0.2),
        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
#        breaks = c(0.001, 0.01, 0.1, 1),
#        labels = c(expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
        na.value = "white"
    ) +
    #    geom_point(aes(x = exp(log(3) - var_b - covar_b), y = exp(log(3) - var_b - covar_b)), colour = "red") +
    xlab(expression(X[1])) +
    ylab(expression(X[2])) +
    ggtitle("Log-Normal Kernel Component for Incidence") +
    theme_bw(base_size = 11)
#+
#    theme(legend.position = "none")

grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 1,
            heights = unit(c(1, 3.3), c("null", "null")),
            widths = unit(c(1), c("null")))))
#pushViewport(viewport(layout.pos.row = 1:2, layout.pos.col = 3))
#grid.draw(legend_grob)
#upViewport()
print(p_per, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(p_inc, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
@
\end{figure}


%<<FigKCDEIntuition, echo = FALSE>>=
%#dengue_sj_for_embedded_ts_plot <- dengue_sj
%#dengue_sj_for_embedded_ts_plot$total_cases_plus_0.5 <-
%#    dengue_sj_for_embedded_ts_plot$total_cases + 0.5
%#dengue_sj_for_embedded_ts_plot$lag_total_cases_plus_0.5 <-
%#    lag(dengue_sj_for_embedded_ts_plot$total_cases_plus_0.5)
%#
%#ind_center <- which(dengue_sj_for_embedded_ts_plot$season == "1995/1996" & dengue_sj_for_embedded_ts_plot$season_week == 7)
%#center <- dengue_sj_for_embedded_ts_plot[ind_center, c("lag_total_cases_plus_0.5", "total_cases_plus_0.5")]
%#
%#dengue_sj_for_embedded_ts_plot$log_total_cases_plus_0.5 <-
%#    log(dengue_sj_for_embedded_ts_plot$total_cases + 0.5)
%#sm <- loess(log_total_cases_plus_0.5 ~ as.numeric(week_start_date),
%#    data = dengue_sj_for_embedded_ts_plot,
%#    span = 12 / nrow(dengue_sj_for_embedded_ts_plot))
%#dengue_sj_for_embedded_ts_plot$smooth_log_cases <- sm$fitted
%#dengue_sj_for_embedded_ts_plot$lag_1_smooth_log_cases <- lag(dengue_sj_for_embedded_ts_plot$smooth_log_cases)
%
%
%
%case_descriptor <- paste0(
%    "ili_national",
%    "-prediction_horizon_", 1L,
%    "-max_lag_", 1L,
%    "-max_seasonal_lag_", 0L,
%    "-filtering_", FALSE,
%    "-differencing_", FALSE,
%    "-seasonality_", FALSE,
%    "-bw_parameterization_", "full"
%)
%
%estimation_results_path <- file.path("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results",
%    "ili_national",
%    "estimation-results")
%
%kcde_fit_file_path <- file.path(estimation_results_path,
%    paste0("kcde_fit-", case_descriptor, ".rds"))
%
%kcde_fit_for_embedded_ts_plot <- readRDS(kcde_fit_file_path)
%
%#kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$x_names <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$x_names[1:2]
%#
%#kcde_fit_for_embedded_ts_plot$kcde_control$kernel_components[[1]]$theta_fixed$continuous_vars <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$continuous_vars <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$continuous_vars[1:2]
%#
%#kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$continuous_var_col_inds <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$continuous_var_col_inds[1:2]
%#
%#kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$bw <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$bw_continuous <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$bw[1:2, 1:2]
%#
%#kcde_fit_for_embedded_ts_plot$kcde_control$kernel_components[[1]]$theta_fixed$lower <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$lower <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$lower[1:2]
%#
%#kcde_fit_for_embedded_ts_plot$kcde_control$kernel_components[[1]]$theta_fixed$upper <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$upper <-
%#    kcde_fit_for_embedded_ts_plot$theta_hat[[1]]$upper[1:2]
%#
%#kcde_fit_for_embedded_ts_plot$kcde_control$kernel_components[[1]]$vars_and_offsets <-
%#    kcde_fit_for_embedded_ts_plot$vars_and_offsets <-
%#    kcde_fit_for_embedded_ts_plot$vars_and_offsets[1:2, ]
%
%
%
%#kcde_fit_for_embedded_ts_plot$kcde_control$kernel_components
%
%
%last_ili_na_ind <- max(which(is.na(ili_national$weighted_ili)))
%ili_national_for_embedded_ts_plot <-
%    ili_national[seq(from = last_ili_na_ind + 1, to = nrow(ili_national)), ]
%
%ili_national_for_embedded_ts_plot$log_weighted_ili <-
%    log(ili_national_for_embedded_ts_plot$weighted_ili)
%sm <- loess(log_weighted_ili ~ as.numeric(time),
%    data = ili_national_for_embedded_ts_plot,
%    span = 12 / nrow(ili_national_for_embedded_ts_plot))
%ili_national_for_embedded_ts_plot$smooth_log_weighted_ili <- sm$fitted
%ili_national_for_embedded_ts_plot$lag_1_smooth_log_weighted_ili <-
%    lag(ili_national_for_embedded_ts_plot$smooth_log_weighted_ili)
%ili_national_for_embedded_ts_plot$smooth_weighted_ili <-
%    exp(ili_national_for_embedded_ts_plot$smooth_log_weighted_ili)
%ili_national_for_embedded_ts_plot$lag_1_smooth_weighted_ili <-
%    lag(ili_national_for_embedded_ts_plot$smooth_weighted_ili)
%ili_national_for_embedded_ts_plot$weighted_ili <- ili_national_for_embedded_ts_plot$smooth_weighted_ili
%
%seasons_for_embedded_ts_plot <- unique(ili_national_for_embedded_ts_plot$season)[1:5]
%last_season_for_embedded_ts_plot <- tail(seasons_for_embedded_ts_plot, 1)
%ind_center <- which(ili_national_for_embedded_ts_plot$season == last_season_for_embedded_ts_plot & ili_national_for_embedded_ts_plot$season_week == 27)
%ind_center <- ind_center - 5
%center <- ili_national_for_embedded_ts_plot[ind_center, c("lag_1_smooth_weighted_ili", "smooth_weighted_ili")]
%
%kcde_fit_for_embedded_ts_plot$train_data <- 
%    ili_national_for_embedded_ts_plot[seq_len(ind_center - 1), ]
%
%undebug(kcde_dist_predict_given_lagged_lead_obs)
%undebug(kcde_kernel_centers_and_weights_predict_given_lagged_obs)
%undebug(compute_kernel_values)
%
%temp <- kcde_predict(kcde_fit_for_embedded_ts_plot,
%    prediction_data = ili_national_for_embedded_ts_plot[seq_len(ind_center), ],
%    leading_rows_to_drop = 0L,
%    trailing_rows_to_drop = 0L,
%    additional_training_rows_to_drop = NULL,
%    prediction_type = "centers-and-weights",
%    log = FALSE)
%
%#temp2 <- kcde_predict(kcde_fit_for_embedded_ts_plot,
%#    prediction_data = ili_national_for_embedded_ts_plot[seq_len(ind_center), ],
%#    leading_rows_to_drop = 0L,
%#    trailing_rows_to_drop = 0L,
%#    additional_training_rows_to_drop = NULL,
%#    prediction_type = "distribution",
%#    log = FALSE)
%
%obs_weights_for_embedded_ts_plot <- cbind(
%    temp$conditioning_vars,
%    temp$weights)
%colnames(obs_weights_for_embedded_ts_plot)[3] <- "obs_weights"
%
%p <- ggplot() +
%#    geom_path(aes(x=lag_1_smooth_log_cases, y = smooth_log_cases),
%    ##    geom_path(aes(x = lag_total_cases_plus_0.5, y = total_cases_plus_0.5),
%#        colour = "grey",
%#        data = dengue_sj_for_embedded_ts_plot[dengue_sj_for_embedded_ts_plot$season %in% c("1990/1991", "1991/1992", "1992/1993", "1993/1994", "1994/1995") |
%#                (dengue_sj_for_embedded_ts_plot$season == "1995/1996" & dengue_sj_for_embedded_ts_plot$season_week <= 7), ]) +
%    geom_path(aes(x=lag_1_smooth_weighted_ili, y = smooth_weighted_ili),
%#    geom_path(aes(x = lag_total_cases_plus_0.5, y = total_cases_plus_0.5),
%        colour = "grey",
%        data = ili_national_for_embedded_ts_plot[ili_national_for_embedded_ts_plot$season %in% seasons_for_embedded_ts_plot |
%                (ili_national_for_embedded_ts_plot$season == last_season_for_embedded_ts_plot & ili_national_for_embedded_ts_plot$season_week <= 7), ]) +
%#    geom_point(aes(x=lag_1_smooth_log_cases, y = smooth_log_cases, colour = obs_weight),
%#        size = 3,
%#        data=San_Juan_train[San_Juan_train$season %in% c("1990/1991", "1991/1992", "1992/1993", "1993/1994", "1994/1995") |
%#                (San_Juan_train$season == "1995/1996" & San_Juan_train$season_week <= 7), ]) +
%#    geom_point(aes(x = lag_1_smooth_weighted_ili, y = smooth_weighted_ili, colour = season_week),
%##        colour = "red",
%#        size = 3,
%##        data = ili_national_for_embedded_ts_plot[ind_center, ]) +
%#        data = ili_national_for_embedded_ts_plot[ili_national_for_embedded_ts_plot$season == last_season_for_embedded_ts_plot, ]) +
%    geom_point(aes(x = weighted_ili_lag1, y = weighted_ili_lag0, colour = obs_weights),
%        size = 3,
%        data = obs_weights_for_embedded_ts_plot) +
%    geom_point(aes(x = lag_1_smooth_weighted_ili, y = smooth_weighted_ili, colour = season_week),
%        colour = "red",
%        size = 3,
%        data = ili_national_for_embedded_ts_plot[ind_center, ]) +
%#    scale_colour_gradient2("Time Point\nWeight", low = "#56B4E9", high = "#E69F00", midpoint = 0.002) +
%#    scale_alpha_continuous("Observation Weight") +
%#    scale_alpha_continuous("Observation Weight",
%#        range = c(1, 0)) +
%    xlab("Lag 1 Smoothed Log Cases") +
%    ylab("Smoothed Log Cases") +
%    theme_bw()
%#    scale_x_log10() +
%#    scale_y_log10() +
%#    theme_bw(base_size=22)
%
%p
%@


The second component of our kernel is a multivariate kernel incorporating
all of the other variables in $\bx_t$ and $y_t^h$.  In our
applications, these variables are measures of incidence; for brevity of
notation, we collect them in the column vector
$\tilde{\bz}_t = (z_{t - l_1}, \ldots, z_{t - l_M}, z_{t + h})'$.
These incidence measures are continuous in the application to influenza and
discrete case counts in the application to dengue fever.  In the continuous
case, we have used a multivariate log-normal kernel function
(Figure~\ref{fig:PeriodicKernelPlot}).  This kernel specification automatically
handles the restriction that counts are non-negative, and approximately captures
the long tail in disease incidence that we will illustrate in the applications
Section below.  This kernel function has the following functional form:
\begin{equation}
K^{\text{inc}}_{\text{cont}}(\tilde{\bz}_{t^*}, \tilde{\bz}_{t}; \bB^h) = \frac{\exp\left[ -\frac{1}{2} \{\log(\tilde{\bz}_{t^*}) - \log(\tilde{\bz}_t)\}' \bB^{-1} \{\log(\tilde{\bz}_{t^*}) - \log(\tilde{\bz}_t)\} \right]}{(2 \pi)^{\frac{M+1}{2}} \vert \bB \vert^{\frac{1}{2}} z_{t^* + h} \prod_{m = 1}^M z_{t^* - l_m} }
\end{equation}

\lboxit{fix functional form for incidence kernel}

In this expression, the $\log$ operator applied to a vector takes the log of
each component of that vector.  The matrix $\bB$ is a bandwidth matrix that
controls the orientation and scale of the kernel function.  This bandwidth
matrix is parameterized by $\btheta^h_{\text{inc}}$.  In this work we have considered
two parameterizations: a diagonal bandwidth matrix, and a fully parameterized
bandwidth based on the Cholesky decomposition.  In order to obtain the
discrete kernel (Figure~\ref{fig:PeriodicKernelPlot}), we integrate an
underlying continuous kernel function over hyper-rectangles containing the
points in the range of the discrete random variable (see supplement for details).

%\begin{figure}
%\caption{Illustrations of $K^{inc}_{cont}$ and
%$K^{inc}_{disc}$ in the bivariate case.  Solid lines show contours of the
%continuous kernel function.  Grey dots indicate the value of the discrete kernel
%function.  The value of the discrete kernel is
%obtained by integrating the continuous kernel over regions as illustrated by the
%dashed lines in panels (a) and (b).  In all panels the kernel function is
%centered at $(2.5, 2.5)$.  In panels (a) and (b) the bandwidth matrix is 
%$\begin{bmatrix}0.2 & 0 \\ 0 & 0.2\end{bmatrix}$, and in panels (c) and (d)
%the bandwidth matrix is $\begin{bmatrix}0.2 & 0.15 \\ 0.15 & 0.2\end{bmatrix}$.
% We illustrate each case with both linear and logarithmic scale axes.}
%\label{fig:IncidenceKernelPlots}
%<<IncidenceKernelPlots, echo = FALSE, fig.keep = "last">>=
%cont_grid_bounds <- c(0.01, 10)
%cont_grid_size <- 101
%x_cont_grid <- 
%    expand.grid(
%        seq(from = cont_grid_bounds[1], to = cont_grid_bounds[2], length = cont_grid_size),
%        seq(from = cont_grid_bounds[1], to = cont_grid_bounds[2], length = cont_grid_size)
%    ) %>%
%    `colnames<-`(c("X1", "X2"))
%disc_grid_bounds <- c(0.5, 9.5)
%x_disc_grid <-
%    expand.grid(
%        seq(from = disc_grid_bounds[1], to = disc_grid_bounds[2], by = 1),
%        seq(from = disc_grid_bounds[1], to = disc_grid_bounds[2], by = 1)
%    ) %>%
%    `colnames<-`(c("X1", "X2"))
%
%
%#' Compute log(round(exp(x))) in such a way that the rounding function
%#' always rounds up or down to an integer + 0.5, and
%#' an integer always gets rounded up.
%#' 
%#' @param x numeric
%#' 
%#' @return floor(x) - 1
%log_round_to_integer_plus_0.5_exp <- function(x) {
%    exp_x <- exp(x) + 0.5
%    
%    inds_ceil <- exp_x - floor(exp_x) >= 0.5
%    
%    exp_x[inds_ceil] <- ceiling(exp_x[inds_ceil])
%    exp_x[!inds_ceil] <- floor(exp_x[!inds_ceil])
%    
%    return(log(exp_x - 0.5))
%}
%
%
%
%
%continuous_density_df_a <- x_cont_grid %>%
%    as.data.frame() %>%
%    `$<-`("z",
%#        sapply(seq_len(nrow(x_cont_grid)), function(x_grid_row_ind) {
%#                log_pdtmvn_kernel(x = as.matrix(x_cont_grid)[x_grid_row_ind, , drop = FALSE],
%                log_pdtmvn_mode_centered_kernel(x = x_cont_grid,
%                    center = as.matrix(data.frame(X1 = 2.5, X2 = 2.5)),
%                    bw = matrix(c(.2, 0, 0, .2), nrow = 2, ncol = 2),
%                    bw_continuous = matrix(c(.2, 0, 0, .2), nrow = 2, ncol = 2),
%                    continuous_vars = c("X1", "X2"),
%                    discrete_vars = character(0),
%                    continuous_var_col_inds = 1:2,
%                    discrete_var_col_inds = integer(0),
%                    discrete_var_range_fns = NULL,
%#                    lower = c(X1 = log(0.5), X2 = log(0.5)),
%                    lower = c(X1 = -Inf, X2 = -Inf),
%                    upper = c(X1 = Inf, X2 = Inf),
%                    x_names = c("X1", "X2"),
%                    log = FALSE)
%#            })
%    )
%discrete_density_df_a <- x_disc_grid %>%
%    as.data.frame() %>%
%    `colnames<-`(c("X1", "X2")) %>%
%    `$<-`("z",
%#        sapply(seq_len(nrow(x_disc_grid)), function(x_grid_row_ind) {
%#                log_pdtmvn_kernel(x = as.matrix(x_disc_grid)[x_grid_row_ind, , drop = FALSE],
%                log_pdtmvn_mode_centered_kernel(x = x_disc_grid,
%                    center = as.matrix(data.frame(X1 = 2.5, X2 = 2.5)),
%                    bw = matrix(c(.2, 0, 0, .2), nrow = 2, ncol = 2),
%                    bw_continuous = matrix(0, nrow = 0, ncol = 0),
%                    continuous_vars = character(0),
%                    discrete_vars = c("X1", "X2"),
%                    continuous_var_col_inds = integer(0),
%                    discrete_var_col_inds = 1:2,
%                    discrete_var_range_fns = list(
%                        X1 = list(a = function(x) {
%                                return(log(exp(x) - 0.5))
%                            },
%                            b = function(x) {
%                                return(log(exp(x) + 0.5))
%                            },
%                            in_range = function(x, tolerance = .Machine$double.eps^0.5) {
%                                return(sapply(x, function(x_i) {
%                                            return(
%                                                isTRUE(all.equal(
%                                                        x_i,
%                                                        log_round_to_integer_plus_0.5_exp(x_i),
%                                                        tolerance = tolerance
%                                                    ))
%                                            )
%                                        }))
%                            },
%                            discretizer = log_round_to_integer_plus_0.5_exp),
%                        X2 = list(a = function(x) {
%                                return(log(exp(x) - 0.5))
%                            },
%                            b = function(x) {
%                                return(log(exp(x) + 0.5))
%                            },
%                            in_range = function(x, tolerance = .Machine$double.eps^0.5) {
%                                return(sapply(x, function(x_i) {
%                                            return(
%                                                isTRUE(all.equal(
%                                                        x_i,
%                                                        log_round_to_integer_plus_0.5_exp(x_i),
%                                                        tolerance = tolerance
%                                                    ))
%                                            )
%                                        }))
%                            },
%                            discretizer = log_round_to_integer_plus_0.5_exp)
%                        ),
%#                    lower = c(X1 = log(0.5), X2 = log(0.5)),
%                    lower = c(X1 = -Inf, X2 = -Inf),
%                    upper = c(X1 = Inf, X2 = Inf),
%                    x_names = c("X1", "X2"),
%                    log = FALSE)
%#            })
%    )
%
%int_area_xlim <- 1:2
%int_area_ylim <- 5:6
%integration_area_polygon_df <-
%    data.frame(id = 1,
%        value = 1,
%        x = rep(int_area_xlim, each = 2),
%        y = c(int_area_ylim, rev(int_area_ylim)))
%
%p_a_regular_scale <- ggplot() +
%    geom_polygon(aes(x = x, y = y, group = id),
%        fill = "grey",
%        data = integration_area_polygon_df) +
%    geom_hline(yintercept = int_area_ylim, linetype = 2) +
%    geom_vline(xintercept = int_area_xlim, linetype = 2) +
%    geom_contour(aes(x = X1, y = X2, z = z, colour = z), bins = 7, data = continuous_density_df_a) +
%    geom_point(aes(x = X1, y = X2, colour = z), data = discrete_density_df_a) +
%    scale_colour_gradientn("Discrete\nKernel\nValue",
%        colours = rev(c("#333333", "#777777", "#BBBBBB", "#FFFFFF")),
%#        colours = rev(c("#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        limits = c(10^{-10}, 1),
%        trans = "log",
%#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%#        values = c(0.0001, 0.001, 0.01, 0.1, 1),
%#        values = c(-4, -3, -2, -1),
%        limits = c(0.00001, 0.2),
%        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%#        breaks = c(0.001, 0.01, 0.1, 1),
%#        labels = c(expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%        na.value = "white"
%    ) +
%    xlab(expression(X[1])) +
%    ylab(expression(X[2])) +
%    ggtitle("(a) Diagonal bandwidth\nLinear axes") +
%    theme_bw()
%
%print(p_a_regular_scale)
%legend_grob <- grid.get("guide-box.3-5-3-5")
%
%## update p_a_regular_scale to not print legend
%p_a_regular_scale <- p_a_regular_scale +
%    theme(legend.position = "none")
%    
%
%p_a_log_scale <- p_a_regular_scale +
%    scale_x_log10() +
%    scale_y_log10() +
%    ggtitle("(b) Diagonal bandwidth\nLogarithmic axes")
%
%var_b <- 0.2
%covar_b <- 0.15
%
%
%continuous_density_df_b <- x_cont_grid %>%
%    as.data.frame() %>%
%    `$<-`("z",
%        log_pdtmvn_mode_centered_kernel(x = x_cont_grid,
%            center = as.matrix(data.frame(X1 = 2.5, X2 = 2.5)),
%            bw = matrix(c(var_b, covar_b, covar_b, var_b), nrow = 2, ncol = 2),
%            bw_continuous = matrix(c(var_b, covar_b, covar_b, var_b), nrow = 2, ncol = 2),
%            continuous_vars = c("X1", "X2"),
%            discrete_vars = character(0),
%            continuous_var_col_inds = 1:2,
%            discrete_var_col_inds = integer(0),
%            discrete_var_range_fns = NULL,
%            lower = c(X1 = -Inf, X2 = -Inf),
%#            lower = c(X1 = log(0.5), X2 = log(0.5)),
%            upper = c(X1 = Inf, X2 = Inf),
%            x_names = c("X1", "X2"),
%            log = FALSE)
%    )
%
%#x_disc_grid <- data.frame(X1 = c(1, 3), X2 = c(1, 3))
%#debug(pdtmvn::dpdtmvn)
%discrete_density_df_b <- x_disc_grid %>%
%    as.data.frame() %>%
%    `$<-`("z",
%#        sapply(seq_len(nrow(x_disc_grid)), function(x_grid_row_ind) {
%                log_pdtmvn_mode_centered_kernel(x = x_disc_grid,
%                    center = as.matrix(data.frame(X1 = 2.5, X2 = 2.5)),
%                    bw = matrix(c(var_b, covar_b, covar_b, var_b), nrow = 2, ncol = 2),
%                    bw_continuous = matrix(0, nrow = 0, ncol = 0),
%                    continuous_vars = character(0),
%                    discrete_vars = c("X1", "X2"),
%                    continuous_var_col_inds = integer(0),
%                    discrete_var_col_inds = 1:2,
%                    discrete_var_range_fns = list(
%                        X1 = list(a = function(x) {
%                                return(log(exp(x) - 0.5))
%                            },
%                            b = function(x) {
%                                return(log(exp(x) + 0.5))
%                            },
%                            in_range = function(x, tolerance = .Machine$double.eps^0.5) {
%                                return(sapply(x, function(x_i) {
%                                            return(
%                                                isTRUE(all.equal(
%                                                        x_i,
%                                                        log_round_to_integer_plus_0.5_exp(x_i),
%                                                        tolerance = tolerance
%                                                    ))
%                                            )
%                                        }))
%                            },
%                            discretizer = log_round_to_integer_plus_0.5_exp),
%                        X2 = list(a = function(x) {
%                                return(log(exp(x) - 0.5))
%                            },
%                            b = function(x) {
%                                return(log(exp(x) + 0.5))
%                            },
%                            in_range = function(x, tolerance = .Machine$double.eps^0.5) {
%                                return(sapply(x, function(x_i) {
%                                            return(
%                                                isTRUE(all.equal(
%                                                        x_i,
%                                                        log_round_to_integer_plus_0.5_exp(x_i),
%                                                        tolerance = tolerance
%                                                    ))
%                                            )
%                                        }))
%                            },
%                            discretizer = log_round_to_integer_plus_0.5_exp)
%                        ),
%#                    lower = c(X1 = log(0.5), X2 = log(0.5)),
%                    lower = c(X1 = -Inf, X2 = -Inf),
%                    upper = c(X1 = Inf, X2 = Inf),
%                    x_names = c("X1", "X2"),
%                    log = FALSE)
%#            })
%    )
%
%p_b_regular_scale <- ggplot() +
%    geom_contour(aes(x = X1, y = X2, z = z), bins = 7, data = continuous_density_df_b) +
%    geom_point(aes(x = X1, y = X2, colour = z), data = discrete_density_df_b) +
%#    scale_colour_gradientn("Predictive\nDistribution\nProbability",
%#        colours = rev(c("#333333", "#777777", "#BBBBBB", "#FFFFFF")),
%##        colours = rev(c("#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%##        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%##        limits = c(10^{-10}, 1),
%#        trans = "log",
%##        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%##        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%##        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%#        values = c(0.0001, 0.001, 0.01, 0.1, 1),
%##        values = c(-4, -3, -2, -1),
%#        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%#        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%##        breaks = c(0.001, 0.01, 0.1, 1),
%##        labels = c(expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%#        na.value = "white"
%#    ) +
%    scale_colour_gradientn("Predictive\nDistribution\nProbability",
%        colours = rev(c("#333333", "#777777", "#BBBBBB", "#FFFFFF")),
%#        colours = rev(c("#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        limits = c(10^{-10}, 1),
%        trans = "log",
%#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%#        values = c(0.0001, 0.001, 0.01, 0.1, 1),
%#        values = c(-4, -3, -2, -1),
%        limits = c(0.00001, 0.2),
%        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%#        breaks = c(0.001, 0.01, 0.1, 1),
%#        labels = c(expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%        na.value = "white"
%    ) +
%    #    geom_point(aes(x = exp(log(3) - var_b - covar_b), y = exp(log(3) - var_b - covar_b)), colour = "red") +
%    xlab(expression(X[1])) +
%    ylab(expression(X[2])) +
%    ggtitle("(c) Non-diagonal bandwidth\nLinear axes") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%p_b_log_scale <- p_b_regular_scale +
%    scale_x_log10() +
%    scale_y_log10() +
%    ggtitle("(c) Non-diagonal bandwidth\nLogarithmic axes")
%
%grid.newpage()
%#grid.layout(nrow = 2, ncol = 2, heights = unit(rep(1, 2), c("null", "lines")))
%pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 3,
%            heights = unit(rep(1, 2), c("null", "null")),
%            widths = unit(c(1, 1, 0.3), c("null", "null", "null")))))
%pushViewport(viewport(layout.pos.row = 1:2, layout.pos.col = 3))
%grid.draw(legend_grob)
%upViewport()
%print(p_a_regular_scale, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
%print(p_a_log_scale, vp = viewport(layout.pos.row = 1, layout.pos.col = 2))
%print(p_b_regular_scale, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
%print(p_b_log_scale, vp = viewport(layout.pos.row = 2, layout.pos.col = 2))
%@
%\end{figure}

%Here, $L(\bw, \bw^{*} ; \bH)$ is a continuous multivariate kernel function
%defined on $\prod_{j = 1}^{J} \mathcal{E}^j$.  For each discrete variable indexed by $j
%= 1, \ldots, J^d$, we associate lower and upper bounds of integration $a_{z_j}$
%and $b_{z_j}$ with each value $z_j \in \mathcal{D}^j$.  In order to ensure that
%our final density estimate integrates to $1$, we require that these integration
%bounds form a disjoint cover of $\mathcal{E}^j$ in the sense that $\cup_{z_j \in
%\mathcal{D}^j} [a_{z_j}, b_{z_j}) = \mathcal{E}^j$ and $\cap_{z_j \in
%\mathcal{D}^j} [a_{z_j}, b_{z_j}) = \emptyset$, the empty set.  At a vector of
%values $\bz \in \prod_{j = 1}^J \mathcal{D}^j$, we define the partially
%discretized kernel as follows:
%\begin{equation*}
%K(\bz, \bz^{*} ; \bH) = \int_{a_{z_1}}^{b_{z_1}} \cdots
%\int_{a_{z_{J^d}}}^{b_{z_{J^d}}} L(\bz, \bz^{*} ; \bH) \, d z_{1} \cdots d
%z_{J^d}
%\end{equation*}

%To make this concrete, consider a $J$-dimensional random
%vector $\bW = (\bW^{d'}, \bW^{c'})'$ that is partitioned into a
%$J^d$-dimensional subvector $\bZ^d$ of discrete random variables and a
%$J^c$-dimensional subvector $\bZ^c$ of continuous random variables.  Without
%loss of generality, we assume that the discrete variables are the first $J^d$
%variables.  For each component random variable $Z_j$, $j = 1, \ldots, J$, we
%denote the set of values that $Z_j$ may take by $\mathcal{D}^j \subseteq
%\mathbb{R}$.  In the continuous cases, we take $\mathcal{D}^j = \mathbb{R}$.  In
%the discrete cases, $\mathcal{D}^j$ is a discrete set such as the positive
%integers.  Our definitions could be modified to handle a component random
%variable whose distribution comprised a combination of discrete and continuous
%parts; however, this is not required for our applications so we have not pursued
%that line here.




%\begin{figure}[height=2in]

We estimate the bandwidth parameters $\btheta^h$ by numerically maximizing the
cross-validated log score of the predictive distributions for the observations
in the training data.  For a random variable $Y$ with observed value $y$ the
log score of the predictive distribution $f_Y$ is $log\{f_Y(y)\}$.  A larger log
score indicates better model performance.  In obtaining the cross-validated log score for the
predictive distribution at time $t^*$, we leave the year
of training data before and after the time $t^*$ out of the set $\btau$ in
Equations~\eqref{eqn:KCDEDefinition} through \eqref{eqn:KCDEWeightsDef}.
Our primary motivation for using the log score as the optimization target during
estimation is that this is the criteria that has been used to evaluate and
compare prediction methods in two recent government-sponsored infectious disease
prediction contests
\cite{PandemicPredictionandForecastingScienceandTechnologyInteragencyWorkingGroup2015Announcement, EpidemicPredictionInitiative2015Index}.
We will apply our method to the data sets
from those competitions in the applications section below, and will report log
scores in order to facilitate comparisons with other results from those
competitions that may be published in the future.
In general, the log score is a strictly proper scoring rule; i.e., its
expectation is uniquely maximized by the true predictive
distribution\cite{gneiting2007strictlyProperScoringRules}.
However, its use as an optimization criterion has been criticised for being
sensitive to outliers\cite{gneiting2007strictlyProperScoringRules}.  In the
kernel density estimation literature, this approach to estimation is referred to
as likelihood cross-validation, and similar criticisms have been made regarding
its performance in handling outliers and estimating heavy-tailed distributions
\cite{schuster1981nonconsistencyLCVforKDE,
scott1981MonteCarloStudyNonparDensityEstimators}.

\subsection{Combining Marginal Predictive Distributions with Copulas}
\label{subsec:Methods:Copulas}

We use copulas (cite cite) to tie the marginal predictive distributions for individual
prediction horizons obtained from KCDE together into a joint predictive
distribution for the trajectory of incidence over multiple time points. 
The copula is a parametric function that captures
the dependence relations among a collection of random variables and allows us
to compute the joint distribution from the marginal distributions.

In order to describe our methods for both continuous and discrete distributions, it is
most convenient to frame the discussion in this section in terms of {c.d.f.}s instead of density
functions.
We will use a capital $C$ to denote the copula function for {c.d.f.}s and a
lower case $c$ to denote the copula function for densities.  Similarly, the predictive
densities $f^{h}(y_{t^*}^h | \bx_{t^*}; \btheta^h)$ we obtained in the previous section
naturally yield corresponding predictive {c.d.f.}s
$F^{h}(y_{t^*}^h | \bx_{t^*}; \btheta^h)$.

Our model specifies the joint {c.d.f.} for $(Y_{t^*}^1, \ldots, Y_{t^*}^{H_{t^*}})$
as follows:
\begin{align}
&F^{H_{t^*}}(y_{t^*}^1, \ldots, y_{t^*}^{H_{t^*}} | \bx_{t^*}; \btheta^1, \ldots, \btheta^{H_{t^*}}, \bxi^{H_{t^*}}) = \nonumber \\
&\qquad C\{F^{1}(y_{t^*}^1 | \bx_{t^*}; \btheta^1), \ldots, F^{H_{t^*}}(y_{t^*}^{H_{t^*}} | \bx_{t^*}; \btheta^{H_{t^*}}); \bxi^{H_{t^*}}\}
\end{align}

The copula function $C$ maps the marginal {c.d.f.} values to the joint
{c.d.f.} value.  We use the isotropic normal
copula implemented in the {\tt R} package {\tt copula}
\cite{HofertRCopulaPackage}.  The copula function is given by
\begin{equation}
C(u_1, \ldots, u_H ; \bxi^H) = \Phi_{\Sigma^H}(\Phi^{-1}(u_1), \ldots, \Phi^{-1}(u_H)),
\end{equation}
where $\Phi^{-1}$ is the inverse {c.d.f.} of a univariate normal
distribution with mean $0$ and variance $1$ and $\Phi_{\Sigma^H}$ is the {c.d.f.}
of a multivariate Gaussian distribution with mean $\b0$ and covariance matrix $\Sigma^H$.  The isotropic
specification sets $\Sigma^H = [{\sigma^H_{i,j}}]$, where 
\begin{equation}
{\sigma^H_{i,j}} = \begin{cases} 1 \text{ if $i = j$,} \\ \xi^H_d \text{ if $\vert i - j \vert = d$} \end{cases}
\end{equation}
Intuitively, $\xi^H_d$ captures the amount of dependence between incidence
levels at future times that are $d$ weeks apart.

We obtain a separate copula fit for each value of $H$ from 2 to $W$ (note that a
copula is not required for ``trajectories'' of length $H = 1$).  In order to do this, we follow a
two-stage estimation strategy\cite{joe2005asymptoticEfficiencyTwoStageCopula}:
\begin{enumerate}
  \item Estimate the parameters for marginal predictive distributions
  using the procedures described in the previous subsection.
  \item Estimate the copula parameters, holding the parameters for the
  marginal predictive distributions fixed:
    \begin{enumerate}
      \item Form vectors of
  ``pseudo-observations'' by passing observed incidence trajectories from previous seasons through the marginal predictive {c.d.f.}s obtained in step 1:
  \begin{align}
  &(u_{k,1}, \ldots, u_{k, H}) = \nonumber \\
  &\qquad \{F^{1}(z_{t_k^* + 1} | t_k^*, z_{t_k^* - l_1}, \ldots, z_{t_k^* - l_M}; \btheta^1), \ldots, F^{H}(z_{t_k^* + H} | t_k^*, z_{t_k^* - l_1}, \ldots, z_{t_k^* - l_M}; \btheta^H)\} \nonumber
  \end{align}
  We form one such vector of pseudo-observations for each season in the training
  data; in the notation here, these seasons are indexed by $k$.  The relevant
  time points $t_k^*$ are the times in those previous seasons falling $H$ time
  steps before the end of the season.
  \item Estimate the copula parameters $\bxi^H$ by maximizing the likelihood of the
  pseudo-observations.
  \end{enumerate}
\end{enumerate}

\section{Simulation Study}
\label{sec:SimStudy}

We conducted a simulation study to examine the
utility of using a non-diagonal bandwidth matrix specification when
estimating conditional distributions with KCDE.  There are many factors that
determine the relative performance of KCDE estimators with different bandwidth
parameterizations.  In this simulation study, we vary just two of these factors:
the number of conditioning variables (either $1$ or $3$) and the sample size
($N = 100$ or $N = 1000$).  We hold other factors that may be related to the
relative performance of different bandwidth specifications fixed.

The distributions that we simulate from are discretized multivariate normal
distributions of dimension either $D = 2$ or $D = 4$.  To define this distribution,
let $\bU \sim MVN(\b0, \Sigma)$ where $\Sigma$ is a $D \times D$ matrix with $1$ on
the diagonal and $0.9$ off of the diagonal.  We treat $\bU$
as a latent variable and discretize it to obtain the random variable $\bX$ using
the approach described in the supplement.

We conducted 500 simulation trials for each combination of the sample size $N$
and dimension $D$.  In each trial, we simulated $N$ observations of
the discretized multivariate normal random variable $\bX$.  Using these
observations as a training data set, we estimated the bandwidth
parameters for two variations on a KCDE model for the conditional distribution
of $X_1 | X_2, \ldots, X_D$: one with a diagonal bandwidth matrix specification
and one with a fully parameterized bandwidth matrix.  In this simulation study,
the kernel function was obtained by discretizing a multivariate normal kernel
function rather than a log-normal kernel function as in our applications below. 
Otherwise, the method is as described previously.

We evaluated the conditional density estimates by an importance
sampling approximation of the Hellinger distance of the conditional
density estimate from the true conditional density, integrated over the range of
the conditioning variables (see supplement). 
The Hellinger distance lies between 0 and 1, with smaller values indicating that the
density estimate is better.  It has been argued that the Hellinger distance is
preferred to other measures of the quality of kernel density estimates such as
integrated squared error\cite{kanazawa1993hellingerDistanceKDE}. For each
combination of the training set sample size, dimension, and simulation trial, we compute the difference between the
Hellinger distance from the true conditional distribution achieved with a
diagonal bandwidth matrix and with a fully parameterized bandwidth matrix. 


%<<SimStudyMotivationPlot, echo = FALSE>>=
%n <- nrow(dengue_sj)
%#plot(log(dengue_sj$total_cases[seq_len(n - 1)] + 100) ~ log(dengue_sj$total_cases[seq(from = 2, to = n)] + 100))
%#plot(log(dengue_sj$total_cases[seq_len(n - 1)] + 0.5) ~ log(dengue_sj$total_cases[seq(from = 2, to = n)] + 0.5))
%plot(dengue_sj$total_cases[seq_len(n - 1)] ~ dengue_sj$total_cases[seq(from = 2, to = n)])
%@

The results indicate that using a fully parameterized bandwidth matrix
instead of a diagonal bandwidth generally yields improved density estimates as
measured by the integrated Hellinger distance (Figure~\ref{fig:SimStudyResultsPlot}).
The average improvement from using a fully parameterized bandwidth matrix
is larger with a sample size of $N = 100$ instead of $N = 1000$, but there is
also more variation in performance with the smaller sample size.

\lboxit{To do: update simulation study results with results from 4 dimensional
case.  Put in a sentence here about whether or not the simulation study
results are the same with $D = 4$.}

\begin{figure}
\caption{Results from the simulation study.  The top facet of the plot
shows results from simulation trials with dimension $D = 2$, and the lower facet
has results from dimension $D = 4$.  Positive values indicate simulation trials
where the full bandwidth specification outperformed the diagonal bandwidth
specification with the same training data set, as measured by Hellinger distance from the
target conditional density.}
\label{fig:SimStudyResultsPlot}
<<SimStudyResultsPlot, echo = FALSE, fig.height = 5>>=
sim_results <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/sim-study/kcde-predictions.rds")
sim_results <- sim_results[1:2000, ]
sim_results$sim_run_inds <- rep(seq_len(500), each = 4)

sim_results_contrasts_within_n_dim <- sim_results %>%
    group_by(sim_n, sim_family, sim_run_inds) %>%
    summarize(
        KL_div_diff = KL_div[which(bw_parameterization == "diagonal")] - KL_div[which(bw_parameterization == "full")],
        Hellinger_dist_diff = Hellinger_dist[which(bw_parameterization == "diagonal")] - Hellinger_dist[which(bw_parameterization == "full")]
    )

ggplot() +
    geom_boxplot(aes(x = sim_n, y = Hellinger_dist_diff),
        data = sim_results_contrasts_within_n_dim) +
    geom_hline(yintercept = 0) +
    facet_wrap( ~ sim_family, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                labels[labels == "multivariate-2d-discretized"] <- "D = 2"
                labels[labels == "multivariate-4d-discretized"] <- "D = 4"
                return(labels)
            })) +
    xlab("Training Set Sample Size") +
    ylab("Difference in Hellinger Distance for KCDE with\nDiagonal Bandwidth vs. Fully Parameterized Bandwidth") +
    theme_bw()
@
\end{figure}

\section{Applications}
\label{sec:Applications}

In this Section, we illustrate our methods through applications to prediction
of infectious disease incidence in two examples with real disease incidence data
sets: one with a weekly measure of incidence of dengue fever in San
Juan, Puerto Rico, and a second with a weekly measure of incidence of influenza
like illness in the United States.  These data sets were used in two recent
prediction competitions sponsored by the United States federal
government\cite{PandemicPredictionandForecastingScienceandTechnologyInteragencyWorkingGroup2015Announcement,
EpidemicPredictionInitiative2015Index}.  In the dengue data set, the incidence
measure is an integer number of reported cases in the given week.  In the
influenza data set the incidence measure is continuous, a weighted
proportion of doctor visits with influenza-like illness.

Figure~\ref{fig:IntialDataPlots} displays each time series.  As indicated in the
figure, we have divided each data set into two subsets.  The first period is used as a training set in
estimating the model parameters.  The last four years of each data set are
reserved as a test set for evaluating model performance.  The length of
the testing set was selected for use with the dengue data by the competition
administrators, and we have adopted that convention for use with the influenza
data as well.  All predictions are made as though in real time assuming that
once cases are reported, they are never revised.  Specifically, we use only data up
through a given week in order to make predictions for incidence after that week.

\begin{figure}
\caption{Plots of the data sets we apply our methods to.  In each case, the last
four years of data are held out as a test data set; this cutoff is indicated
with a vertical dashed line.  For the flu data set, low-season incidence was not
recorded in early years of data collection; these missing data are indicated
with vertical grey bars.}
\label{fig:IntialDataPlots}
<<InitialDataPlot, echo = FALSE, fig.height = 5>>=
#time_limits <- c(min(c(ili_national$time, dengue_sj$time)),
#    max(c(ili_national$time, dengue_sj$time)))

dengue_plot <- ggplot() +
    geom_line(aes(x = as.Date(time), y = total_cases),
        data = dengue_sj) +
    geom_vline(aes(xintercept = as.numeric(as.Date(dengue_train_cutoff_time))),
        colour = "red", linetype = 2) +
    scale_x_date() +
#    scale_x_date(limits = time_limits, expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 500), expand = c(0, 0)) +
    xlab("Time") +
    ylab("Reported Cases") +
    ggtitle("Dengue Fever Data - San Juan, Puerto Rico") +
    theme_bw(base_size = 11)

ili_plot <- ggplot() +
    geom_line(aes(x = as.Date(time), y = weighted_ili),
        data = ili_national) +
    geom_vline(aes(xintercept = as.numeric(as.Date(time))),
        colour = "grey",
        data = ili_national[is.na(ili_national$weighted_ili), ]) +
    geom_vline(aes(xintercept = as.numeric(as.Date(ili_train_cutoff_time))),
        colour = "red", linetype = 2) +
    scale_x_date() +
#    scale_x_date(limits = time_limits, expand = c(0, 0)) +
    xlab("Time") +
    ylab("Weighted Influenza-like Illness\n") +
    ggtitle("Influenza Data - National United States") +
    theme_bw(base_size = 11)

grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 1)))
print(dengue_plot, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(ili_plot, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
@
\end{figure}

There are three prediction targets for
each data set, based closely on the prediction targets that were used in the
original competitions.  First, for each week in the test data, we obtain a
predictive distribution for the incidence measure in that week at each prediction horizon
from 1 to 52 weeks ahead.  Second, in each week of the test data set, we make
predictions for the timing of the peak week of the corresponding season. 
Third, in each week of the test data set we predict incidence in the peak
week for the corresponding season.  Following the precedent set in the
competitions, we make predictions for \textit{binned} incidence in the peak
week.  For the dengue data set, the bins are $[0, 50), [50, 100), \ldots, [500, \infty)$.
For the influenza data set, the bins are $[0, 0.5), [0.5, 1), \ldots, [13, \infty)$.
Our predictions for incidence in individual weeks are for the raw, unbinned,
incidence measure.  These prediction targets are illustrated in the supplement.
%Figure~\ref{fig:PredictionTargetsIllustration}.



Our applications include four variations on KCDE model specifications:
\begin{enumerate}
\item The ``Null KCDE Model'' omits the periodic component of the kernel function and uses
a diagonal bandwidth matrix specification.
\item The ``Full Bandwidth KCDE Model'' omits the periodic component of the
kernel function and uses a fully parameterized bandwidth matrix specification.
\item The ``Periodic KCDE Model'' includes the periodic component of the kernel
function and uses a diagonal bandwidth matrix specifications.
\item The ``Periodic, Full Bandwidth KCDE Model'' includes the periodic
component of the kernel function and uses a fully parameterized bandwidth
matrix specification.
\end{enumerate}

%.  The
%``Null KCDE Model'' omits the periodic component of the kernel function and uses
%a diagonal bandwidth matrix specification.  The other three variations are
%obtained by adding the periodic kernel component to this null KCDE model, using
%a fully parameterized bandwidth matrix for the incidence kernel, or both.  
We use a seasonal autoregressive integrated moving average (SARIMA) model for
the log-transformed incidence measure as a baseline to compare our methods to.  
We obtained the final model fits using the {\tt auto.arima} function in {\tt
R}'s {\tt forecast} package\cite{hyndmanRForecastPackage}; this function uses a stepwise
procedure to determine the terms to include in the model.
This procedure resulted in a
<<ILISarimaModelFitSummary, echo = FALSE, results = "asis">>=
ili_sarima_fit <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/estimation-results/sarima-fit.rds")
temp <- capture.output(summary(ili_sarima_fit)) 
cat(paste0("SARIMA(", substr(temp[2], 7, 15), as.integer(substr(temp[2], 16,16)) + 1, substr(temp[2], 17, 18), ")$_{52}$"))
@
model for the influenza data and a 
<<DengueSarimaModelFitSummary, echo = FALSE, results = "asis">>=
dengue_sarima_fit <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/dengue_sj/estimation-results/sarima-fit.rds")
temp <- capture.output(summary(dengue_sarima_fit)) 
cat(paste0("SARIMA(", substr(temp[2], 7, 15), as.integer(substr(temp[2], 16, 16)) + 1, substr(temp[2], 17, 18), ")$_{52}$"))
@
model for the dengue data.  Details of the SARIMA model specification and
estimation procedure are in the supplement.

We begin with a discussion of predictive distributions for incidence
at individual time points.  Figure~\ref{fig:DengueRibbonsPredictions} displays
the median and 95\% interval limits for the predictive distributions obtained 
at prediction horizons of $1$, $6$, or $26$ weeks from SARIMA and from the KCDE
specification with a fully parameterized bandwidth matrix and a periodic kernel component.
For predictions of dengue fever incidence, at a prediction horizon of one week
the point predictions from SARIMA and KCDE are similar, but the distribution from KCDE is
much more concentrated around its center.  Both methods struggle with larger
prediction horizons, but it appears that the SARIMA model has more
difficulty with aligning the predictive distribution with the
season's peak, particularly in the two seasons with higher incidence.
For the predictions of influenza incidence, which exhibits more regular
seasonality, there is much less of a noticeable distinction between the
predictions given by the two methods.  Throughout, the point predictions and intervals are similar.


%In our first example, we apply the method for prediction of
%influenza with prediction horizons of 1 through 4 weeks.  Data on influenza
%incidence are available through {\tt R}'s {\tt cdcfluview} package.  Here we
%create a data set with a nationally aggregated measure of flu incidence
%
%
%There are several methods that we could employ to handle these missing data:
%\begin{enumerate}
%\item Impute the missing values.  They are all in the low season, so this should be relatively easy to do.
%\item Drop all data up through the last NA.
%\item Use the data that are available.
%\end{enumerate}
%Of these approaches, the first is probably preferred.  The concern with the second
%is that we are not making use of all of the available data.  The potential concern with the
%third is that in the data used in estimation, there will be more examples of prediction of values in the high season
%using values in the high season and middle of the season than of prediction of values in the high season using values in the low season.
%This could potentially affect our inference.  However, we do not expect this effect to be large,
%so we proceed with this option for the purposes of this example.

%We also plot histograms of the observed total cases on the original scale and on the log scale.
%
%<<FluDataHistogramPlotTotalCases, echo = FALSE>>=
%hist_df <- rbind(
%	data.frame(value = ili_national$weighted_ili,
%    	variable = "Weighted ILI"),
%    data.frame(value = log(ili_national$weighted_ili),
%    	variable = "log(Weighted ILI)")
%)
%
%ggplot(aes(x = value), data = hist_df) +
%    geom_histogram() +
%    facet_wrap( ~ variable, ncol = 2) +
%    xlab("Weighted ILI") +
%    theme_bw()
%@
%
%These plots demonstrate that total cases follows an approximately log-normal
%distribution.  In the application below, we will consider modeling these data on
%both the original scale and the log scale.  Intuitively, since we are using a
%kernel that is obtained from a Gaussian, modeling the data on the log scale
%should yield better performance.  On the other hand, the performance gain may be
%negligible if we have enough data.

%Finally, we plot the autocorrelation function:
%
%<<FluDataACFPlotTotalCases, echo = FALSE>>=
%last_na_ind <- max(which(is.na(ili_national$weighted_ili)))
%non_na_inds <- seq(from = last_na_ind + 1, to=nrow(ili_national))
%acf(ili_national$weighted_ili[non_na_inds],
%  lag.max = 52 * 4)
%@
%
%This plot illustrates the annual periodicity that was also visible in the
%initial data plot above.  There is no apparent evidence of longer term annual
%cycles.  We therefore include a periodic kernel acting on the time index with a
%period of 52.2 weeks (the length of the period is motivated by the fact that
%in our data, there is a year with 53 weeks once every 5 or 6 years).


%<<FluDataKernelComponentsSetup, echo = TRUE>>=
%## Definitions of kernel components.  A couple of notes:
%##   1) In the current implementation, it is required that separate kernel
%##      components be used for lagged (predictive) variables and for leading
%##      (prediction target) variables.
%##   2) The current syntax is verbose; in a future version of the package,
%##      convenience functions may be provided.
%
%## Define kernel components -- 3 pieces:
%##   1) Periodic kernel acting on time index
%##   2) pdtmvn kernel acting on lagged total cases (predictive) -- all continuous
%##   3) pdtmvn kernel acting on lead total cases (prediction target) -- all continuous
%kernel_components <- list(
%    list(
%        vars_and_offsets = data.frame(var_name = "time_index",
%            offset_value = 0L,
%            offset_type = "lag",
%            combined_name = "time_index_lag0",
%            stringsAsFactors = FALSE),
%        kernel_fn = periodic_kernel,
%        theta_fixed = list(period=pi / 52.2),
%        theta_est = list("bw"),
%        initialize_kernel_params_fn = initialize_params_periodic_kernel,
%        initialize_kernel_params_args = NULL,
%        vectorize_kernel_params_fn = vectorize_params_periodic_kernel,
%        vectorize_kernel_params_args = NULL,
%        update_theta_from_vectorized_theta_est_fn = update_theta_from_vectorized_theta_est_periodic_kernel,
%        update_theta_from_vectorized_theta_est_args = NULL
%    ),
%    list(
%        vars_and_offsets = data.frame(var_name = "weighted_ili",
%            offset_value = 1L,
%            offset_type = "horizon",
%            combined_name = "time_index_horizon1",
%            stringsAsFactors = FALSE),
%        kernel_fn = pdtmvn_kernel,
%        rkernel_fn = rpdtmvn_kernel,
%        theta_fixed = list(
%            parameterization = "bw-diagonalized-est-eigenvalues",
%            continuous_vars = "weighted_ili_horizon1",
%            discrete_vars = NULL,
%            discrete_var_range_fns = NULL,
%            lower = -Inf,
%            upper = Inf
%        ),
%        theta_est = list("bw"),
%        initialize_kernel_params_fn = initialize_params_pdtmvn_kernel,
%        initialize_kernel_params_args = NULL,
%        vectorize_kernel_params_fn = vectorize_params_pdtmvn_kernel,
%        vectorize_kernel_params_args = NULL,
%        update_theta_from_vectorized_theta_est_fn = update_theta_from_vectorized_theta_est_pdtmvn_kernel,
%        update_theta_from_vectorized_theta_est_args = NULL
%    ))#,
%    list(
%        vars_and_lags = vars_and_lags[3:5, ],
%        kernel_fn = pdtmvn_kernel,
%        rkernel_fn = rpdtmvn_kernel,
%        theta_fixed = NULL,
%        theta_est = list("bw"),
%        initialize_kernel_params_fn = initialize_params_pdtmvn_kernel,
%        initialize_kernel_params_args = list(
%            continuous_vars = vars_and_lags$combined_name[3:4],
%            discrete_vars = vars_and_lags$combined_name[5],
%            discrete_var_range_fns = list(
%                c_lag2 = list(a = pdtmvn::floor_x_minus_1, b = floor, in_range = pdtmvn::equals_integer, discretizer = round_up_.5))
%        ),
%        vectorize_theta_est_fn = vectorize_params_pdtmvn_kernel,
%        vectorize_theta_est_args = NULL,
%        update_theta_from_vectorized_theta_est_fn = update_theta_from_vectorized_theta_est_pdtmvn_kernel,
%        update_theta_from_vectorized_theta_est_args = list(
%            parameterization = "bw-diagonalized-est-eigenvalues"
%        )
%    ))
%@

<<DengueDataMergePredictionResults, echo = FALSE>>=
dengue_prediction_results_sarima <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/dengue_sj/prediction-results/sarima-predictions.rds")
dengue_prediction_results_kcde <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/dengue_sj/prediction-results/kcde-predictions.rds")
dengue_prediction_results_kcde$model <- "KCDE"
dengue_prediction_results <- rbind.fill(dengue_prediction_results_sarima[!is.na(dengue_prediction_results_sarima$log_score), ],
    dengue_prediction_results_kcde)
dengue_prediction_results$AE <- unlist(dengue_prediction_results$AE)
     
dengue_prediction_results$full_model_descriptor <- paste0(dengue_prediction_results$model,
    "-seasonal_lag_", dengue_prediction_results$max_seasonal_lag,
#    "-filtering_", dengue_prediction_results$filtering,
    "-differencing_", dengue_prediction_results$differencing,
    "-periodic_", dengue_prediction_results$seasonality,
    "-bw_", dengue_prediction_results$bw_parameterization)

dengue_prediction_log_score_diffs_from_sarima_wide <- dengue_prediction_results %>%
    select(full_model_descriptor, prediction_time, prediction_horizon, log_score) %>%
    spread(full_model_descriptor, log_score)

dengue_prediction_log_score_diffs_from_sarima_wide[, unique(dengue_prediction_results$full_model_descriptor)] <-
    dengue_prediction_log_score_diffs_from_sarima_wide[, unique(dengue_prediction_results$full_model_descriptor)] -
    dengue_prediction_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]

dengue_prediction_log_score_diffs_from_sarima_long <- dengue_prediction_log_score_diffs_from_sarima_wide %>%
    gather_("model", "log_score_difference", unique(dengue_prediction_results$full_model_descriptor)) %>%
    mutate(
        seasonal_lag = grepl("seasonal_lag_1", model),
        differencing = grepl("differencing_TRUE", model),
        periodic = grepl("periodic_TRUE", model),
        bw_full = grepl("bw_full", model)
    )
dengue_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null KCDE"
dengue_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    dengue_prediction_log_score_diffs_from_sarima_long$periodic & !dengue_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic KCDE"
dengue_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    !dengue_prediction_log_score_diffs_from_sarima_long$periodic & dengue_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Full Bandwidth KCDE"
dengue_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    dengue_prediction_log_score_diffs_from_sarima_long$periodic & dengue_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic, Full Bandwidth KCDE"
dengue_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
    factor(dengue_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor,
        levels = c("Null KCDE", "Full Bandwidth KCDE", "Periodic KCDE", "Periodic, Full Bandwidth KCDE"))
@

<<FluDataMergePredictionResults, echo = FALSE>>=
ili_prediction_results_sarima <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/prediction-results/sarima-predictions.rds")
ili_prediction_results_kcde <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/prediction-results/kcde-predictions.rds")
ili_prediction_results_kcde$model <- "KCDE"
ili_prediction_results <- rbind.fill(ili_prediction_results_sarima[!is.na(ili_prediction_results_sarima$log_score), ],
    ili_prediction_results_kcde)
ili_prediction_results$AE <- unlist(ili_prediction_results$AE)

ili_prediction_results$full_model_descriptor <- paste0(ili_prediction_results$model,
    "-seasonal_lag_", ili_prediction_results$max_seasonal_lag,
#    "-filtering_", ili_prediction_results$filtering,
    "-differencing_", ili_prediction_results$differencing,
    "-periodic_", ili_prediction_results$seasonality,
    "-bw_", ili_prediction_results$bw_parameterization)

ili_prediction_log_score_diffs_from_sarima_wide <- ili_prediction_results %>%
    select(full_model_descriptor, prediction_time, prediction_horizon, log_score) %>%
    spread(full_model_descriptor, log_score)

ili_prediction_log_score_diffs_from_sarima_wide[, unique(ili_prediction_results$full_model_descriptor)] <-
    ili_prediction_log_score_diffs_from_sarima_wide[, unique(ili_prediction_results$full_model_descriptor)] -
    ili_prediction_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]

ili_prediction_log_score_diffs_from_sarima_long <- ili_prediction_log_score_diffs_from_sarima_wide %>%
    gather_("model", "log_score_difference", unique(ili_prediction_results$full_model_descriptor)) %>%
    mutate(
        seasonal_lag = grepl("seasonal_lag_1", model),
        differencing = grepl("differencing_TRUE", model),
        periodic = grepl("periodic_TRUE", model),
        bw_full = grepl("bw_full", model)
    )
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null KCDE"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_prediction_log_score_diffs_from_sarima_long$periodic & !ili_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic KCDE"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    !ili_prediction_log_score_diffs_from_sarima_long$periodic & ili_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Full Bandwidth KCDE"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_prediction_log_score_diffs_from_sarima_long$periodic & ili_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic, Full Bandwidth KCDE"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
    factor(ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor,
        levels = c("Null KCDE", "Full Bandwidth KCDE", "Periodic KCDE", "Periodic, Full Bandwidth KCDE"))
@



\begin{figure}
\caption{Plots of point and interval predictions from SARIMA and the KCDE
specification with a fully parameterized bandwidth and periodic kernel
component.}
\label{fig:DengueRibbonsPredictions} %fig.height = 4.3
<<DengueDataRibbonsPredictionPlot95Intervals, echo = FALSE, fig.height = 8.6>>=
#color_palette <- c("#E69F00", "#0072B2")
color_palette <- c("#D55E00", "#0072B2")

dengue_ribbons_df <- dengue_prediction_results %>%
    select(prediction_time,
        prediction_horizon,
        full_model_descriptor,
        model,
        interval_pred_lb_95:interval_pred_ub_50) %>%
    gather("bound_type", "predictive_value", interval_pred_lb_95:interval_pred_ub_50) %>%
    mutate(interval_type = ifelse(grepl("50", bound_type), "50", "95"),
        bound_type = ifelse(grepl("lb", bound_type), "lower", "upper")) %>%
    spread(bound_type, predictive_value)

phs_used <- c(1, 6, 26)
models_used <- c("SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
#models_used <- c("SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
#    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
pi_type <- "95"
#pi_type <- "50"

p_dengue <- ggplot() +
    geom_ribbon(aes(x = prediction_time, ymin = lower, ymax = upper, colour = model, fill = model, alpha = model),
#        alpha = 0.3,
        size = 0,
        data = dengue_ribbons_df[dengue_ribbons_df$prediction_horizon %in% phs_used &
                dengue_ribbons_df$full_model_descriptor %in% models_used &
                dengue_ribbons_df$interval_type == pi_type, ]) +
    geom_line(aes(x = time, y = total_cases), data = dengue_sj[dengue_sj$season %in% paste0(2009:2012, "/", 2010:2013), ]) +
#    geom_point(aes(x = time, y = total_cases), data = dengue_sj[dengue_sj$year %in% 2010:2014, ]) +
    geom_line(aes(x = prediction_time, y = pt_pred, colour = model, linetype = model),
        size = 1,
        data = dengue_prediction_results[dengue_prediction_results$prediction_horizon %in% phs_used &
                dengue_prediction_results$full_model_descriptor %in% models_used, ]) +
    scale_alpha_discrete("Model",
#        labels = c("50 Percent", "95 Percent"),
        limits = c("KCDE", "SARIMA"),
        range = c(0.45, 0.2)) +
#    scale_fill_manual("Model", values = c("#0072B2", "#E69F00")) +
#    scale_colour_manual("Model", values = c("#0072B2", "#E69F00")) +
    scale_fill_manual("Model", values = color_palette) +
    scale_colour_manual("Model", values = color_palette) +
    scale_linetype("Model") +
    facet_wrap( ~ prediction_horizon, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Prediction Horizon = ", labels))
            })) +
    xlab("Prediction Time") +
    ylab("Reported Cases") +
    ggtitle("(a) Point and 95% Interval Predictions, Dengue Fever") +
#    scale_y_log10() +
    theme_bw(base_size = 11)

ili_ribbons_df <- ili_prediction_results %>%
    select(prediction_time,
        prediction_horizon,
        full_model_descriptor,
        model,
        interval_pred_lb_95:interval_pred_ub_50) %>%
    gather("bound_type", "predictive_value", interval_pred_lb_95:interval_pred_ub_50) %>%
    mutate(interval_type = ifelse(grepl("50", bound_type), "50", "95"),
        bound_type = ifelse(grepl("lb", bound_type), "lower", "upper")) %>%
    spread(bound_type, predictive_value)

#phs_used <- c(1, 6, 13, 26)
models_used <- c("SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")

p_ili <- ggplot() +
    geom_ribbon(aes(x = prediction_time, ymin = lower, ymax = upper, colour = model, fill = model, alpha = model),
#        alpha = 0.3,
        size = 0,
        data = ili_ribbons_df[ili_ribbons_df$prediction_horizon %in% phs_used &
                ili_ribbons_df$full_model_descriptor %in% models_used &
                ili_ribbons_df$interval_type == pi_type, ]) +
    geom_line(aes(x = time, y = weighted_ili), data = ili_national[ili_national$year %in% 2011:2014, ]) +
#    geom_point(aes(x = time, y = weighted_ili), data = ili_national[ili_national$year %in% 2010:2014, ]) +
    geom_line(aes(x = prediction_time, y = pt_pred, colour = model, linetype = model),
        size = 1,
        data = ili_prediction_results[ili_prediction_results$prediction_horizon %in% phs_used &
                ili_prediction_results$full_model_descriptor %in% models_used, ]) +
    scale_alpha_discrete("Model",
#        labels = c("50 Percent", "95 Percent"),
        limits = c("KCDE", "SARIMA"),
        range = c(0.45, 0.2)) +
#    scale_fill_manual("Model", values = c("#0072B2", "#E69F00")) +
#    scale_colour_manual("Model", values = c("#0072B2", "#E69F00")) +
    scale_fill_manual("Model", values = color_palette) +
    scale_colour_manual("Model", values = color_palette) +
    scale_linetype("Model") +
    facet_wrap( ~ prediction_horizon, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Prediction Horizon = ", labels))
            })) +
    xlab("Prediction Time") +
    ylab("Weighted Influenza-like Illness") +
    ggtitle("(b) Point and 95% Interval Predictions, Influenza") +
#    ggtitle("Point and 95% Interval Predictions") +
#    scale_y_log10() +
    theme_bw(base_size = 11)

grid.newpage()
#pushViewport(viewport(layout = grid.layout(nrow = 1, ncol = 2,
#            heights = unit(c(1), c("null")),
#            widths = unit(c(1, 1), c("null", "null")))))
#print(p_dengue, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
#print(p_ili, vp = viewport(layout.pos.row = 1, layout.pos.col = 2))
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 1,
            heights = unit(c(1, 1), c("null", "null")),
            widths = unit(c(1), c("null")))))
print(p_dengue, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(p_ili, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
@
\end{figure}

Figure~\ref{fig:AggregatedFluResultsBoxPlots} offers a more quantitative summary
of these results in terms of log scores.  In the
application to predicting dengue fever, the KCDE specifications including a
periodic kernel component had slightly larger log scores than the SARIMA model
on average, with many outlying cases where KCDE did much better than SARIMA.
For the specifications without the periodic kernel component, the median
performance was similar to the SARIMA model, but again there were outlying
cases where KCDE did much better than SARIMA.
Figure~\ref{fig:AggregatedFluResultsBoxPlots} (b) shows that KCDE particularly
outperformed SARIMA in its predictions for times of high incidence near the season peaks.
In weeks with fewer than 93 reported cases (roughly one third of the maximum
weekly case count in the testing period), the average log score difference
between the predictions from the Periodic, Full Bandwidth KCDE Model and the
SARIMA model was about 0.25 with a standard deviation of 0.73.  In weeks with
more than 184 reported cases, in the upper third, the mean difference in log
scores was about 1.59 with a standard deviation of 1.6.  Translating to a
probability scale, in these periods of high incidence the predictive
distributions from KCDE assigned about 5 times as much probability to the
observed outcome as the predictive distributions from SARIMA on average, with
outlying cases where KCDE assigned up to about 450 times as much probability to
the realized outcome.

%% Code to get the numbers in the paragraph above
%lower_cutoff <- max(dengue_prediction_log_score_diffs_from_sarima_long_test$total_cases) / 3
%upper_cutoff <- 2 * lower_cutoff
%
%temp <- dengue_prediction_log_score_diffs_from_sarima_long_test[
%    dengue_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full" &
%        dengue_prediction_log_score_diffs_from_sarima_long_test$total_cases <= lower_cutoff,
%    "log_score_difference"]
%
%mean(temp)
%sd(temp)
%summary(temp)
%
%temp <- dengue_prediction_log_score_diffs_from_sarima_long_test[
%    dengue_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full" &
%        dengue_prediction_log_score_diffs_from_sarima_long_test$total_cases >= upper_cutoff,
%    "log_score_difference"]
%
%mean(temp)
%sd(temp)
%summary(temp)


In the application to predicting influenza, the KCDE specifications including a
periodic kernel did about as well as the SARIMA model, while the median
performance of the specifications without a periodic kernel was slightly worse
than SARIMA.  In both applications, including the periodic kernel component led
to improved predictions; this can be seen directly in Figure *** of the
supplement. Using the fully parameterized bandwidth matrix generally had little
impact on the quality of the predictive distributions as measured by the log score.

%  For that data set, the average difference in log scores
% is slightly positive (indicating slightly improved performance relative to SARIMA)
%for the KCDE specification with both a periodic kernel component and a fully
%parameterized bandwidth matrix, but is slightly negative for the other KCDE
%specifications.

%% Relevant code to verify medians
%models_used <- unique(ili_prediction_results$full_model_descriptor[
%    !ili_prediction_results$differencing & !(ili_prediction_results$max_seasonal_lag == 1)])
%inds <- which(ili_prediction_log_score_diffs_from_sarima_long$model %in% models_used)
%tapply(ili_prediction_log_score_diffs_from_sarima_long$log_score_difference[inds],
%    ili_prediction_log_score_diffs_from_sarima_long$model[inds],
%    median)
%tapply(ili_prediction_log_score_diffs_from_sarima_long$log_score_difference[inds],
%    ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[inds],
%    mean)
%tapply(ili_prediction_log_score_diffs_from_sarima_long$log_score_difference[inds],
%    ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[inds],
%    min)
%ili_prediction_results


%% Relevant code to verify medians
%inds <- which(combined_contrast_bw_full$data_set == "Influenza")
%tapply(combined_contrast_bw_full$contrast_value[inds],
%    factor(combined_contrast_bw_full$fixed_values[inds]),
%    median)
%tapply(combined_contrast_bw_full$contrast_value[inds],
%    factor(combined_contrast_bw_full$fixed_values[inds]),
%    mean)

\begin{figure}
\caption{Differences in log scores for the weekly predictive distributions
obtained from KCDE specifications and SARIMA.  For reference, a log score
difference of 2.3 (4.6) indicates that the predictive density from KCDE was about 10 (100) times as
large as the predictive density from SARIMA at the realized outcome.  In Panel
(a) we summarize the results across all combinations of prediction horizon and
prediction time in the test period.  In Panel (b) we display more detailed
results for just the application to predicting dengue fever and the
Periodic, Full Bandwidth KCDE specification.  Each point corresponds to a unique
combination of prediction target week and prediction horizon.
}
\label{fig:AggregatedFluResultsBoxPlots}
<<FluDataResultsAggregatedBoxplots, echo = FALSE, fig.height = 7.8>>=
models_used <- unique(ili_prediction_results$full_model_descriptor[
    !ili_prediction_results$differencing & !(ili_prediction_results$max_seasonal_lag == 1)])

dengue_prediction_log_score_diffs_from_sarima_long$data_set <- "Dengue"
ili_prediction_log_score_diffs_from_sarima_long$data_set <- "Influenza"
combined_prediction_log_score_diffs_from_sarima_long <-
    rbind(dengue_prediction_log_score_diffs_from_sarima_long,
        ili_prediction_log_score_diffs_from_sarima_long[
            !(ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor == "Periodic, Full Bandwidth KCDE" &
                    ili_prediction_log_score_diffs_from_sarima_long$prediction_horizon == 50L),])

color_palette <- c("#D55E00", "#56B4E9")

boxplot_sarima_contrasts <- ggplot() +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = data_set),
        data = combined_prediction_log_score_diffs_from_sarima_long[combined_prediction_log_score_diffs_from_sarima_long$model %in% models_used, ]) +
#        data = ili_prediction_log_score_diffs_from_sarima_long[ili_prediction_log_score_diffs_from_sarima_long$model %in% models_used, ]) +
#    ylim(c(-4, 4)) +
    scale_colour_manual("Data Set", values = color_palette) +
    scale_x_discrete(labels = c("Periodic, Full Bandwidth KCDE" = "Periodic, Full Bandwidth\nKCDE")) +
    ggtitle("(a) Comparison of KCDE with SARIMA") +
#    xlab("Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score KCDE -\nLog Score SARIMA") +
    theme_bw(base_size = 11)# +
#    theme(axis.text.x=element_text(angle = -90, hjust = 0))



#ili_contrast_periodic_kernel <- ili_prediction_log_score_diffs_from_sarima_long %>%
#    filter(model %in% models_used) %>%
#    select_("prediction_time", "prediction_horizon", "log_score_difference",
#        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
#    spread_("periodic",
#        "log_score_difference") %>%
#    mutate(
#        contrast_value = `TRUE` - `FALSE`)
#ili_contrast_periodic_kernel$fixed_values <- "Null Model"
#ili_contrast_periodic_kernel$fixed_values[ili_contrast_periodic_kernel$bw_full] <-
#    "Full Bandwidth"
#ili_contrast_periodic_kernel$fixed_values <-
#    factor(ili_contrast_periodic_kernel$fixed_values,
#        levels = c("Null Model", "Full Bandwidth"))

combined_contrast_periodic_kernel <- combined_prediction_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("prediction_time", "prediction_horizon", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full", "data_set") %>%
    spread_("periodic",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
combined_contrast_periodic_kernel$fixed_values <- "Null KCDE"
combined_contrast_periodic_kernel$fixed_values[combined_contrast_periodic_kernel$bw_full] <-
    "Full Bandwidth KCDE"
combined_contrast_periodic_kernel$fixed_values <-
    factor(combined_contrast_periodic_kernel$fixed_values,
        levels = c("Null KCDE", "Full Bandwidth KCDE"))


#boxplot_periodic_kernel_contrasts <- ggplot(ili_contrast_periodic_kernel) +
boxplot_periodic_kernel_contrasts <- ggplot(combined_contrast_periodic_kernel) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = data_set)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    scale_colour_discrete("Data Set") +
    ggtitle("(b) Effect of Adding Periodic Kernel to Model") +
#    xlab("Base Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
    theme_bw(base_size = 11)



#ili_contrast_bw_full <- ili_prediction_log_score_diffs_from_sarima_long %>%
#    filter(model %in% models_used) %>%
#    select_("prediction_time", "prediction_horizon", "log_score_difference",
#        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
#    spread_("bw_full",
#        "log_score_difference") %>%
#    mutate(
#        contrast_value = `TRUE` - `FALSE`)
#ili_contrast_bw_full$fixed_values <- "Null Model"
#ili_contrast_bw_full$fixed_values[ili_contrast_bw_full$periodic] <-
#    "Periodic Kernel"
#ili_contrast_bw_full$fixed_values <-
#    factor(ili_contrast_bw_full$fixed_values,
#        levels = c("Null Model", "Periodic Kernel"))

combined_contrast_bw_full <- combined_prediction_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("prediction_time", "prediction_horizon", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full", "data_set") %>%
    spread_("bw_full",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
combined_contrast_bw_full$fixed_values <- "Null KCDE"
combined_contrast_bw_full$fixed_values[combined_contrast_bw_full$periodic] <-
    "Periodic KCDE"
combined_contrast_bw_full$fixed_values <-
    factor(combined_contrast_bw_full$fixed_values,
        levels = c("Null KCDE", "Periodic KCDE"))

#boxplot_bw_full_contrasts <- ggplot(ili_contrast_bw_full) +
boxplot_bw_full_contrasts <- ggplot(combined_contrast_bw_full) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = data_set)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    scale_colour_discrete("Data Set") +
    ggtitle("(c) Effect of Adding Fully Parameterized BW to Model") +
#    xlab("Base Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
    theme_bw(base_size = 11)


temp <- dengue_sj[, c("time", "total_cases", "season")]
colnames(temp) <- c("prediction_time", "total_cases", "season")

dengue_prediction_log_score_diffs_from_sarima_long_test <-
    dengue_prediction_log_score_diffs_from_sarima_long %>%
    left_join(temp, by = "prediction_time")


scatterplot_dengue_by_obs_cases <- ggplot() +
    geom_point(aes(x = total_cases, y = log_score_difference),
        data = dengue_prediction_log_score_diffs_from_sarima_long_test[dengue_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full", ]) +
    geom_hline(yintercept = 0) +
    geom_smooth(aes(x = total_cases, y = log_score_difference),
        method = lm,
        colour = "#56B4E9",
        data = dengue_prediction_log_score_diffs_from_sarima_long_test[dengue_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full", ]) +
    facet_wrap( ~ season, ncol = 1) +
    xlab("Reported Dengue Cases in Prediction Target Week") +
    ylab("Log Score Difference") +
    ggtitle("(b) Log Score Difference from SARIMA vs. Reported Dengue Fever Cases\nPeriodic, Full Bandwidth KCDE Model") +
    theme_bw(base_size = 11)

grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 1,
            heights = unit(c(1, 3), c("null", "null")),
            widths = unit(c(1), c("null")))))
print(boxplot_sarima_contrasts, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(scatterplot_dengue_by_obs_cases, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
#print(boxplot_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
#print(boxplot_bw_full_contrasts, vp = viewport(layout.pos.row = 3, layout.pos.col = 1))






#temp <- ili_national[, c("time", "weighted_ili", "season")]
#colnames(temp) <- c("prediction_time", "weighted_ili", "season")
#
#ili_prediction_log_score_diffs_from_sarima_long_test <-
#    ili_prediction_log_score_diffs_from_sarima_long %>%
#    left_join(temp, by = "prediction_time")
#
#scatterplot_ili_by_obs_cases <- ggplot() +
#    geom_point(aes(x = weighted_ili, y = log_score_difference),
#        data = ili_prediction_log_score_diffs_from_sarima_long_test[ili_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full", ]) +
#    geom_hline(yintercept = 0) +
#    geom_smooth(aes(x = weighted_ili, y = log_score_difference),
#        method = lm,
#        data = ili_prediction_log_score_diffs_from_sarima_long_test[ili_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full", ]) +
#    facet_wrap( ~ season, ncol = 1) +
#    xlab("Observed Total Cases in Prediction Target Week") +
#    ylab("Log Score Difference") +
#    ggtitle("(b) Log Score Difference from SARIMA vs. Observed Cases\nKCDE Specification with Periodic Kernel and Full Bandwidth") +
#    theme_bw()





#ili_prediction_log_score_diffs_from_sarima_long$fixed_values <-
#    as.character(ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor)
#ili_prediction_log_score_diffs_from_sarima_long$contrast_value <-
#    ili_prediction_log_score_diffs_from_sarima_long$log_score_difference
#ili_prediction_log_score_diffs_from_sarima_long$contrast_type <- "Difference from SARIMA"
#ili_contrast_periodic_kernel$contrast_type <- "Effect of Adding Periodic Kernel"
#ili_contrast_bw_full$contrast_type <- "Effect of Adding Full Bandwidth"
#
#ili_contrasts_merged <- rbind.fill(
#    ili_prediction_log_score_diffs_from_sarima_long[ili_prediction_log_score_diffs_from_sarima_long$model %in% models_used, ],
#    ili_contrast_periodic_kernel,
#    ili_contrast_bw_full)
#
#ggplot(ili_contrasts_merged) +
#    geom_hline(yintercept = 0) +
#    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value)) +
#    facet_wrap( ~ contrast_type, ncol = 1) +
##    ggtitle("Effect of Adding Fully Parameterized BW to Model") +
#    xlab("") +
#    ylab("Log Score Difference") +
#    theme_bw()


#temp <- dengue_sj[, c("time", "total_cases", "season")]
#colnames(temp) <- c("prediction_time", "total_cases", "season")
#
#dengue_prediction_log_score_diffs_from_sarima_long_test <-
#    dengue_prediction_log_score_diffs_from_sarima_long %>%
#    left_join(temp, by = "prediction_time")
#
#ggplot() +
#    geom_point(aes(x = total_cases, y = log_score_difference),
#        data = dengue_prediction_log_score_diffs_from_sarima_long_test) +
#    facet_wrap( ~ model, ncol = 1) +
#    theme_bw()
#
#ggplot() +
#    geom_point(aes(x = total_cases, y = log_score_difference),
#        data = dengue_prediction_log_score_diffs_from_sarima_long_test[dengue_prediction_log_score_diffs_from_sarima_long_test$model == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full", ]) +
#    facet_wrap( ~ season, ncol = 1) +
#    theme_bw()

@
\end{figure}




%\begin{figure}
%\caption{Plots of point and interval predictions from SARIMA and KCDE.}
%\label{fig:FluRibbonsPredictions}
%<<FluDataRibbonsPredictionPlot95Intervals, echo = FALSE>>=
%@
%\end{figure}





Figure~\ref{fig:CombinedPeakWeekIncidencePredictionLogScores} displays the log
score of the predictive distributions for incidence in the peak week
obtained from SARIMA and KCDE models over the course of each season in the test data sets, and
Figure *** in the supplement displays log scores for predictions of
peak week timing.  For both of these prediction targets, there is no consistent
pattern of KCDE either outperforming or underperforming relative to SARIMA.

%
%If we consider the three seasons in the Influenza data set, KCDE tended to
%outperform SARIMA for predicting peak week timing in the 2011/2012 season, but
%underperformed relative to SARIMA in the 2012/2013 and 2013/2014 seasons.  It is
%difficult to extrapolate from three test seasons, but a look at the data reveals two interesting factors related
%to historical timing of season peaks that may explain differences in the
%relative performance of the models in these seasons.
%First, the 2011/2012 season had the latest peak week of any season in the data
%set.  Second, there is a consistent ``mini-peak'' in reported incidence for
%influenza at Christmas week, which we illustrate in Figure *** in the supplemental materials.  In the
%2012/2013 and 2013/2014 seasons, this ``Christmas effect'' coincided with the season peak.
%The structure of the SARIMA model using seasonal differencing and seasonally
%lagged incidence allows that model to pick up on this Christmas effect, and the
%method scored well for those two seasons.  In the season when the peak
%occurred later than it had in the training data, KCDE outperformed SARIMA. 
%Overall, this points to SARIMA having picked up on a relevant feature of the
%data generating process that KCDE did not, but the predictive distributions from
%KCDE are generally concentrated in the right area and are broad enough to capture unusual
%events.



%We have plotted this distribution for 2012/2013 season
%in Figure ***; the distributions for all seasons are in the supplemental materials.  In that plot,
%we can see that from the start, the SARIMA model assigns high probability that
%the season peak will be during the week of Christmas as there was a local peak
%in Christmas week the prior season.  The KCDE model does not have this
%structure, and so does not pick up on the Christmas week effect.  Its predictive
%distribution for peak week timing is much smoother than the distribution from
%SARIMA.  In seasons where the peak occurred at Christmas week, this is a
%disadvantage for KCDE.  On the other hand, in the 2011/2012 season, the peak
%occurred much later.  In that season, KCDE put much larger probability on the
%peak week that was eventually realized than SARIMA did.

<<FluDataMergePeakWeekPredictionResults, echo = FALSE>>=
data_set <- "ili_national"
 
prediction_save_path <- file.path("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results",
    data_set,
    "prediction-results")

all_max_lags <- as.character(c(1L))
#all_max_seasonal_lags <- as.character(c(0L, 1L))
all_max_seasonal_lags <- as.character(c(0L))
all_filtering_values <- c("FALSE")
#all_differencing_values <- c("FALSE", "TRUE")
all_differencing_values <- c("FALSE")
all_seasonality_values <- c("FALSE", "TRUE")
all_bw_parameterizations <- c("diagonal", "full")

case_definitions <- expand.grid(
        data_set,
        all_max_lags,
        all_max_seasonal_lags,
        all_filtering_values,
        all_differencing_values,
        all_seasonality_values,
        all_bw_parameterizations,
        stringsAsFactors = FALSE) %>%
    `colnames<-`(c("data_set",
            "max_lag",
            "max_seasonal_lag",
            "filtering",
            "differencing",
            "seasonality",
            "bw_parameterization"))
 
ili_peak_week_results <- rbind.fill(
    c(
        list(
            readRDS(file.path(prediction_save_path,
                        paste0("peak-week-sarima-", data_set, ".rds"))) %>%
                mutate(model = "SARIMA")
        ),
        lapply(seq_len(nrow(case_definitions)), function(case_row_ind) {
                max_lag <- case_definitions$max_lag[case_row_ind]
                max_seasonal_lag <- case_definitions$max_seasonal_lag[case_row_ind]
                filtering <- case_definitions$filtering[case_row_ind]
                differencing <- case_definitions$differencing[case_row_ind]
                seasonality <- case_definitions$seasonality[case_row_ind]
                bw_parameterization <- case_definitions$bw_parameterization[case_row_ind]
                
                case_descriptor <- paste0(
                    data_set,
                    "-max_lag_", max_lag,
                    "-max_seasonal_lag_", max_seasonal_lag,
                    "-filtering_", filtering,
                    "-differencing_", differencing,
                    "-seasonality_", seasonality,
                    "-bw_parameterization_", bw_parameterization
                )
                
                readRDS(file.path(prediction_save_path,
                            paste0("peak-week-", case_descriptor, ".rds"))) %>%
                    mutate(model = "KCDE",
                        max_lag = max_lag,
                        max_seasonal_lag = max_seasonal_lag,
                        filtering = filtering,
                        differencing = differencing,
                        seasonality = seasonality,
                        bw_parameterization = bw_parameterization)
            })
    )
)

ili_peak_week_results$full_model_descriptor <- paste0(ili_peak_week_results$model,
    "-seasonal_lag_", ili_peak_week_results$max_seasonal_lag,
#    "-filtering_", ili_prediction_results$filtering,
    "-differencing_", ili_peak_week_results$differencing,
    "-periodic_", ili_peak_week_results$seasonality,
    "-bw_", ili_peak_week_results$bw_parameterization)

ili_peak_week_results$peak_week_log_score[ili_peak_week_results$peak_week_log_score < -50] <- -50
ili_peak_week_results$peak_height_log_score[ili_peak_week_results$peak_height_log_score < -50] <- -50

ili_peak_week_results$reduced_model_descriptor <- "Null KCDE"
ili_peak_week_results$reduced_model_descriptor[
    as.logical(ili_peak_week_results$seasonality) & !(ili_peak_week_results$bw_parameterization == "full")] <-
    "Periodic KCDE"
ili_peak_week_results$reduced_model_descriptor[
    !as.logical(ili_peak_week_results$seasonality) & (ili_peak_week_results$bw_parameterization == "full")] <-
    "Full Bandwidth KCDE"
ili_peak_week_results$reduced_model_descriptor[
    as.logical(ili_peak_week_results$seasonality) & (ili_peak_week_results$bw_parameterization == "full")] <-
    "Periodic, Full Bandwidth KCDE"
ili_peak_week_results$reduced_model_descriptor[
    ili_peak_week_results$model == "SARIMA"] <-
    "SARIMA"

num_analysis_time_season_values <- length(unique(ili_peak_week_results$analysis_time_season))
num_analysis_time_season_week_values <- length(unique(ili_peak_week_results$analysis_time_season_week))
ili_peak_week_results <- rbind.fill(ili_peak_week_results,
    data.frame(
        full_model_descriptor = rep("Equal Bin Probabilities", num_analysis_time_season_week_values * num_analysis_time_season_values),
        reduced_model_descriptor = rep("Equal Bin Probabilities", num_analysis_time_season_week_values * num_analysis_time_season_values),
        analysis_time_season = rep(unique(ili_peak_week_results$analysis_time_season), each = num_analysis_time_season_week_values),
        analysis_time_season_week = rep(unique(ili_peak_week_results$analysis_time_season_week), times = num_analysis_time_season_values),
        peak_week_log_score = rep(log(1/52), num_analysis_time_season_week_values * num_analysis_time_season_values),
        peak_height_log_score = rep(log(1/27), num_analysis_time_season_week_values * num_analysis_time_season_values)
    ))


ili_peak_week_results$reduced_model_descriptor <-
    factor(ili_peak_week_results$reduced_model_descriptor,
        levels = c("SARIMA", "Null KCDE", "Full Bandwidth KCDE", "Periodic KCDE",
            "Periodic, Full Bandwidth KCDE",
            "Equal Bin Probabilities"
        ))

#geom_hline(yintercept = log(1/31), colour = "grey", linetype = 2)

ili_peak_week_times <- data.frame(
    analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
    peak_week = sapply(unique(ili_peak_week_results$analysis_time_season),
        function(season_val) {
            max_incidence_in_season <-
                max(ili_national$weighted_ili[ili_national$season == season_val])
            return(ili_national$season_week[ili_national$season == season_val &
                        ili_national$weighted_ili == max_incidence_in_season])
        })
)

ili_peak_week_heights <- data.frame(
    analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
    peak_height = sapply(unique(ili_peak_week_results$analysis_time_season),
        function(season_val) {
            return(max(ili_national$weighted_ili[ili_national$season == season_val]))
        })
)
        
ili_peak_week_results$peak_week_log_score[ili_peak_week_results$peak_week_log_score == -50] <- NA
ili_peak_week_results$peak_height_log_score[ili_peak_week_results$peak_height_log_score == -50] <- NA
@


%\begin{figure}
%\caption{Differences in log scores for the predictive distributions for the peak
%week and incidence at the peak week among pairs of models across all analysis
%times in the test period.
%In panel (a) positive values indicate cases when KCDE outperformed SARIMA.  In panel
%(b) positive values indicate cases when the specification of KCDE with the
%periodic kernel outperformed the corresponding specification without the periodic kernel.
%In panel (c) positive values indicate cases when the specification of KCDE with
%a fully parameterized bandwidth outperformed the KCDE specification with a diagonal
%bandwidth matrix.  In the plot for peak week timing in panel (a), the log score
%differences are not displayed for one analysis time when none of the simulated
%trajectories from SARIMA peaked at the true peak week.  In that case, our
%monte carlo estimate of the difference in log scores is infinity.}
%\label{fig:FluPeakWeekPredictions}
%<<FluDataPeakWeekPredictionBoxPlots, echo = FALSE>>=
%ili_peak_week_times <- data.frame(
%    analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
%    peak_week = sapply(unique(ili_peak_week_results$analysis_time_season),
%        function(season_val) {
%            max_incidence_in_season <-
%                max(ili_national$weighted_ili[ili_national$season == season_val])
%            return(ili_national$season_week[ili_national$season == season_val &
%                        ili_national$weighted_ili == max_incidence_in_season])
%        })
%)
%
%ili_peak_week_heights <- data.frame(
%    analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
%    peak_height = sapply(unique(ili_peak_week_results$analysis_time_season),
%        function(season_val) {
%            return(max(ili_national$weighted_ili[ili_national$season == season_val]))
%        })
%)
%
%## Contrasts with SARIMA for peak week timing
%ili_peak_timing_log_score_diffs_from_sarima_wide <- ili_peak_week_results %>%
%    select(full_model_descriptor, analysis_time_season, analysis_time_season_week, peak_week_log_score) %>%
%    spread(full_model_descriptor, peak_week_log_score)
%
%ili_peak_timing_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] <-
%    ili_peak_timing_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] -
%    ili_peak_timing_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]
%
%ili_peak_timing_log_score_diffs_from_sarima_long <- ili_peak_timing_log_score_diffs_from_sarima_wide %>%
%    gather_("model", "log_score_difference", unique(ili_peak_week_results$full_model_descriptor)) %>%
%    mutate(
%        seasonal_lag = as.logical(grepl("seasonal_lag_1", model)),
%        differencing = as.logical(grepl("differencing_TRUE", model)),
%        periodic = as.logical(grepl("periodic_TRUE", model)),
%        bw_full = as.logical(grepl("bw_full", model))
%    )
%ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
%ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    ili_peak_timing_log_score_diffs_from_sarima_long$periodic & !ili_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel"
%ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    !ili_peak_timing_log_score_diffs_from_sarima_long$periodic & ili_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
%    "Full Bandwidth"
%ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    ili_peak_timing_log_score_diffs_from_sarima_long$periodic & ili_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel,\nFull Bandwidth"
%ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
%    factor(ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor,
%        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))
%
%ili_peak_timing_log_score_diffs_from_sarima_long$leq_peak_week <-
%    ili_peak_timing_log_score_diffs_from_sarima_long$analysis_time_season_week <=
%    ili_peak_week_times$peak_week[
%        sapply(ili_peak_timing_log_score_diffs_from_sarima_long$analysis_time_season,
%            function(season_val) which(ili_peak_week_times$analysis_time_season == season_val))]
%
%models_used <- unique(ili_peak_week_results$full_model_descriptor[
%        !as.logical(ili_peak_week_results$differencing) & !(ili_peak_week_results$max_seasonal_lag == 1)])
%
%boxplot_timing_sarima_contrasts <- ggplot() +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = leq_peak_week),
%        data = ili_peak_timing_log_score_diffs_from_sarima_long[
%            ili_peak_timing_log_score_diffs_from_sarima_long$model %in% models_used & 
%                ili_peak_timing_log_score_diffs_from_sarima_long$log_score_difference < 40, ]) +
%#    ylim(c(-4, 4)) +
%    ggtitle("Peak Week Timing") +
%#    xlab("Model") +
%    xlab("") +
%    ylab("Log Score Difference") +
%#    ylab("Log Score KCDE -\nLog Score SARIMA") +
%    theme_bw(base_size = 11)# +
%
%
%
%## Contrasts with SARIMA for peak week height
%ili_peak_height_log_score_diffs_from_sarima_wide <- ili_peak_week_results %>%
%    select(full_model_descriptor, analysis_time_season, analysis_time_season_week, peak_height_log_score) %>%
%    spread(full_model_descriptor, peak_height_log_score)
%
%ili_peak_height_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] <-
%    ili_peak_height_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] -
%    ili_peak_height_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]
%
%ili_peak_height_log_score_diffs_from_sarima_long <- ili_peak_height_log_score_diffs_from_sarima_wide %>%
%    gather_("model", "log_score_difference", unique(ili_peak_week_results$full_model_descriptor)) %>%
%    mutate(
%        seasonal_lag = as.logical(grepl("seasonal_lag_1", model)),
%        differencing = as.logical(grepl("differencing_TRUE", model)),
%        periodic = as.logical(grepl("periodic_TRUE", model)),
%        bw_full = as.logical(grepl("bw_full", model))
%    )
%ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
%ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    ili_peak_height_log_score_diffs_from_sarima_long$periodic & !ili_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel"
%ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    !ili_peak_height_log_score_diffs_from_sarima_long$periodic & ili_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
%    "Full Bandwidth"
%ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    ili_peak_height_log_score_diffs_from_sarima_long$periodic & ili_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel,\nFull Bandwidth"
%ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
%    factor(ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor,
%        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))
%
%ili_peak_height_log_score_diffs_from_sarima_long$leq_peak_week <-
%    ili_peak_height_log_score_diffs_from_sarima_long$analysis_time_season_week <=
%    ili_peak_week_times$peak_week[
%        sapply(ili_peak_height_log_score_diffs_from_sarima_long$analysis_time_season,
%            function(season_val) which(ili_peak_week_times$analysis_time_season == season_val))]
%
%models_used <- unique(ili_peak_week_results$full_model_descriptor[
%        !as.logical(ili_peak_week_results$differencing) & !(ili_peak_week_results$max_seasonal_lag == 1)])
%
%boxplot_height_sarima_contrasts <- ggplot() +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = leq_peak_week),
%        data = ili_peak_height_log_score_diffs_from_sarima_long[ili_peak_height_log_score_diffs_from_sarima_long$model %in% models_used, ]) +
%#    ylim(c(-4, 4)) +
%    ggtitle("Peak Week Incidence") +
%#    xlab("Model") +
%    xlab("") +
%    ylab("") +
%#    ylab("Log Score KCDE -\nLog Score SARIMA") +
%    theme_bw(base_size = 11)# +
%
%
%
%ili_timing_contrast_periodic_kernel <- ili_peak_timing_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("periodic",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%ili_timing_contrast_periodic_kernel$fixed_values <- "Null Model"
%ili_timing_contrast_periodic_kernel$fixed_values[ili_timing_contrast_periodic_kernel$bw_full] <-
%    "Full Bandwidth"
%ili_timing_contrast_periodic_kernel$fixed_values <-
%    factor(ili_timing_contrast_periodic_kernel$fixed_values,
%        levels = c("Null Model", "Full Bandwidth"))
%
%ili_timing_contrast_periodic_kernel$leq_peak_week <-
%    ili_timing_contrast_periodic_kernel$analysis_time_season_week <=
%    ili_peak_week_times$peak_week[
%        sapply(ili_timing_contrast_periodic_kernel$analysis_time_season,
%            function(season_val) which(ili_peak_week_times$analysis_time_season == season_val))]
%
%
%ili_height_contrast_periodic_kernel <- ili_peak_height_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("periodic",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%ili_height_contrast_periodic_kernel$fixed_values <- "Null Model"
%ili_height_contrast_periodic_kernel$fixed_values[ili_height_contrast_periodic_kernel$bw_full] <-
%    "Full Bandwidth"
%ili_height_contrast_periodic_kernel$fixed_values <-
%    factor(ili_height_contrast_periodic_kernel$fixed_values,
%        levels = c("Null Model", "Full Bandwidth"))
%
%ili_height_contrast_periodic_kernel$leq_peak_week <-
%    ili_height_contrast_periodic_kernel$analysis_time_season_week <=
%    ili_peak_week_times$peak_week[
%        sapply(ili_height_contrast_periodic_kernel$analysis_time_season,
%            function(season_val) which(ili_peak_week_times$analysis_time_season == season_val))]
%
%
%boxplot_timing_periodic_kernel_contrasts <- ggplot(ili_timing_contrast_periodic_kernel) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Timing") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("Log Score Difference") +
%#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
%    theme_bw(base_size = 11)
%
%
%boxplot_height_periodic_kernel_contrasts <- ggplot(ili_height_contrast_periodic_kernel) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Incidence") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("") +
%#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
%    theme_bw(base_size = 11)
%
%
%ili_timing_contrast_bw_full <- ili_peak_timing_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("bw_full",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%ili_timing_contrast_bw_full$fixed_values <- "Null Model"
%ili_timing_contrast_bw_full$fixed_values[ili_timing_contrast_bw_full$periodic] <-
%    "Periodic Kernel"
%ili_timing_contrast_bw_full$fixed_values <-
%    factor(ili_timing_contrast_bw_full$fixed_values,
%        levels = c("Null Model", "Periodic Kernel"))
%
%ili_timing_contrast_bw_full$leq_peak_week <-
%    ili_timing_contrast_bw_full$analysis_time_season_week <=
%    ili_peak_week_times$peak_week[
%        sapply(ili_timing_contrast_bw_full$analysis_time_season,
%            function(season_val) which(ili_peak_week_times$analysis_time_season == season_val))]
%
%
%ili_height_contrast_bw_full <- ili_peak_height_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("bw_full",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%ili_height_contrast_bw_full$fixed_values <- "Null Model"
%ili_height_contrast_bw_full$fixed_values[ili_height_contrast_bw_full$periodic] <-
%    "Periodic Kernel"
%ili_height_contrast_bw_full$fixed_values <-
%    factor(ili_height_contrast_bw_full$fixed_values,
%        levels = c("Null Model", "Periodic Kernel"))
%
%ili_height_contrast_bw_full$leq_peak_week <-
%    ili_height_contrast_bw_full$analysis_time_season_week <=
%    ili_peak_week_times$peak_week[
%        sapply(ili_height_contrast_bw_full$analysis_time_season,
%            function(season_val) which(ili_peak_week_times$analysis_time_season == season_val))]
%
%
%boxplot_timing_bw_full_contrasts <- ggplot(ili_timing_contrast_bw_full) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Timing") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("Log Score Difference") +
%#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
%    theme_bw(base_size = 11)
%
%boxplot_height_bw_full_contrasts <- ggplot(ili_height_contrast_bw_full) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Incidence") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("") +
%#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
%    theme_bw(base_size = 11)
%
%
%grid.newpage()
%pushViewport(viewport(layout =
%    grid.layout(nrow = 6, ncol = 2, heights = unit(rep(1, 6), rep(c("lines", "null"), times = 3)))))
%grid.text("(a) Comparison of KCDE with SARIMA",
%    gp = gpar(fontsize = 12),
%    vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
%print(boxplot_timing_sarima_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
%print(boxplot_height_sarima_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 2))
%grid.text("(b) Effect of Adding Periodic Kernel to Model",
%    gp = gpar(fontsize = 12),
%    vp = viewport(layout.pos.row = 3, layout.pos.col = 1:2))
%print(boxplot_timing_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 4, layout.pos.col = 1))
%print(boxplot_height_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 4, layout.pos.col = 2))
%grid.text("(c) Effect of Adding Fully Parameterized BW to Model",
%    gp = gpar(fontsize = 12),
%    vp = viewport(layout.pos.row = 5, layout.pos.col = 1:2))
%print(boxplot_timing_bw_full_contrasts, vp = viewport(layout.pos.row = 6, layout.pos.col = 1))
%print(boxplot_height_bw_full_contrasts, vp = viewport(layout.pos.row = 6, layout.pos.col = 2))
%@
%\end{figure}
%
%\begin{figure}
%\caption{Differences in log scores for the predictive distributions for the peak
%week and incidence at the peak week for Dengue among pairs of models across all
%analysis times in the test period.
%In panel (a) positive values indicate cases when KCDE outperformed SARIMA.  In panel
%(b) positive values indicate cases when the specification of KCDE with the
%periodic kernel outperformed the corresponding specification without the periodic kernel.
%In panel (c) positive values indicate cases when the specification of KCDE with
%a fully parameterized bandwidth outperformed the KCDE specification with a diagonal
%bandwidth matrix.  In the plot for peak week timing in panel (a), the log score
%differences are not displayed for one analysis time when none of the simulated
%trajectories from SARIMA peaked at the true peak week.  In that case, our
%monte carlo estimate of the difference in log scores is infinity.}
%\label{fig:DenguePeakWeekPredictions}
%<<DengueDataPeakWeekPredictionBoxPlots, echo = FALSE, dependson = c("DengueDataMergePeakWeekPredictionResults")>>=
%dengue_peak_week_times <- data.frame(
%    analysis_time_season = unique(dengue_peak_week_results$analysis_time_season),
%    peak_week = sapply(unique(dengue_peak_week_results$analysis_time_season),
%        function(season_val) {
%            max_incidence_in_season <-
%                max(dengue_sj$total_cases[dengue_sj$season == season_val])
%            return(dengue_sj$season_week[dengue_sj$season == season_val &
%                        dengue_sj$total_cases == max_incidence_in_season])
%        })
%)
%
%dengue_peak_week_heights <- data.frame(
%    analysis_time_season = unique(dengue_peak_week_results$analysis_time_season),
%    peak_height = sapply(unique(dengue_peak_week_results$analysis_time_season),
%        function(season_val) {
%            return(max(dengue_sj$total_cases[dengue_sj$season == season_val]))
%        })
%)
%
%## Contrasts with SARIMA for peak week timing
%dengue_peak_timing_log_score_diffs_from_sarima_wide <- dengue_peak_week_results %>%
%    select(full_model_descriptor, analysis_time_season, analysis_time_season_week, peak_week_log_score) %>%
%    spread(full_model_descriptor, peak_week_log_score)
%
%dengue_peak_timing_log_score_diffs_from_sarima_wide[, unique(dengue_peak_week_results$full_model_descriptor)] <-
%    dengue_peak_timing_log_score_diffs_from_sarima_wide[, unique(dengue_peak_week_results$full_model_descriptor)] -
%    dengue_peak_timing_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]
%
%dengue_peak_timing_log_score_diffs_from_sarima_long <- dengue_peak_timing_log_score_diffs_from_sarima_wide %>%
%    gather_("model", "log_score_difference", unique(dengue_peak_week_results$full_model_descriptor)) %>%
%    mutate(
%        seasonal_lag = as.logical(grepl("seasonal_lag_1", model)),
%        differencing = as.logical(grepl("differencing_TRUE", model)),
%        periodic = as.logical(grepl("periodic_TRUE", model)),
%        bw_full = as.logical(grepl("bw_full", model))
%    )
%dengue_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
%dengue_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    dengue_peak_timing_log_score_diffs_from_sarima_long$periodic & !dengue_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel"
%dengue_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    !dengue_peak_timing_log_score_diffs_from_sarima_long$periodic & dengue_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
%    "Full Bandwidth"
%dengue_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    dengue_peak_timing_log_score_diffs_from_sarima_long$periodic & dengue_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel,\nFull Bandwidth"
%dengue_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
%    factor(dengue_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor,
%        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))
%
%dengue_peak_timing_log_score_diffs_from_sarima_long$leq_peak_week <-
%    dengue_peak_timing_log_score_diffs_from_sarima_long$analysis_time_season_week <=
%    dengue_peak_week_times$peak_week[
%        sapply(dengue_peak_timing_log_score_diffs_from_sarima_long$analysis_time_season,
%            function(season_val) which(dengue_peak_week_times$analysis_time_season == season_val))]
%
%models_used <- unique(dengue_peak_week_results$full_model_descriptor[
%        !as.logical(dengue_peak_week_results$differencing) & !(dengue_peak_week_results$max_seasonal_lag == 1)])
%
%boxplot_timing_sarima_contrasts <- ggplot() +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = leq_peak_week),
%        data = dengue_peak_timing_log_score_diffs_from_sarima_long[
%            dengue_peak_timing_log_score_diffs_from_sarima_long$model %in% models_used & 
%                dengue_peak_timing_log_score_diffs_from_sarima_long$log_score_difference < 40, ]) +
%#    ylim(c(-4, 4)) +
%    ggtitle("Peak Week Timing") +
%#    xlab("Model") +
%    xlab("") +
%    ylab("Log Score Difference") +
%#    ylab("Log Score KCDE -\nLog Score SARIMA") +
%    theme_bw(base_size = 11)# +
%
%
%
%## Contrasts with SARIMA for peak week height
%dengue_peak_height_log_score_diffs_from_sarima_wide <- dengue_peak_week_results %>%
%    select(full_model_descriptor, analysis_time_season, analysis_time_season_week, peak_height_log_score) %>%
%    spread(full_model_descriptor, peak_height_log_score)
%
%dengue_peak_height_log_score_diffs_from_sarima_wide[, unique(dengue_peak_week_results$full_model_descriptor)] <-
%    dengue_peak_height_log_score_diffs_from_sarima_wide[, unique(dengue_peak_week_results$full_model_descriptor)] -
%    dengue_peak_height_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]
%
%dengue_peak_height_log_score_diffs_from_sarima_long <- dengue_peak_height_log_score_diffs_from_sarima_wide %>%
%    gather_("model", "log_score_difference", unique(dengue_peak_week_results$full_model_descriptor)) %>%
%    mutate(
%        seasonal_lag = as.logical(grepl("seasonal_lag_1", model)),
%        differencing = as.logical(grepl("differencing_TRUE", model)),
%        periodic = as.logical(grepl("periodic_TRUE", model)),
%        bw_full = as.logical(grepl("bw_full", model))
%    )
%dengue_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
%dengue_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    dengue_peak_height_log_score_diffs_from_sarima_long$periodic & !dengue_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel"
%dengue_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    !dengue_peak_height_log_score_diffs_from_sarima_long$periodic & dengue_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
%    "Full Bandwidth"
%dengue_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
%    dengue_peak_height_log_score_diffs_from_sarima_long$periodic & dengue_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
%    "Periodic Kernel,\nFull Bandwidth"
%dengue_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
%    factor(dengue_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor,
%        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))
%
%dengue_peak_height_log_score_diffs_from_sarima_long$leq_peak_week <-
%    dengue_peak_height_log_score_diffs_from_sarima_long$analysis_time_season_week <=
%    dengue_peak_week_times$peak_week[
%        sapply(dengue_peak_height_log_score_diffs_from_sarima_long$analysis_time_season,
%            function(season_val) which(dengue_peak_week_times$analysis_time_season == season_val))]
%
%models_used <- unique(dengue_peak_week_results$full_model_descriptor[
%        !as.logical(dengue_peak_week_results$differencing) & !(dengue_peak_week_results$max_seasonal_lag == 1)])
%
%boxplot_height_sarima_contrasts <- ggplot() +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = leq_peak_week),
%        data = dengue_peak_height_log_score_diffs_from_sarima_long[dengue_peak_height_log_score_diffs_from_sarima_long$model %in% models_used, ]) +
%#    ylim(c(-4, 4)) +
%    ggtitle("Peak Week Incidence") +
%#    xlab("Model") +
%    xlab("") +
%    ylab("") +
%#    ylab("Log Score KCDE -\nLog Score SARIMA") +
%    theme_bw(base_size = 11)# +
%
%
%
%dengue_timing_contrast_periodic_kernel <- dengue_peak_timing_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("periodic",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%dengue_timing_contrast_periodic_kernel$fixed_values <- "Null Model"
%dengue_timing_contrast_periodic_kernel$fixed_values[dengue_timing_contrast_periodic_kernel$bw_full] <-
%    "Full Bandwidth"
%dengue_timing_contrast_periodic_kernel$fixed_values <-
%    factor(dengue_timing_contrast_periodic_kernel$fixed_values,
%        levels = c("Null Model", "Full Bandwidth"))
%
%dengue_timing_contrast_periodic_kernel$leq_peak_week <-
%    dengue_timing_contrast_periodic_kernel$analysis_time_season_week <=
%    dengue_peak_week_times$peak_week[
%        sapply(dengue_timing_contrast_periodic_kernel$analysis_time_season,
%            function(season_val) which(dengue_peak_week_times$analysis_time_season == season_val))]
%
%
%dengue_height_contrast_periodic_kernel <- dengue_peak_height_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("periodic",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%dengue_height_contrast_periodic_kernel$fixed_values <- "Null Model"
%dengue_height_contrast_periodic_kernel$fixed_values[dengue_height_contrast_periodic_kernel$bw_full] <-
%    "Full Bandwidth"
%dengue_height_contrast_periodic_kernel$fixed_values <-
%    factor(dengue_height_contrast_periodic_kernel$fixed_values,
%        levels = c("Null Model", "Full Bandwidth"))
%
%dengue_height_contrast_periodic_kernel$leq_peak_week <-
%    dengue_height_contrast_periodic_kernel$analysis_time_season_week <=
%    dengue_peak_week_times$peak_week[
%        sapply(dengue_height_contrast_periodic_kernel$analysis_time_season,
%            function(season_val) which(dengue_peak_week_times$analysis_time_season == season_val))]
%
%
%boxplot_timing_periodic_kernel_contrasts <- ggplot(dengue_timing_contrast_periodic_kernel) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Timing") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("Log Score Difference") +
%#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
%    theme_bw(base_size = 11)
%
%
%boxplot_height_periodic_kernel_contrasts <- ggplot(dengue_height_contrast_periodic_kernel) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Incidence") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("") +
%#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
%    theme_bw(base_size = 11)
%
%
%dengue_timing_contrast_bw_full <- dengue_peak_timing_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("bw_full",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%dengue_timing_contrast_bw_full$fixed_values <- "Null Model"
%dengue_timing_contrast_bw_full$fixed_values[dengue_timing_contrast_bw_full$periodic] <-
%    "Periodic Kernel"
%dengue_timing_contrast_bw_full$fixed_values <-
%    factor(dengue_timing_contrast_bw_full$fixed_values,
%        levels = c("Null Model", "Periodic Kernel"))
%
%dengue_timing_contrast_bw_full$leq_peak_week <-
%    dengue_timing_contrast_bw_full$analysis_time_season_week <=
%    dengue_peak_week_times$peak_week[
%        sapply(dengue_timing_contrast_bw_full$analysis_time_season,
%            function(season_val) which(dengue_peak_week_times$analysis_time_season == season_val))]
%
%
%dengue_height_contrast_bw_full <- dengue_peak_height_log_score_diffs_from_sarima_long %>%
%    filter(model %in% models_used) %>%
%    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("bw_full",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`)
%dengue_height_contrast_bw_full$fixed_values <- "Null Model"
%dengue_height_contrast_bw_full$fixed_values[dengue_height_contrast_bw_full$periodic] <-
%    "Periodic Kernel"
%dengue_height_contrast_bw_full$fixed_values <-
%    factor(dengue_height_contrast_bw_full$fixed_values,
%        levels = c("Null Model", "Periodic Kernel"))
%
%dengue_height_contrast_bw_full$leq_peak_week <-
%    dengue_height_contrast_bw_full$analysis_time_season_week <=
%    dengue_peak_week_times$peak_week[
%        sapply(dengue_height_contrast_bw_full$analysis_time_season,
%            function(season_val) which(dengue_peak_week_times$analysis_time_season == season_val))]
%
%
%boxplot_timing_bw_full_contrasts <- ggplot(dengue_timing_contrast_bw_full) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Timing") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("Log Score Difference") +
%#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
%    theme_bw(base_size = 11)
%
%boxplot_height_bw_full_contrasts <- ggplot(dengue_height_contrast_bw_full) +
%    geom_hline(yintercept = 0) +
%    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
%#    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Peak Week Incidence") +
%#    xlab("Base Model") +
%    xlab("") +
%    ylab("") +
%#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
%    theme_bw(base_size = 11)
%
%
%grid.newpage()
%pushViewport(viewport(layout =
%    grid.layout(nrow = 6, ncol = 2, heights = unit(rep(1, 6), rep(c("lines", "null"), times = 3)))))
%grid.text("(a) Comparison of KCDE with SARIMA",
%    gp = gpar(fontsize = 12),
%    vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
%print(boxplot_timing_sarima_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
%print(boxplot_height_sarima_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 2))
%grid.text("(b) Effect of Adding Periodic Kernel to Model",
%    gp = gpar(fontsize = 12),
%    vp = viewport(layout.pos.row = 3, layout.pos.col = 1:2))
%print(boxplot_timing_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 4, layout.pos.col = 1))
%print(boxplot_height_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 4, layout.pos.col = 2))
%grid.text("(c) Effect of Adding Fully Parameterized BW to Model",
%    gp = gpar(fontsize = 12),
%    vp = viewport(layout.pos.row = 5, layout.pos.col = 1:2))
%print(boxplot_timing_bw_full_contrasts, vp = viewport(layout.pos.row = 6, layout.pos.col = 1))
%print(boxplot_height_bw_full_contrasts, vp = viewport(layout.pos.row = 6, layout.pos.col = 2))
%@
%\end{figure}




<<DengueDataMergePeakWeekPredictionResults, echo = FALSE>>=
data_set <- "dengue_sj"
    
prediction_save_path <- file.path("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results",
    data_set,
    "prediction-results")

all_max_lags <- as.character(c(1L))
#all_max_seasonal_lags <- as.character(c(0L, 1L))
all_max_seasonal_lags <- as.character(c(0L))
all_filtering_values <- c("FALSE")
#all_differencing_values <- c("FALSE", "TRUE")
all_differencing_values <- "FALSE"
all_seasonality_values <- c("FALSE", "TRUE")
all_bw_parameterizations <- c("diagonal", "full")

case_definitions <- expand.grid(
        data_set,
        all_max_lags,
        all_max_seasonal_lags,
        all_filtering_values,
        all_differencing_values,
        all_seasonality_values,
        all_bw_parameterizations,
        stringsAsFactors = FALSE) %>%
    `colnames<-`(c("data_set",
            "max_lag",
            "max_seasonal_lag",
            "filtering",
            "differencing",
            "seasonality",
            "bw_parameterization"))
 
dengue_peak_week_results <- rbind.fill(
    c(
        list(
            readRDS(file.path(prediction_save_path,
                        paste0("peak-week-sarima-", data_set, ".rds"))) %>%
                mutate(model = "SARIMA")
        ),
        lapply(seq_len(nrow(case_definitions)), function(case_row_ind) {
                max_lag <- case_definitions$max_lag[case_row_ind]
                max_seasonal_lag <- case_definitions$max_seasonal_lag[case_row_ind]
                filtering <- case_definitions$filtering[case_row_ind]
                differencing <- case_definitions$differencing[case_row_ind]
                seasonality <- case_definitions$seasonality[case_row_ind]
                bw_parameterization <- case_definitions$bw_parameterization[case_row_ind]
                
                case_descriptor <- paste0(
                    data_set,
                    "-max_lag_", max_lag,
                    "-max_seasonal_lag_", max_seasonal_lag,
                    "-filtering_", filtering,
                    "-differencing_", differencing,
                    "-seasonality_", seasonality,
                    "-bw_parameterization_", bw_parameterization
                )
                
                readRDS(file.path(prediction_save_path,
                            paste0("peak-week-", case_descriptor, ".rds"))) %>%
                    mutate(model = "KCDE",
                        max_lag = max_lag,
                        max_seasonal_lag = max_seasonal_lag,
                        filtering = filtering,
                        differencing = differencing,
                        seasonality = seasonality,
                        bw_parameterization = bw_parameterization)
            })
    )
)

dengue_peak_week_results$full_model_descriptor <- paste0(dengue_peak_week_results$model,
    "-seasonal_lag_", dengue_peak_week_results$max_seasonal_lag,
#    "-filtering_", dengue_prediction_results$filtering,
    "-differencing_", dengue_peak_week_results$differencing,
    "-periodic_", dengue_peak_week_results$seasonality,
    "-bw_", dengue_peak_week_results$bw_parameterization)

dengue_peak_week_results$reduced_model_descriptor <- "Null KCDE"
dengue_peak_week_results$reduced_model_descriptor[
    as.logical(dengue_peak_week_results$seasonality) & !(dengue_peak_week_results$bw_parameterization == "full")] <-
    "Periodic KCDE"
dengue_peak_week_results$reduced_model_descriptor[
    !as.logical(dengue_peak_week_results$seasonality) & (dengue_peak_week_results$bw_parameterization == "full")] <-
    "Full Bandwidth KCDE"
dengue_peak_week_results$reduced_model_descriptor[
    as.logical(dengue_peak_week_results$seasonality) & (dengue_peak_week_results$bw_parameterization == "full")] <-
    "Periodic, Full Bandwidth KCDE"
dengue_peak_week_results$reduced_model_descriptor[
    dengue_peak_week_results$model == "SARIMA"] <-
    "SARIMA"

num_analysis_time_season_values <- length(unique(dengue_peak_week_results$analysis_time_season))
num_analysis_time_season_week_values <- length(unique(dengue_peak_week_results$analysis_time_season_week))
dengue_peak_week_results <- rbind.fill(dengue_peak_week_results,
    data.frame(
        full_model_descriptor = rep("Equal Bin Probabilities", num_analysis_time_season_week_values * num_analysis_time_season_values),
        reduced_model_descriptor = rep("Equal Bin Probabilities", num_analysis_time_season_week_values * num_analysis_time_season_values),
        analysis_time_season = rep(unique(dengue_peak_week_results$analysis_time_season), each = num_analysis_time_season_week_values),
        analysis_time_season_week = rep(unique(dengue_peak_week_results$analysis_time_season_week), times = num_analysis_time_season_values),
        peak_week_log_score = rep(log(1/52), num_analysis_time_season_week_values * num_analysis_time_season_values),
        peak_height_log_score = rep(log(1/11), num_analysis_time_season_week_values * num_analysis_time_season_values)
    ))


dengue_peak_week_results$reduced_model_descriptor <-
    factor(dengue_peak_week_results$reduced_model_descriptor,
        levels = c("SARIMA", "Null KCDE", "Full Bandwidth KCDE", "Periodic KCDE",
            "Periodic, Full Bandwidth KCDE",
            "Equal Bin Probabilities"
        ))

#geom_hline(yintercept = log(1/31), colour = "grey", linetype = 2)

dengue_peak_week_times <- data.frame(
    analysis_time_season = unique(dengue_peak_week_results$analysis_time_season),
    peak_week = sapply(unique(dengue_peak_week_results$analysis_time_season),
        function(season_val) {
            max_incidence_in_season <-
                max(dengue_sj$total_cases[dengue_sj$season == season_val])
            return(dengue_sj$season_week[dengue_sj$season == season_val &
                        dengue_sj$total_cases == max_incidence_in_season])
        })
)

dengue_peak_week_heights <- data.frame(
    analysis_time_season = unique(dengue_peak_week_results$analysis_time_season),
    peak_height = sapply(unique(dengue_peak_week_results$analysis_time_season),
        function(season_val) {
            return(max(dengue_sj$total_cases[dengue_sj$season == season_val]))
        })
)

dengue_peak_week_results$peak_week_log_score[dengue_peak_week_results$peak_week_log_score < -50] <- -50
dengue_peak_week_results$peak_height_log_score[dengue_peak_week_results$peak_height_log_score < -50] <- -50
dengue_peak_week_results$peak_week_log_score[dengue_peak_week_results$peak_week_log_score == -50] <- NA
dengue_peak_week_results$peak_height_log_score[dengue_peak_week_results$peak_height_log_score == -50] <- NA
@

%, dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots")

%%% PUT THIS IN THE SUPPLEMENT

%\begin{figure}
%\caption{Log scores for predictions of peak week timing by predictive
%model and analysis time.  The vertical gray line is placed at the peak week for
%each season.  The log score for ``Equal Bin Probabilities'' is obtained by
%assigning equal probability that the peak will occur in each week of the year.}
%\label{fig:CombinedPeakWeekTimingPredictionLogScores}
%<<DenguePeakWeekTimingLogScoreByAnalysisTime, echo = FALSE, fig.keep = "last", fig.height = 8.5, dependson = c("FluDataMergePeakWeekPredictionResults", "DengueDataMergePeakWeekPredictionResults")>>=
%## Add season and season week columns to data so that we can get from
%## analysis_time_season and analysis_time_season_week to analysis_time
%#dengue_sj$season <- ifelse(
%#    dengue_sj$week <= 30,
%#    paste0(dengue_sj$year - 1, "/", dengue_sj$year),
%#    paste0(dengue_sj$year, "/", dengue_sj$year + 1)
%#)
%#
%## Season week column: week number within season
%#dengue_sj$season_week <- sapply(seq_len(nrow(dengue_sj)), function(row_ind) {
%#    sum(dengue_sj$season == dengue_sj$season[row_ind] & dengue_sj$time_index <= dengue_sj$time_index[row_ind])
%#})
%#
%#
%#dengue_peak_week_results$analysis_time <- dengue_peak_week_results$analysis_time_season_week
%
%#dengue_peak_week_results_for_plot
%
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "Equal Bin Probabilities")
%reduced_models_used <- c(
%    "SARIMA",
%    "Null KCDE Model",
%    "Full Bandwidth",
%    "Periodic Kernel",
%    "Periodic Kernel,\nFull Bandwidth",
%    "Equal Bin Probabilities"
%)
%
%p <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used, ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = dengue_peak_week_times) +
%    facet_wrap( ~ analysis_time_season, ncol = 1) +
%    xlab("Season Week at Analysis Time") +
%    ylab("Log Score") +
%    theme_bw()
%
%suppressWarnings(print(p))
%grid_list <- capture.output(grid.ls())
%legend_grob <- grid.get(str_trim(grid_list[grep("guide-box", grid_list)]))
%
%p_d_1 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
%                dengue_peak_week_results$analysis_time_season == "2009/2010", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2009/2010", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Dengue Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%p_d_2 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
%                dengue_peak_week_results$analysis_time_season == "2010/2011", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2010/2011", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Dengue Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%p_d_3 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
%                dengue_peak_week_results$analysis_time_season == "2011/2012", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2011/2012", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Dengue Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%p_d_4 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
%                dengue_peak_week_results$analysis_time_season == "2012/2013", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2012/2013", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Dengue Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("Season Week at Analysis Time") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%
%
%p_i_1 <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used &
%                ili_peak_week_results$analysis_time_season == "2011/2012", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = ili_peak_week_times[ili_peak_week_times$analysis_time_season == "2011/2012", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Influenza Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%p_i_2 <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used &
%                ili_peak_week_results$analysis_time_season == "2012/2013", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = ili_peak_week_times[ili_peak_week_times$analysis_time_season == "2012/2013", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Influenza Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%p_i_3 <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used &
%                ili_peak_week_results$analysis_time_season == "2013/2014", ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = ili_peak_week_times[ili_peak_week_times$analysis_time_season == "2013/2014", ]) +
%    ylim(c(-10, 0)) +
%    facet_wrap( ~ analysis_time_season, ncol = 1,
%        labeller = as_labeller(function(labels, ...) {
%                return(paste0("Influenza Data, ", labels))
%            })
%    ) +
%#    xlab("Season Week at Analysis Time") +
%#    ylab("Log Score") +
%    xlab("Season Week at Analysis Time") +
%    ylab("") +
%    theme_bw() +
%    theme(legend.position = "none")
%
%grid.newpage()
%#grid.layout(nrow = 2, ncol = 2, heights = unit(rep(1, 2), c("null", "lines")))
%pushViewport(viewport(layout = grid.layout(nrow = 4, ncol = 3,
%            heights = unit(rep(1, 4), c("null", "null", "null", "null")),
%            widths = unit(c(1, 1, 1), c("lines", "null", "null")))))
%grid.text("Log Score",
%    gp = gpar(fontsize = 12),
%    rot = 90,
%    vp = viewport(layout.pos.row = 1:4, layout.pos.col = 1))
%        
%pushViewport(viewport(layout.pos.row = 4, layout.pos.col = 3))
%grid.draw(legend_grob)
%upViewport()
%suppressWarnings(print(p_d_1, vp = viewport(layout.pos.row = 1, layout.pos.col = 2)))
%suppressWarnings(print(p_d_2, vp = viewport(layout.pos.row = 2, layout.pos.col = 2)))
%suppressWarnings(print(p_d_3, vp = viewport(layout.pos.row = 3, layout.pos.col = 2)))
%suppressWarnings(print(p_d_4, vp = viewport(layout.pos.row = 4, layout.pos.col = 2)))
%suppressWarnings(print(p_i_1, vp = viewport(layout.pos.row = 1, layout.pos.col = 3)))
%suppressWarnings(print(p_i_2, vp = viewport(layout.pos.row = 2, layout.pos.col = 3)))
%suppressWarnings(print(p_i_3, vp = viewport(layout.pos.row = 3, layout.pos.col = 3)))
%
%@
%\end{figure}

%, dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots")
\begin{figure}
\caption{Log scores for predictions of peak week incidence by predictive
model and analysis time.  The vertical line is placed at the peak week for
each season.  The log score for ``Equal Bin Probabilities'' is obtained by
assigning equal probability that the peak incidence will be in each of the
specified incidence bins.  There are 11 incidence bins for dengue
and 27 bins for influenza.}
\label{fig:CombinedPeakWeekIncidencePredictionLogScores}
<<CombinedPeakWeekHeightLogScoreByAnalysisTime, echo = FALSE, fig.keep = "last", fig.height = 8.3, dependson = c("FluDataMergePeakWeekPredictionResults", "DengueDataMergePeakWeekPredictionResults")>>=
## Add season and season week columns to data so that we can get from
## analysis_time_season and analysis_time_season_week to analysis_time
#dengue_sj$season <- ifelse(
#    dengue_sj$week <= 30,
#    paste0(dengue_sj$year - 1, "/", dengue_sj$year),
#    paste0(dengue_sj$year, "/", dengue_sj$year + 1)
#)
#
## Season week column: week number within season
#dengue_sj$season_week <- sapply(seq_len(nrow(dengue_sj)), function(row_ind) {
#    sum(dengue_sj$season == dengue_sj$season[row_ind] & dengue_sj$time_index <= dengue_sj$time_index[row_ind])
#})
#
#
#dengue_peak_week_results$analysis_time <- dengue_peak_week_results$analysis_time_season_week

#dengue_peak_week_results_for_plot

models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
    "Equal Bin Probabilities")
reduced_models_used <- c(
    "SARIMA",
    "Null KCDE",
    "Full Bandwidth KCDE",
    "Periodic KCDE",
    "Periodic, Full Bandwidth KCDE",
    "Equal Bin Probabilities"
)

p <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used, ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = dengue_peak_week_times) +
    facet_wrap( ~ analysis_time_season, ncol = 1) +
    xlab("Season Week at Analysis Time") +
    ylab("Log Score") +
    theme_bw()

suppressWarnings(print(p))
grid_list <- capture.output(grid.ls())
legend_grob <- grid.get(str_trim(grid_list[grep("guide-box", grid_list)]))

#competition_scores <- read.csv("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/dengue_sj/forecast_scores_from_competition.csv")
#test_df <- competition_scores[competition_scores$metric.type == "LS" &
#    competition_scores$location == "sanjuan" &
#    competition_scores$prediction.target == "peakinc", ]
#test_df$full_model_descriptor <-
#    test_df$reduced_model_descriptor <-
#    paste0("competition_", test_df$team)
#test_df$peak_height_log_score <- test_df$metric
#test_df$analysis_time_season_week <- test_df$forecast.week
#test_df$analysis_time_season <- test_df$season
#test_df <- test_df[test_df$analysis_time_season %in% unique(dengue_peak_week_results$analysis_time_season), ]
#
#
#ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used, ]) +
#    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, group = reduced_model_descriptor), colour = "gray", data = test_df) +
#    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, group = reduced_model_descriptor), colour = "blue", data = test_df[test_df$reduced_model_descriptor == "competition_baseline", ]) +
#    #    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
#    scale_colour_manual("Model", breaks = c(reduced_models_used, "blah"), values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999", "#999999")) +
##    scale_colour_manual("Model", breaks = c(reduced_models_used, "blah"), values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999", "#999999")) +
##    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
##    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
#    geom_vline(aes(xintercept = peak_week), colour = "#999999", linetype = 1, data = dengue_peak_week_times) +
#    facet_wrap( ~ analysis_time_season, ncol = 1,
#        labeller = as_labeller(function(labels, ...) {
#                return(paste0("Dengue Data, ", labels))
#            })
#    ) +
##    xlab("Season Week at Analysis Time") +
##    ylab("Log Score") +
#    ylim(c(-5, 0)) +
#    xlab("") +
#    ylab("") +
#    theme_bw()# +
##    theme(legend.position = "none")
#


p_d_1 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
                dengue_peak_week_results$analysis_time_season == "2009/2010", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2009/2010", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Dengue Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")

p_d_2 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
                dengue_peak_week_results$analysis_time_season == "2010/2011", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2010/2011", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Dengue Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")

p_d_3 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
                dengue_peak_week_results$analysis_time_season == "2011/2012", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2011/2012", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Dengue Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")

p_d_4 <- ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used &
                dengue_peak_week_results$analysis_time_season == "2012/2013", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = dengue_peak_week_times[dengue_peak_week_times$analysis_time_season == "2012/2013", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Dengue Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("Season Week at Analysis Time") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")



p_i_1 <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used &
                ili_peak_week_results$analysis_time_season == "2011/2012", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = ili_peak_week_times[ili_peak_week_times$analysis_time_season == "2011/2012", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Influenza Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")

p_i_2 <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used &
                ili_peak_week_results$analysis_time_season == "2012/2013", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = ili_peak_week_times[ili_peak_week_times$analysis_time_season == "2012/2013", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Influenza Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")

p_i_3 <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used &
                ili_peak_week_results$analysis_time_season == "2013/2014", ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
#    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
    geom_vline(aes(xintercept = peak_week), linetype = 1, data = ili_peak_week_times[ili_peak_week_times$analysis_time_season == "2013/2014", ]) +
    ylim(c(-6, 0)) +
    facet_wrap( ~ analysis_time_season, ncol = 1,
        labeller = as_labeller(function(labels, ...) {
                return(paste0("Influenza Data, ", labels))
            })
    ) +
#    xlab("Season Week at Analysis Time") +
#    ylab("Log Score") +
    xlab("Season Week at Analysis Time") +
    ylab("") +
    theme_bw() +
    theme(legend.position = "none")

grid.newpage()
#grid.layout(nrow = 2, ncol = 2, heights = unit(rep(1, 2), c("null", "lines")))
pushViewport(viewport(layout = grid.layout(nrow = 4, ncol = 3,
            heights = unit(rep(1, 4), c("null", "null", "null", "null")),
            widths = unit(c(1, 1, 1), c("lines", "null", "null")))))
grid.text("Log Score",
    gp = gpar(fontsize = 12),
    rot = 90,
    vp = viewport(layout.pos.row = 1:4, layout.pos.col = 1))
        
pushViewport(viewport(layout.pos.row = 4, layout.pos.col = 3))
grid.draw(legend_grob)
upViewport()
suppressWarnings(print(p_d_1, vp = viewport(layout.pos.row = 1, layout.pos.col = 2)))
suppressWarnings(print(p_d_2, vp = viewport(layout.pos.row = 2, layout.pos.col = 2)))
suppressWarnings(print(p_d_3, vp = viewport(layout.pos.row = 3, layout.pos.col = 2)))
suppressWarnings(print(p_d_4, vp = viewport(layout.pos.row = 4, layout.pos.col = 2)))
suppressWarnings(print(p_i_1, vp = viewport(layout.pos.row = 1, layout.pos.col = 3)))
suppressWarnings(print(p_i_2, vp = viewport(layout.pos.row = 2, layout.pos.col = 3)))
suppressWarnings(print(p_i_3, vp = viewport(layout.pos.row = 3, layout.pos.col = 3)))

@
\end{figure}


%\begin{figure}
%\caption{Log scores for predictions of incidence in the peak week for Dengue by
%predictive model and analysis time.  The vertical gray line is placed at the peak week for
%each season.}
%\label{fig:DenguePeakWeekIncidencePredictionLogScores}
%<<DenguePeakWeekIncidenceLogScoreByAnalysisTime, echo = FALSE, dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots")>>=
%## Add season and season week columns to data so that we can get from
%## analysis_time_season and analysis_time_season_week to analysis_time
%#dengue_sj$season <- ifelse(
%#    dengue_sj$week <= 30,
%#    paste0(dengue_sj$year - 1, "/", dengue_sj$year),
%#    paste0(dengue_sj$year, "/", dengue_sj$year + 1)
%#)
%#
%## Season week column: week number within season
%#dengue_sj$season_week <- sapply(seq_len(nrow(dengue_sj)), function(row_ind) {
%#    sum(dengue_sj$season == dengue_sj$season[row_ind] & dengue_sj$time_index <= dengue_sj$time_index[row_ind])
%#})
%#
%#
%#dengue_peak_week_results$analysis_time <- dengue_peak_week_results$analysis_time_season_week
%
%#dengue_peak_week_results_for_plot
% 
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "Equal Bin Probabilities")
%reduced_models_used <- c(
%    "SARIMA",
%    "Null KCDE Model",
%    "Full Bandwidth",
%    "Periodic Kernel",
%    "Periodic Kernel,\nFull Bandwidth",
%    "Equal Bin Probabilities")
%
%dengue_peak_week_results$peak_height_log_score[dengue_peak_week_results$peak_height_log_score == -50] <- NA
%ggplot(dengue_peak_week_results[dengue_peak_week_results$full_model_descriptor %in% models_used, ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = dengue_peak_week_times) +
%    facet_wrap( ~ analysis_time_season, ncol = 1) +
%#    geom_raster(aes(x = analysis_time_season_week, y = log_score),
%#        data = dengue_peak_week_results) +
%    xlab("Season Week at Analysis Time") +
%    ylab("Log Score") +
%    theme_bw()
%@
%\end{figure}
%
%\begin{figure}
%\caption{Log scores for predictions of incidence in the peak week by predictive
%model and analysis time.  The vertical gray line is placed at the peak week for
%each season.}
%\label{fig:FluPeakWeekIncidencePredictionLogScores}
%<<FluPeakWeekIncidenceLogScoreByAnalysisTime, echo = FALSE>>=
%## Add season and season week columns to data so that we can get from
%## analysis_time_season and analysis_time_season_week to analysis_time
%#ili_national$season <- ifelse(
%#    ili_national$week <= 30,
%#    paste0(ili_national$year - 1, "/", ili_national$year),
%#    paste0(ili_national$year, "/", ili_national$year + 1)
%#)
%#
%## Season week column: week number within season
%#ili_national$season_week <- sapply(seq_len(nrow(ili_national)), function(row_ind) {
%#    sum(ili_national$season == ili_national$season[row_ind] & ili_national$time_index <= ili_national$time_index[row_ind])
%#})
%#
%#
%#ili_peak_week_results$analysis_time <- ili_peak_week_results$analysis_time_season_week
%
%#ili_peak_week_results_for_plot
%
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "Equal Bin Probabilities")
%reduced_models_used <- c(
%    "SARIMA",
%    "Null KCDE Model",
%    "Full Bandwidth",
%    "Periodic Kernel",
%    "Periodic Kernel,\nFull Bandwidth",
%    "Equal Bin Probabilities")
%
%ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used, ]) +
%    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
%#    geom_point(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
%    scale_colour_manual("Model", breaks = reduced_models_used, values = c("#E69F00", "#56B4E9", "#009E73", "#D55E00", "#0072B2", "#999999")) +
%    scale_linetype_manual("Model", breaks = reduced_models_used, values = c(1:5, 1)) +
%    scale_shape_manual("Model", breaks = reduced_models_used, values = c(0:4, 45)) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = ili_peak_week_times) +
%    facet_wrap( ~ analysis_time_season, ncol = 1) +
%#    geom_raster(aes(x = analysis_time_season_week, y = log_score),
%#        data = ili_peak_week_results) +
%    xlab("Season Week at Analysis Time") +
%    ylab("Log Score") +
%    theme_bw()
%@
%\end{figure}


<<FluObtainPeakWeekTimingPredictiveDistributionsByAnalysisTime, echo = FALSE, dependson = c("FluDataMergePeakWeekPredictionResults")>>=
ili_incidence_bins <- data.frame(
    lower = seq(from = 0, to = 13, by = 0.5),
    upper = c(seq(from = 0.5, to = 13, by = 0.5), Inf))

for(bin_num in seq(from = 9, to = 41)) {
    ili_peak_week_results[, paste0("est_prob_bin_", bin_num)] <-
        apply(ili_peak_week_results[, paste0("peak_week_", seq_len(10000))],
            1,
            function(x) {sum(x == bin_num) / length(x)})
}

peak_timing_pred_dist_by_analysis_time <- ili_peak_week_results %>%
    select(full_model_descriptor,
            analysis_time_season,
            analysis_time_season_week,
            starts_with("est_prob_bin_")) %>%
    gather_("bin", "est_prob", paste0("est_prob_bin_", seq(from = 9, to = 41)))
peak_timing_pred_dist_by_analysis_time$bin <-
    as.integer(substr(peak_timing_pred_dist_by_analysis_time$bin, 14, 15))


#junkjunkjunk <-    peak_timing_pred_dist_by_analysis_time[
#        peak_timing_pred_dist_by_analysis_time$full_model_descriptor == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full" &
#        peak_timing_pred_dist_by_analysis_time$bin ==
#            peak_week_times$peak_week[
#                sapply(peak_timing_pred_dist_by_analysis_time$analysis_time_season,
#                    function(season_val) {
#                        which(peak_week_times$analysis_time_season == season_val)
#                    })
#        ],
#        c("est_prob", "analysis_time_season", "analysis_time_season_week")
#    ] %>%
#    mutate(log_score = log(est_prob))
#
#junkjunkjunk <- 
#    junkjunkjunk[
#        order(junkjunkjunk$analysis_time_season,
#            junkjunkjunk$analysis_time_season_week), ]
#
#junkjunkjunkjunk <- ili_peak_week_results[
#    ili_peak_week_results$full_model_descriptor == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
#    c("peak_week_log_score", "analysis_time_season", "analysis_time_season_week")
#]
#
#junkjunkjunkjunk <- 
#    junkjunkjunkjunk[
#        order(junkjunkjunkjunk$analysis_time_season,
#            junkjunkjunkjunk$analysis_time_season_week), ]
#
#tapply(peak_timing_pred_dist_by_analysis_time$est_prob,
#    peak_timing_pred_dist_by_analysis_time[,
#        c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week")],
#    sum)
 
peak_timing_and_height_pred_dist_means_by_analysis_time <- 
    ili_peak_week_results %>%
    select(full_model_descriptor,
        analysis_time_season,
        analysis_time_season_week,
        starts_with("est_prob_bin_")) %>%
    mutate(
        mean_peak_week = apply(ili_peak_week_results[, paste0("peak_week_", seq_len(10000))],
            1,
            mean),
        median_peak_week = apply(ili_peak_week_results[, paste0("peak_week_", seq_len(10000))],
            1,
            median),
        mean_peak_height = apply(ili_peak_week_results[, paste0("unbinned_peak_height_", seq_len(10000))],
            1,
            mean),
        median_peak_height = apply(ili_peak_week_results[, paste0("unbinned_peak_height_", seq_len(10000))],
            1,
            median)
    )

#peak_timing_pred_dist_by_analysis_time <- ili_peak_week_results %>%
#    mutate(count_)
#    select_(c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week"))
#
#
#
#peak_timing_pred_dist_by_analysis_time <-
#    as.data.frame(expand.grid(
#            model = c(
#                "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
#                "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"),
#            analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
#            analysis_time_season_week = seq(from = 10, to = 40),
#            bin_number = seq(from = 10, to = 40),
##        incidence_bin = seq_len(nrow(ili_incidence_bins)),
#            stringsAsFactors = FALSE
#        ))
#peak_timing_pred_dist_by_analysis_time$est_bin_prob <- sapply(
#    seq_len(nrow(peak_timing_pred_dist_by_analysis_time)),
#    function(row_ind) {
#        sum(ili_peak_week_results[
#                    ili_peak_week_results$full_model_descriptor == peak_timing_pred_dist_by_analysis_time$model[row_ind] &
#                        ili_peak_week_results$analysis_time_season == peak_timing_pred_dist_by_analysis_time$analysis_time_season[row_ind] &
#                        ili_peak_week_results$analysis_time_season_week == peak_timing_pred_dist_by_analysis_time$analysis_time_season_week[row_ind],
#                    paste0("peak_week_", seq_len(10000))] ==
#                peak_timing_pred_dist_by_analysis_time$bin_number[row_ind]) / 10000
#    })
#
#
#
@

%\begin{figure}
%\caption{Predictive distributions for predictions of peak week timing.  The
%horizontal and vertical dashed lines are at the observed peak week for the
%season.}
%\label{fig:FluPeakWeekTimingPredictiveDistributions}
%<<FluPlotPeakWeekTimingPredictiveDistributionsByAnalysisTime, echo = FALSE, dependson = c("FluObtainPeakWeekTimingPredictiveDistributionsByAnalysisTime")>>=
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%
%#peak_timing_pred_dist_by_analysis_time$est_prob[
%#    peak_timing_pred_dist_by_analysis_time$est_prob == 0] <- 10^{-20}
%#peak_timing_pred_dist_by_analysis_time$est_prob[
%#    peak_timing_pred_dist_by_analysis_time$est_prob == 10^{-20}] <- 0
%
%#min(
%#    peak_timing_pred_dist_by_analysis_time$est_prob[
%#        peak_timing_pred_dist_by_analysis_time$est_prob != 0 &
%#            peak_timing_pred_dist_by_analysis_time$full_model_descriptor %in% models_used]
%#)
%
%ggplot() +
%    geom_raster(aes(x = analysis_time_season_week, y = bin, fill = est_prob),
%        data = peak_timing_pred_dist_by_analysis_time[peak_timing_pred_dist_by_analysis_time$full_model_descriptor %in% models_used, ]) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = ili_peak_week_times) +
%    geom_hline(aes(yintercept = peak_week), colour = "red", linetype = 2, data = ili_peak_week_times) +
%    geom_point(aes(x = analysis_time_season_week, y = median_peak_week),
%        colour = "red",
%        data = peak_timing_and_height_pred_dist_means_by_analysis_time[peak_timing_and_height_pred_dist_means_by_analysis_time$full_model_descriptor %in% models_used, ]) +
%    scale_fill_gradientn("Predictive\nDistribution\nProbability",
%        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        limits = c(10^{-10}, 1),
%        trans = "log",
%#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%#        labels = c(0.0001, 0.001, 0.01, 0.1, 1),
%        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%        na.value = "white"
%    ) +
%    facet_grid(analysis_time_season ~ full_model_descriptor,
%        labeller = as_labeller(function(labels, ...) {
%            labels[labels == "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"] <- "SARIMA"
%            labels[labels == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"] <- "KCDE"
%            return(labels)
%        })) +
%    xlab("Season Week at Analysis Time") +
%    ylab("Season Week at Peak Incidence") +
%    theme_bw()
%@
%\end{figure}




<<FluObtainPeakWeekHeightPredictiveDistributionsByAnalysisTime, echo = FALSE, cache = TRUE, dependson = c("FluDataMergePeakWeekPredictionResults")>>=
ili_incidence_bins <- data.frame(
    lower = seq(from = 0, to = 13, by = 0.5),
    upper = c(seq(from = 0.5, to = 13, by = 0.5), Inf),
    center = seq(from = 0.25, to = 13.25, by = 0.5))
#ili_peak_week_results <-  
for(bin_num in seq_len(nrow(ili_incidence_bins))) {
    ili_peak_week_results[, paste0("est_prob_bin_", bin_num)] <-
        apply(ili_peak_week_results[, paste0("peak_height_", seq_len(10000))],
            1,
            function(x) {sum(x == bin_num) / length(x)})
}

peak_height_pred_dist_by_analysis_time <- ili_peak_week_results %>%
    select(full_model_descriptor,
            analysis_time_season,
            analysis_time_season_week,
            starts_with("est_prob_bin_")) %>%
    gather_("bin", "est_prob", paste0("est_prob_bin_", seq_len(nrow(ili_incidence_bins))))
peak_height_pred_dist_by_analysis_time$bin <-
    as.integer(substr(peak_height_pred_dist_by_analysis_time$bin, 14, 15))
peak_height_pred_dist_by_analysis_time$bin_center <-
    ili_incidence_bins$center[peak_height_pred_dist_by_analysis_time$bin]

junk <- "junk"
#peak_timing_pred_dist_by_analysis_time <- ili_peak_week_results %>%
#    mutate(count_)
#    select_(c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week"))
#
#
#
#peak_timing_pred_dist_by_analysis_time <-
#    as.data.frame(expand.grid(
#            model = c(
#                "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
#                "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"),
#            analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
#            analysis_time_season_week = seq(from = 10, to = 40),
#            bin_number = seq(from = 10, to = 40),
##        incidence_bin = seq_len(nrow(ili_incidence_bins)),
#            stringsAsFactors = FALSE
#        ))
#peak_timing_pred_dist_by_analysis_time$est_bin_prob <- sapply(
#    seq_len(nrow(peak_timing_pred_dist_by_analysis_time)),
#    function(row_ind) {
#        sum(ili_peak_week_results[
#                    ili_peak_week_results$full_model_descriptor == peak_timing_pred_dist_by_analysis_time$model[row_ind] &
#                        ili_peak_week_results$analysis_time_season == peak_timing_pred_dist_by_analysis_time$analysis_time_season[row_ind] &
#                        ili_peak_week_results$analysis_time_season_week == peak_timing_pred_dist_by_analysis_time$analysis_time_season_week[row_ind],
#                    paste0("peak_week_", seq_len(10000))] ==
#                peak_timing_pred_dist_by_analysis_time$bin_number[row_ind]) / 10000
#    })
#
#
#
@

%\begin{figure}
%\caption{Predictive distributions for predictions of peak week incidence.  The
%horizontal dashed line is at the observed peak incidence for the season.  The
%vertical dashed line is at the observed peak week for the season.}
%\label{fig:FluPeakWeekHeightPredictiveDistributions}
%<<FluPlotPeakWeekHeightPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%junk <- "junk2"
%
%ggplot() +
%    geom_raster(aes(x = analysis_time_season_week, y = bin_center, fill = est_prob),
%        data = peak_height_pred_dist_by_analysis_time[peak_height_pred_dist_by_analysis_time$full_model_descriptor %in% models_used, ]) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = ili_peak_week_times) +
%    geom_hline(aes(yintercept = peak_height), colour = "red", linetype = 2, data = ili_peak_week_heights) +
%    geom_point(aes(x = analysis_time_season_week, y = median_peak_height),
%        colour = "red",
%        data = peak_timing_and_height_pred_dist_means_by_analysis_time[peak_timing_and_height_pred_dist_means_by_analysis_time$full_model_descriptor %in% models_used, ]) +
%    scale_fill_gradientn("Predictive\nDistribution\nProbability",
%        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        limits = c(10^{-10}, 1),
%        trans = "log",
%#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%        na.value = "white"
%    ) +
%    facet_grid(analysis_time_season ~ full_model_descriptor,
%        labeller = as_labeller(function(labels, ...) {
%                labels[labels == "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"] <- "SARIMA"
%                labels[labels == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"] <- "KCDE"
%                return(labels)
%            })) +
%    ylab("Peak Incidence") +
%    xlab("Season Week at Analysis Time") +
%    theme_bw()
%@
%\end{figure}

















% , dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots")
%<<DengueObtainPeakWeekTimingPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
%dengue_incidence_bins <- data.frame(
%    lower = seq(from = 0, to = 500, by = 50),
%    upper = c(seq(from = 50, to = 500, by = 50), Inf))
%  
%for(bin_num in seq(from = 1, to = 52)) {
%    dengue_peak_week_results[, paste0("est_prob_bin_", bin_num)] <-
%        apply(dengue_peak_week_results[, paste0("peak_week_", seq_len(10000))],
%            1,
%            function(x) {sum(x == bin_num) / length(x)})
%}
%
%peak_timing_pred_dist_by_analysis_time_dengue <- dengue_peak_week_results %>%
%    select(full_model_descriptor,
%            analysis_time_season,
%            analysis_time_season_week,
%            starts_with("est_prob_bin_")) %>%
%    gather_("bin", "est_prob", paste0("est_prob_bin_", seq(from = 1, to = 52)))
%peak_timing_pred_dist_by_analysis_time_dengue$bin <-
%    as.integer(substr(peak_timing_pred_dist_by_analysis_time_dengue$bin, 14, 15))
%
%
%#junkjunkjunk <-    peak_timing_pred_dist_by_analysis_time[
%#        peak_timing_pred_dist_by_analysis_time$full_model_descriptor == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full" &
%#        peak_timing_pred_dist_by_analysis_time$bin ==
%#            peak_week_times$peak_week[
%#                sapply(peak_timing_pred_dist_by_analysis_time$analysis_time_season,
%#                    function(season_val) {
%#                        which(peak_week_times$analysis_time_season == season_val)
%#                    })
%#        ],
%#        c("est_prob", "analysis_time_season", "analysis_time_season_week")
%#    ] %>%
%#    mutate(log_score = log(est_prob))
%#
%#junkjunkjunk <- 
%#    junkjunkjunk[
%#        order(junkjunkjunk$analysis_time_season,
%#            junkjunkjunk$analysis_time_season_week), ]
%#
%#junkjunkjunkjunk <- dengue_peak_week_results[
%#    dengue_peak_week_results$full_model_descriptor == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%#    c("peak_week_log_score", "analysis_time_season", "analysis_time_season_week")
%#]
%#
%#junkjunkjunkjunk <- 
%#    junkjunkjunkjunk[
%#        order(junkjunkjunkjunk$analysis_time_season,
%#            junkjunkjunkjunk$analysis_time_season_week), ]
%#
%#tapply(peak_timing_pred_dist_by_analysis_time$est_prob,
%#    peak_timing_pred_dist_by_analysis_time[,
%#        c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week")],
%#    sum)
% 
%peak_timing_and_height_pred_dist_means_by_analysis_time_dengue <- 
%    dengue_peak_week_results %>%
%    select(full_model_descriptor,
%        analysis_time_season,
%        analysis_time_season_week,
%        starts_with("est_prob_bin_")) %>%
%    mutate(
%        mean_peak_week = apply(dengue_peak_week_results[, paste0("peak_week_", seq_len(10000))],
%            1,
%            mean),
%        median_peak_week = apply(dengue_peak_week_results[, paste0("peak_week_", seq_len(10000))],
%            1,
%            median),
%        mean_peak_height = apply(dengue_peak_week_results[, paste0("unbinned_peak_height_", seq_len(10000))],
%            1,
%            mean),
%        median_peak_height = apply(dengue_peak_week_results[, paste0("unbinned_peak_height_", seq_len(10000))],
%            1,
%            median)
%    )
%
%#peak_timing_pred_dist_by_analysis_time <- dengue_peak_week_results %>%
%#    mutate(count_)
%#    select_(c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week"))
%#
%#
%#
%#peak_timing_pred_dist_by_analysis_time <-
%#    as.data.frame(expand.grid(
%#            model = c(
%#                "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%#                "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"),
%#            analysis_time_season = unique(dengue_peak_week_results$analysis_time_season),
%#            analysis_time_season_week = seq(from = 10, to = 40),
%#            bin_number = seq(from = 10, to = 40),
%##        incidence_bin = seq_len(nrow(dengue_incidence_bins)),
%#            stringsAsFactors = FALSE
%#        ))
%#peak_timing_pred_dist_by_analysis_time$est_bin_prob <- sapply(
%#    seq_len(nrow(peak_timing_pred_dist_by_analysis_time)),
%#    function(row_ind) {
%#        sum(dengue_peak_week_results[
%#                    dengue_peak_week_results$full_model_descriptor == peak_timing_pred_dist_by_analysis_time$model[row_ind] &
%#                        dengue_peak_week_results$analysis_time_season == peak_timing_pred_dist_by_analysis_time$analysis_time_season[row_ind] &
%#                        dengue_peak_week_results$analysis_time_season_week == peak_timing_pred_dist_by_analysis_time$analysis_time_season_week[row_ind],
%#                    paste0("peak_week_", seq_len(10000))] ==
%#                peak_timing_pred_dist_by_analysis_time$bin_number[row_ind]) / 10000
%#    })
%#
%#
%#
%@

%, dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots")
%\begin{figure}
%\caption{Predictive distributions for predictions of peak week timing for
%Dengue.  The horizontal and vertical dashed lines are at the observed peak week
%for the season.}
%\label{fig:DenguePeakWeekTimingPredictiveDistributions}
%<<DenguePlotPeakWeekTimingPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%
%#peak_timing_pred_dist_by_analysis_time$est_prob[
%#    peak_timing_pred_dist_by_analysis_time$est_prob == 0] <- 10^{-20}
%#peak_timing_pred_dist_by_analysis_time$est_prob[
%#    peak_timing_pred_dist_by_analysis_time$est_prob == 10^{-20}] <- 0
%
%#min(
%#    peak_timing_pred_dist_by_analysis_time$est_prob[
%#        peak_timing_pred_dist_by_analysis_time$est_prob != 0 &
%#            peak_timing_pred_dist_by_analysis_time$full_model_descriptor %in% models_used]
%#)
%
%ggplot() +
%    geom_raster(aes(x = analysis_time_season_week, y = bin, fill = est_prob),
%        data = peak_timing_pred_dist_by_analysis_time_dengue[peak_timing_pred_dist_by_analysis_time_dengue$full_model_descriptor %in% models_used, ]) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = dengue_peak_week_times) +
%    geom_hline(aes(yintercept = peak_week), colour = "red", linetype = 2, data = dengue_peak_week_times) +
%    geom_point(aes(x = analysis_time_season_week, y = median_peak_week),
%        colour = "red",
%        data = peak_timing_and_height_pred_dist_means_by_analysis_time_dengue[peak_timing_and_height_pred_dist_means_by_analysis_time_dengue$full_model_descriptor %in% models_used, ]) +
%    scale_fill_gradientn("Predictive\nDistribution\nProbability",
%        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        limits = c(10^{-10}, 1),
%        trans = "log",
%#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%#        labels = c(0.0001, 0.001, 0.01, 0.1, 1),
%        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%        na.value = "white"
%    ) +
%    facet_grid(analysis_time_season ~ full_model_descriptor,
%        labeller = as_labeller(function(labels, ...) {
%            labels[labels == "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"] <- "SARIMA"
%            labels[labels == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"] <- "KCDE"
%            return(labels)
%        })) +
%    xlab("Season Week at Analysis Time") +
%    ylab("Season Week at Peak Incidence") +
%    theme_bw()
%@
%\end{figure}



%, dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots")
<<DengueObtainPeakWeekHeightPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
dengue_incidence_bins <- data.frame(
    lower = seq(from = 0, to = 500, by = 50),
    upper = c(seq(from = 50, to = 500, by = 50), Inf),
    center = seq(from = 25, to = 525, by = 50))

for(bin_num in seq_len(nrow(dengue_incidence_bins))) {
    dengue_peak_week_results[, paste0("est_prob_bin_", bin_num)] <-
        apply(dengue_peak_week_results[, paste0("peak_height_", seq_len(10000))],
            1,
            function(x) {sum(x == bin_num) / length(x)})
}

peak_height_pred_dist_by_analysis_time_dengue <- dengue_peak_week_results %>%
    select(full_model_descriptor,
            analysis_time_season,
            analysis_time_season_week,
            starts_with("est_prob_bin_")) %>%
    gather_("bin", "est_prob", paste0("est_prob_bin_", seq_len(nrow(dengue_incidence_bins))))
peak_height_pred_dist_by_analysis_time_dengue$bin <-
    as.integer(substr(peak_height_pred_dist_by_analysis_time_dengue$bin, 14, 15))
peak_height_pred_dist_by_analysis_time_dengue$bin_center <-
    dengue_incidence_bins$center[peak_height_pred_dist_by_analysis_time_dengue$bin]


#peak_timing_pred_dist_by_analysis_time <- dengue_peak_week_results %>%
#    mutate(count_)
#    select_(c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week"))
#
#
#
#peak_timing_pred_dist_by_analysis_time <-
#    as.data.frame(expand.grid(
#            model = c(
#                "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
#                "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"),
#            analysis_time_season = unique(dengue_peak_week_results$analysis_time_season),
#            analysis_time_season_week = seq(from = 10, to = 40),
#            bin_number = seq(from = 10, to = 40),
##        incidence_bin = seq_len(nrow(dengue_incidence_bins)),
#            stringsAsFactors = FALSE
#        ))
#peak_timing_pred_dist_by_analysis_time$est_bin_prob <- sapply(
#    seq_len(nrow(peak_timing_pred_dist_by_analysis_time)),
#    function(row_ind) {
#        sum(dengue_peak_week_results[
#                    dengue_peak_week_results$full_model_descriptor == peak_timing_pred_dist_by_analysis_time$model[row_ind] &
#                        dengue_peak_week_results$analysis_time_season == peak_timing_pred_dist_by_analysis_time$analysis_time_season[row_ind] &
#                        dengue_peak_week_results$analysis_time_season_week == peak_timing_pred_dist_by_analysis_time$analysis_time_season_week[row_ind],
#                    paste0("peak_week_", seq_len(10000))] ==
#                peak_timing_pred_dist_by_analysis_time$bin_number[row_ind]) / 10000
#    })
#
#
#
@

%\begin{figure}
%\caption{Predictive distributions for predictions of peak week incidence for
%Dengue.  The horizontal dashed line is at the observed peak incidence for the
%season.  The vertical dashed line is at the observed peak week for the season.}
%\label{fig:DenguePeakWeekHeightPredictiveDistributions} %, dependson = c("DengueDataMergePeakWeekPredictionResults", "DengueDataPeakWeekPredictionBoxPlots", "DengueObtainPeakWeekHeightPredictiveDistributionsByAnalysisTime")
%<<DenguePlotPeakWeekHeightPredictiveDistributionsByAnalysisTime, echo = FALSE, cache = FALSE>>=
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c(
%    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
%    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
% 
%ggplot() +
%    geom_raster(aes(x = analysis_time_season_week, y = bin_center, fill = est_prob),
%        data = peak_height_pred_dist_by_analysis_time_dengue[peak_height_pred_dist_by_analysis_time_dengue$full_model_descriptor %in% models_used, ]) +
%    geom_vline(aes(xintercept = peak_week), colour = "red", linetype = 2, data = dengue_peak_week_times) +
%    geom_hline(aes(yintercept = peak_height), colour = "red", linetype = 2, data = dengue_peak_week_heights) +
%    geom_point(aes(x = analysis_time_season_week, y = median_peak_height),
%        colour = "red",
%        data = peak_timing_and_height_pred_dist_means_by_analysis_time_dengue[peak_timing_and_height_pred_dist_means_by_analysis_time_dengue$full_model_descriptor %in% models_used, ]) +
%    scale_fill_gradientn("Predictive\nDistribution\nProbability",
%        colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
%#        limits = c(10^{-10}, 1),
%        trans = "log",
%#        values = c(0, seq(from = exp(-10), to = 1, length = 15))) +
%#        values = c(0, exp(seq(from = log(10^-3), to = log(1), length = 15)))
%#        values = c(0, exp(seq(from = log(5 * 10^-4), to = log(1), length = 15)))
%        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
%        labels = c(expression(10^{-4}), expression(10^{-3}), expression(10^{-2}), expression(10^{-1}), "1   "),
%        na.value = "white"
%    ) +
%    facet_grid(analysis_time_season ~ full_model_descriptor,
%        labeller = as_labeller(function(labels, ...) {
%                labels[labels == "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"] <- "SARIMA"
%                labels[labels == "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"] <- "KCDE"
%                return(labels)
%            })) +
%    ylab("Peak Incidence") +
%    xlab("Season Week at Analysis Time") +
%    theme_bw()
%@
%\end{figure}


%\lboxit{To do: Put figures 8 - 11 in supplemental materials, possibly pull out
%1 to 4 sub-panels for further discussion?}





\section{Conclusions}

Prediction of infectious disease incidence at horizons of more than a few weeks
is a challenging task.  We have presented a non-parametric approach to doing
this based on KCDE and copulas and found that it is a viable method that
can yield improved predictions relative to commonly employed methods in this
field.  In predicting incidence of dengue fever in individual weeks, we saw that
our approach offered consistent and substantial performance gains relative to a
SARIMA model.  These improvements were particularly concentrated in the times
that are of most interest to public health decision makers: periods of high
incidence near the season peak.  For predicting influenza-like illness, our
method did about as well as SARIMA when predicting incidence in individual
weeks.

We believe that the difference in relative performance of KCDE and SARIMA for
prediction in the dengue and influenza data sets can be explained to a great
extent by differences in the underlying disease processes and how they relate to
the differing model specifications.  The most salient difference between the two
time series depicted in Figure~\ref{fig:IntialDataPlots} is the much greater
season-to-season variablility in the dengue data set relative to the influenza
data set.  For dengue, the peak incidence in the largest season is about 30
times larger than the peak incidence in the smallest season; this ratio is only
about 3 for influenza.  It may be the case that the restrictive linear
structure of the SARIMA model means that it is not able to capture the dynamics
of dengue incidence accurately.  Relaxing that structure by using a
nonparametric approach such as KCDE may yield improved capability to represent
the disease dynamics.  This is less of an issue in predicting influenza where
there is much more consistency across different seasons.

%dengue_max_by_season <- tapply(dengue_sj$total_cases, dengue_sj$season, max)
%max(dengue_max_by_season) / min(dengue_max_by_season)
%ili_max_by_season <- tapply(ili_national$weighted_ili,
%as.factor(ili_national$season), max, na.rm = TRUE)
%max(ili_max_by_season) / min(ili_max_by_season)

Another more subtle effect is present in the influenza data: there is a
consistent short-term peak in influenza incidence on Christmas week.  This is
visible in Figure~\ref{fig:IntialDataPlots}, and is highlighted in Figure *** in
the supplement.  This ``Christmas effect'' sometimes coincides with
the season peak, but sometimes occurs before the season peak.  We have observed
evidence that the seasonal structure of the SARIMA model picks up on this
structure, and SARIMA tended to outperform KCDE on Christmas week and the weeks
immediately thereafter on the influenza data set.  We believe that it would be
possible to construct a variation on KCDE that captures this effect, for example
by including indicator variables for the weeks around Christmas as conditioning
variables.  However, we have not explored that avenue in this work.

We have also demonstrated that it is feasible to use KCDE in combination with
copulas to obtain predictions for the timing of and incidence in the week of the season with the
highest incidence.  For those prediction targets, our method was competitive
with SARIMA; we did better in some of the test seasons and worse in others,
with no clear indication that either model was better than the other.

One explanation for the difference in relative performance of the methods on
these different prediction tasks may lie in the connection between the objective
function used in parameter estimation and the prediction task.  
We estimated the bandwidth parameters for KCDE by optimizing the log score of
predictive distributions for incidence in individual weeks in the training data
set.  This is the prediction target where KCDE outperformed SARIMA on the dengue
data set.  It may be the case that performance on the other two prediction tasks
could be improved by implementing a combined one-stage estimation
strategy for both the KCDE and copula parameters that optimizes a measure of
performance on the specific prediction task at hand.

Our implementation of KCDE offers two main methodological improvements
relative to previous implementations.  Most importantly in the context of
modeling infectious disease, we have introduced the use of a periodic kernel
component that captures seasonality.  In both of our applications, including
this periodic kernel component in the KCDE specification led to substantial 
improvements in the predictive distributions for incidence in individual weeks.
We also introduced a method for obtaining kernel functions that are appropriate
for use with discrete data while allowing for a fully parameterized bandwidth
matrix.  In our applications, using a fully parameterized bandwidth matrix did
not lead to consistent improvements in predictions.  However, we have
demonstrated through a simulation study that the fully parameterized bandwidth
can be helpful in some conditional density estimation tasks.  This general
method for obtaining discrete kernel functions may be beneficial in other applications of KCDE.

There is a great deal of room for extensions and improvements to the methods we
have outlined in this article.  One major limitation of our work lies in the
selection of conditioning variables for the predictive model.  We have simply
used incidence at the two most recent time points, and possibly the observation
time, as conditioning variables.  We considered using a stepwise
variable selection approach to select the model specification as in (cite ***),
but we found this to be too computationally expensive to be practical.

Another possibility for addressing this problem would be to replace
variable selection with shrinkage.  Hall \etal\cite{hall2004crossvalidationKCDE}
show that when cross-validation is used to select the bandwidth parameters in KCDE using product kernels, the estimated
bandwidths corresponding to irrelevant conditioning variables tend to infinity
asymptotically as the sample size increases.
%They discuss the fact that similar
%results could be obtained for linear combinations of continuous variables if a
%full bandwidth matrix were used.  A difficulty with relying on cross-validation
%to eliminate irrelevant conditioning variables is that we may not have a large
%enough sample size for this asymptotic argument to be relevant.
We conjecture
that by introducing an appropriate penalty on the elements bandwidth
matrix, we could include more (possibly
irrelevant) conditioning variables in the model without requiring
a dramatically larger sample size.  In particular, we hypothesize that a
penalty on the inverse of the bandwidth matrix encouraging it to have small
eigenvalues could be helpful.  If successful, this would also enable further
exploration of using other predictive variables (such as weather) in the model.
%A similar effect could be achieved in
%a Bayesian framework by using Dirichlet process mixtures with informative priors
%on the mixture component covariances.
%Our approach for obtaining kernels that can be
%used with mixed discrete and continuous variables opens up an opportunity to
%extend this analysis to that case; we have not pursued this mathematical
%analysis here.

Another aspect of our method that should be explored further is the use of
log score in estimation.  We used log scores in this work in order to match the use
of log scores in evaluating and comparing the performance of different models. 
The log score has the advantage of defining a proper scoring
rule, but it has the disadvantage of being sensitive to outlying values.
Previous authors have suggested the use of other loss functions in estimation
for kernel-based density estimation methods that reduce these effects, such as
variations on integrated squared error that were used by **** cite cite cite.

%We could also make some tweaks to our implementation of KCDE.  One
%limitation of our current implementation is its sensitivity to edge
%effects.  A possibility for addressing this would be to adopt locally linear
%or polynomial mean functions.  Approaches along these lines have been explored
%by Cite Hyndman, Bashtannyk, Grunwald - "Estimating and Visualizing Conditional Densities", maybe also Fan and Yim - "A crossvaildation
%method for estimating conditional densities" and Fan et al. 1996 "Estimation of
%conditional densities and sensitivity measures in nonlinear dynamical systems."

There is also a long history of using other modeling approaches such as
compartmental models for infectious disease prediction.  A full discussion of
those methods is beyond the scope of this article; see Brown et {al.}\cite{brown2016IDPredictionReview}
for a recent review.  KCDE is distinguished from these approaches in that it
makes minimal assumptions about the data generating process.  This can be
either an advantage or a disadvantage of KCDE.  In general, we would expect a
well-specified parametric model to outperform KCDE.  On the other hand, because
non-parametric approaches such as KCDE make fewer assumptions about the data
generating process, they may outperform incorrectly specified parametric models.
%In general, flexible non-parametric methods such as KCDE exhibit low
%bias but high variance.  If they are correctly specified, models with more
%structure may achieve reduced variance without introducing bias.
%On the other hand,   An
An evaluation of the benefits of an approach such as KCDE is therefore dependent
on the particular characteristics of the system being modeled, the data that are
available, and the quality of the models that are considered as alternatives.

\lboxit{FIX CITATION INFO FOR LEXI'S REVIEW PAPER OR FIND AN ALTERNATIVE}

However, rather than selecting one ``preferred'' modeling framework or
model formulation, we believe it may be fruitful to incorporate the models
developed in this paper as components of an ensemble method with several
different types of models.  For example, in our application to influenza, we saw
that the SARIMA model captured some features of the data generating process,
such as the Christmas-week effect, that KCDE did not capture.  On the other
hand, the KCDE approach was more flexible and yielded better predictions than
SARIMA at other times -- most notably, in periods of high incidence in the
application to dengue.  An appropriately constructed ensemble incorporating
predictions from both SARIMA and KCDE as well as other methods such as
mechanistic models might perform better than any of these models on its own,
and would be a valuable approach for maximizing the utility of these
predictions to public health decision makers.

\bibliographystyle{plainnat}
\bibliography{kde-bib}


\end{document}