\documentclass[Crown, sagev]{sagej}

\usepackage{amssymb, amsmath, amsfonts}


\include{GrandMacros}
\newcommand{\cdf}{{c.d.f.} }
\newcommand{\pdf}{{p.d.f.} }
\newcommand{\ind}{\mathbb{I}}

\begin{document}

\title{Infectious disease prediction with kernel conditional density
estimation}

\author{Evan L. Ray\affilnum{1},
Krzysztof Sakrejda\affilnum{1},
Stephen A. Lauer\affilnum{1},
Michael Johansen\affilnum{2} and
Nicholas G. Reich\affilnum{1}}

\affiliation{\affilnum{1}Department of Biostatistics and Epidemiology,
University of Massachusetts, Amherst\\
\affilnum{2}CDC, Puerto Rico}

\corrauth{Evan Ray, UMass Address Here}

\email{elray@umass.edu}

\begin{abstract}
Abstract
\end{abstract}
\keywords{copula, infectious disease, kernel conditional density estimation,
prediction}

\maketitle

<<knitrGlobalSetup, echo = FALSE>>=
library(cdcfluview)

library(reshape2)
library(plyr)
library(dplyr)
library(tidyr)
library(lubridate)

library(ggplot2)
library(grid)

library(kcde)

#opts_chunk$set(cache = TRUE, autodep = TRUE)
opts_chunk$set(cache = FALSE)
@

\section{Introduction}
\label{sec:Intro}

Accurate prediction of infectious disease incidence is important for public
health officials planning disease prevention and control measures such as vector
control and increased use of personal protective equipment by medical
personnel during periods of high disease incidence (cite ***).  Several
quantities have emerged as being of particular utility in making these planning decisions (cite ***); in this article we focus
on measures of weekly incidence, the timing of the season peak, and incidence
in the peak week.  Predictive distributions for these quantities are preferred
to point predictions because they communicate uncertainty in the predictions and
give decision makers more information in cases where the predictive distribution
is skewed or has multiple modes.
In this work, we employ a non-parametric approach referred to as kernel
conditional density estimation (KCDE) to obtain separate predictive
distributions for disease incidence in each week of the season, and then combine
those marginal distributions using copulas to obtain joint predictive distributions for the
trajectory of incidence over the course of multiple weeks.  Predictive
distributions relating to the timing of and incidence at the peak week can be
obtained from this joint predictive distribution for the trajectory of
disease incidence.
In addition to the novel application of these methods to predicting disease incidence, our contributions include the use of a periodic kernel specification to capture
seasonality in disease incidence and a method for obtaining multivariate
kernel functions that handle discrete data while allowing for a fully
parameterized bandwidth matrix.

KCDE is a method for estimating the conditional distribution of
a random vector $\bY$ given observations of another vector $\bX$.  In our work,
$\bY$ is a measure of disease incidence at some future date (the prediction
target) and $\bX$ is a vector of predictive variables that we condition
on in order to make our prediction.  In our example applications,
$\bX$ includes observations of incidence over several recent time
points and variables indicating the time of year at which we are
making a prediction; in general, it would be possible to include other
variables such as weather covariates.

KCDE has not previously been applied to obtain predictive distributions in the
context of infectious disease, but it has been successfully used for prediction in other settings such as survival time of
lung cancer patients\cite{hall2004crossvalidationKCDE}, female labor force
participation\cite{hall2004crossvalidationKCDE}, bond yields and value at risk
in financial markets\cite{fan2004crossvalidationKCDE}, and wind
power\cite{jeon2012KCDEWindPower} among others.  Although KCDE has not
previously been applied to predicting infectious disease, closely related methods for obtaining point predictions have been employed for
diseases such as measles\cite{sugihara1990nonlinearForecasting} and
influenza\cite{viboud2003predictionInfluenzaMoA}.  In the infectious disease
literature these methods have been referred to as state space reconstruction and
the method of analogues, but they amount to an application of nearest neighbors
regression methods.  The point prediction obtained from nearest neighbors
regression is equal to the expected value of the predictive distribution
obtained from KCDE if a particular kernel function is used in the formulation of
KCDE\cite{HastieTibshiraniESL}.  However, KCDE offers the advantage of providing
a complete predictive distribution rather than only a point prediction.  Methods
similar to those we explore in this article can also be formulated in the
Bayesian framework.  One example along these lines is Zhou et
{al.}\cite{zhou2015DirichletProcessCopulaAmphibianDiseaseArrival}, who model the
time to arrival of a disease in amphibian populations using Dirichlet
processes and copulas.

There is also a long history of using other modeling approaches such as
compartmental models for infectious disease prediction.  A full discussion of
those methods is beyond the scope of this article; see *** for a recent review. 
KCDE is distinguished from these alternative approaches in that it makes
minimal assumptions about the data generating process.  This can be
either an advantage and a disadvantage of KCDE.
In general, flexible non-parametric methods such as KCDE exhibit low
bias but high variance.  If they are correctly specified, models with more
structure may achieve reduced variance without introducing bias.
On the other hand, because non-parametric approaches such as KCDE make fewer
assumptions they may outperform incorrectly specified parametric models.  An
evaluation of the benefits of an approach such as KCDE is therefore dependent on
the particular characteristics of the system being modeled, the data that are
available, and the quality of the more structured parametric models that are
considered as alternatives.  We will return to this point in our conclusions.

\lboxit{Need to find a review of prediction methods for infectious disease.}

%There is an extensive literature on KCDE, focusing mainly on estimation of
%continuous conditional densities.  Here we offer a brief overview emphasizing
%the case with mixed continuous and discrete variables; Li and
%Racine\cite{li2007nonparametricEconometrics} offer a detailed discussion of this
%case.

To our knowledge, all previous authors using kernel methods to estimate
multivariate densities involving discrete variables have employed a kernel
function that is a product of univariate kernel functions \cite{aitchison1976multivariateBinaryKernel,
wang1981SmoothEstDiscreteDistn,
li2003nonparametricEstDistnsCategoricalContinuous,
ouyang2006crossvalidationEstDistnCategorical}.
A variety of functional forms have been proposed for this purpose, including
geometric, triangular and Poisson among others
\cite{aitchison1976multivariateBinaryKernel, wang1981SmoothEstDiscreteDistn, li2008nonparametricConditionalCDFQuantile, li2003nonparametricEstDistnsCategoricalContinuous,
ouyang2006crossvalidationEstDistnCategorical}.

%\cite{wang1981SmoothEstDiscreteDistn},
%\cite{li2008nonparametricConditionalCDFQuantile}\cite{li2003nonparametricEstDistnsCategoricalContinuous},
% \cite{ouyang2006crossvalidationEstDistnCategorical}].

Using a product kernel simplifies the mathemetical formulation of the kernel
function when discrete variables are present, but has the
effect of forcing the kernel function to be orientied in line with the
coordinate axes.  In settings with only continuous variables, asymptotic
analysis and experience with applications have shown that using a multivariate
kernel function with a bandwidth parameterization that allows for
other orientations can result in improved density estimates
in many cases (cite ***).  We introduce an approach to allowing for discrete
kernels with orientation by discretizing an underlying continuous kernel
function.
%One possibility for introducing orientation
%to the kernel function is to use a fully parameterized
%bandwidth matrix, allowing the kernel to be oriented in any direction.  Another
%common alternative is to fix the orientation to be in the directions of the
%eigenvectors of the sample covariance matrix.

%Estimation.  Two main strategies:  cross validation and rule-based.  Targets
% for optimization in cross-validation.  For
%estimating joint densities without
%conditioning, \cite{hart1990bandwidthEstDependentData} have shown that with
%dependent data, but small gains in the mean integrated square error of the
%density estimate relative to the true conditional density can be achieved by
%leaving out observations adjacent to the time point whose density is being
%estimated.

A limitation of kernel-based density estimation methods is that they may not
scale well with the dimension of the vector whose distribution is being
estimated.  This is particularly relevant in our application, where it is
desired to obtain joint predictive distributions for disease incidence over the
course of many weeks.  Copulas present one strategy for estimating the joint
distribution of moderate to high dimensional random vectors, and work by
specifying a relatively simple parametric model for the dependence relations
among those variables.  Specifically, we model the joint distribution of $Y_1,
\ldots, Y_D$ by $F_{Y_1, \ldots, Y_D}(y_1, \ldots, y_D) = C(F_{Y_1}(y_1),
\ldots, F_{Y_D}(y_D) ; \bxi)$.  Here $C: [0,1]^D \rightarrow [0,1]$ is
the copula function depending on parameters $\bxi$ and mapping the vector
of marginal {c.d.f.} values to the joint {c.d.f.} value.

It would be possible to handle
this task using just the formulation of KCDE we discussed above, but a
direct application of this approach has some limitations.  First, the
performance of kernel-based density estimation methods scales poorly with the
dimension of the random vector whose density is being estimated (cite ***). 
Second, we have found that different information is available in the data at
different prediction horizons.  For example, we will demonstrate in our
applications below that recently observed incidence is important for
making short-term predictions, but terms capturing seasonality are more
important for making long-term predictions.

%We make several contributions in this article.  First, we apply KCDE to
%prediction of infectious disease (specifically, Dengue fever and Influenza), a
%novel application of the method which gives rise to several challenges and
%opportunities.  Among these challenges is the fact that infectious disease
%incidence can be quite noisy, with a lot of variation around a longer term
%trend; we will illustrate this in two real data sets in Section ***.  As we will
%see, this noise can cause difficulty for the method when applied to prediction
%of future incidence directly from recent observations of incidence.  Our
%solution is to introduce an initial low-pass filtering step on the observed
%incidence counts that are used as inputs to the predictions.

%Another challenge is in capturing seasonality in disease incidence.  In order
%to address this, we consider the use of periodic functions of the observation
%time as conditioning variables.  Effectively, this means that we can base our
%predictive density on previous observations that have been recorded at the time
%of year we are interested in.

%A third challenge is that for some applications, observations of disease
%incidence may take the form of discrete counts (i.e., the number of new cases
%in the last week).  If these incidence counts span a large range, it may be
%reasonable to approximate their predictive distribution with a continuous
%density function.  However, in our data for Dengue fever, the number of cases
%often falls within a limited range so that this continuous approximation is not
%reasonable.  We address this by discretizing an underlying continuous density
%function.  To our knowledge, this approach is novel in the KCDE literature.

The remainder of this article is organized as follows.  We:
 - describe how kernel density estimation with a non-diagonal bandwidth can be
 achieved using a partially discretized multivariate normal distribution for the
 kernel functions.

 - simulation study comparing product and non-product formulations for marginal
 and conditional density estimation
 
 - applications

\section{Method Description}
\label{sec:Methods}

In this Section, we give a detailed discussion of our methods. Suppose we
observe a measure $z_t$ of disease incidence at each point in time $t = 1, \ldots, T$.
At time $t^*$, our model gives a
predictive distribution $f(z_{t^* + 1}, \ldots, z_{t^* + H} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M})$
for the trajectory of disease incidence over a range of prediction horizons
from $1$ to $H$ weeks in the future.  The time $t^*$ will typically be
equal to $T$ when we are applying the method to perform prediction, but takes
other values in the estimation procedure we describe below.  The predictive
distribution is conditional on the time at which we are making the predictions
and observed incidence at a few recent time points with lags given by the
non-negative integers $l_1, \ldots, l_M$.  It would also be possible to
condition on other covariates such as weather, but we have not pursued that line in this work.


%Throughout, we
%use the term density to refer to the Radon-Nikodym derivative of the
%cumulative distribution function with respect to an appropriately defined measure.
%In the case of random vectors where some
%components are continuous random variables and other are discrete, we take this
%measure to be a product of Lebesgue and counting measures for the corresponding
%random variables.  We use bold letters to indicate column vectors or matrices;
%capital letters are random variables and lower case letters are observations of those
%random variables.


%We estimate this joint predictive density in two stages.  First, we
%use KCDE to obtain separate predictive distributions for each prediction
%horizon $h = 1, \ldots, H$: $f(z_{T + h} | z_{1}, \ldots, z_{T}, T)$.  Next, we
%use a copula to combine these 

Our model represents this density as follows:
\begin{align*}
&f(z_{t^* + 1}, \ldots, z_{t^* + H} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}) = \\
&\qquad c^H\{f^{1}(z_{t^* + 1} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^1), \ldots, f^{H}(z_{t^* + H} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^H) ; \bxi^H\}.
\end{align*}%\label{eqn:ModelKCDECopula}
%In Equation~\eqref{eqn:ModelKCDECopula}, each
Here, each $f^{h}(z_{t^* + h} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^h)$
is a predictive density for one prediction horizon obtained through KCDE.  The
distribution for each prediction horizon depends on a separate parameter vector $\btheta^h$.
The function $c^H(\cdot)$ is a copula
used to tie these marginal predictive densities together into a joint predictive
density, and depends on parameters $\bxi^H$.  In our
applications, we will obtain a separate copula fit for each trajectory length
$H$ of interest for the prediction task.

Broadly, estimation for the model parameters proceeds in two stages:
first we estimate the parameters for KCDE separately for each prediction
horizon $h$, and second we estimate the copula parameters while holding the KCDE
parameters fixed.  The efficiency of two-stage estimation procedures for copula
models has been studied in the literature both theoretically and through
simulation studies.  In general the two-stage approach may result in some loss
of efficiency relative to one-stage methods, but this efficiency loss is be small
for some model specifications\cite{joe2005asymptoticEfficiencyTwoStageCopula}.
We pursue the two-stage strategy in this work because it results in a large
reduction in the computational cost of parameter estimation.

In the following subsections we describe the formulations of KCDE and
the copula in more detail and give our estimation strategy for each set of
model parameters.

\subsection{KCDE for Predictive Densities at Individual Prediction Horizons}
\label{subsec:Methods:KCDE}

We now discuss the methods we use to obtain the predictive density
$f^{h}(z_{t^* + h} | t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}; \btheta^h)$
for disease incidence at a particular horizon $h$ after time $t^*$.  In order to
simplify the notation we define two new variables: $Y_t^{h} = Z_{t + h}$ represents
the prediction target relative to time $t$, and $\bX_t = (t, Z_{t -
l_1}, \ldots, Z_{t - l_M})$ represents the vector of predictive
variables relative to time $t$.  With this notation, the distribution we wish to estimate is
$f^{h}(y_{t^*}^{h} | \bx_{t^*}; \btheta^h)$.

In order to estimate this distribution, we use the observed data to form the
pairs $(\bx_t, y_t^{h})$ for all $t = 1 + \max_m l_m, \ldots, T - h$;
for smaller values of $t$ there are not enough observations before $t$ to form
$\bx_t$ and for larger values of t there are not enough observations after $t$ to form
$y_t^{h}$.  We then regard these pairs as a (dependent) sample from the joint
distribution of $(\bX, Y^h)$ and estimate the conditional distribution of $Y^h | \bX$ via KCDE:
\begin{align}
&\widehat{f}^h(y^h_{t^*} | \bx_{t^*}) = \frac{\sum_{t \in \btau} K^{\bX, Y}\left\{(\bx_{t^*}, y^h_{t^*}), (\bx_t, y^h_t); \btheta^h \right\}}{\sum_{t \in \btau}K^{\bX}(\bx_{t^*}, \bx_t ; \btheta^h)} \label{eqn:KCDEDefinition} \\
&\qquad = \frac{\sum_{t \in \btau} K^{Y | \bX}(y^h_{t^*}, y^h_t | \bx_{t^*}, \bx_t; \btheta^h) K^{\bX}(\bx_{t^*}, \bx_t; \btheta^h)}{\sum_{t \in \btau} K^{\bX}(\bx_{t^*}, \bx_t; \btheta^h) } \label{eqn:KDESubKDEJtMarginal} \\
&\qquad = \sum_{t \in \btau} w^h_t K^{Y | \bX}(y^h_{t^*}, y^h_t | \bx_{t^*}, \bx_t; \btheta^h) \text{, where} \label{eqn:KDEwt} \\
&w^h_t = \frac{ K^{\bX}(\bx_{t^*}, \bx_t; \btheta^h) }{\sum_{s \in \btau} K^{\bX}(\bx_{t^*}, \bx_{s}; \btheta^h) } \label{eqn:KCDEWeightsDef}
\end{align}

Here we are working with a slightly restricted specification in which
the kernel function $K^{\bX, Y}$ can be written as the product of $K^{\bX}$ and a ``conditional kernel'' $K^{\bY|\bX}$.
With this restriction, we can
interpret $K^{\bX}$ as a weighting function determining how much each observation
$(\bx_t, y^h_t)$ contributes to our final density estimate according to how
similar $\bx_t$ is to the value $\bx_{t^*}$ that we are conditioning on.
For each $y^h_t$, $K^{\bY | \bX}$ is a density function that contributes
mass to the final density estimate near $y^h_t$.  The
parameters $\btheta^h$ control the locality and orientation of the weighting
function and the contributions to the density estimate from each observation.
In Equations \eqref{eqn:KCDEDefinition} through \eqref{eqn:KCDEWeightsDef},
$\btau \subseteq \{1 + \max_m l_m, \ldots, T - h\}$ indexes the subset of
observations used in obtaining the conditional density estimate; we return to
how this subset of observations is defined in the discussion of estimation
below.
%In practice, we have parameterized these matrices in terms of the Cholesky
% decomposition.
%; we further take the bandwidth matrix $\bB^X$ to be a sub-matrix of $\bB^{Y,X}$
%  Hall, Racine,
%and Li \cite{hall2004crossvalidationKCDE} say that this "does not adversely affect
%the rate of convergence of estimators..."

We take the kernel function $K^{Y, \bX}$ to be a product kernel with one
component being a periodic kernel in time and the other component capturing the
remaining covariates:
\begin{align}
&K^{\bX, Y}\left\{(\bx_{t^*}, y^h_{t^*}), (\bx_t, y^h_t); \btheta^h \right\} \nonumber \\
&\qquad = K^{\bX, Y}\left\{(t^*, z_{t^* - l_1}, \ldots, z_{t^* - l_M}, z_{t^* + h}), (t, z_{t - l_1}, \ldots, z_{t - l_M}, z_{t + h}); \btheta^h \right\} \nonumber \\
&\qquad = K^{Periodic}(t^*, t; \btheta^h) K^{Incidence}\{(z_{t^* - l_1}, \ldots, z_{t^* - l_M}, z_{t^* + h}), (z_{t - l_1}, \ldots, z_{t - l_M}, z_{t + h}); \btheta^h\} \nonumber
\end{align}

The periodic kernel function was originally developed in the
literature on Gaussian Processes\cite{mackay1998introductionGP}, and is defined by
\begin{equation}
K^{Periodic}(t^*, t; \rho, b) = \exp\left[- \frac{\sin^2\{\rho (t^* - t)\}}{2b^2} \right]. \label{eqn:PeriodicKernel}
\end{equation}
We illustrate this kernel function in Figure \ref{fig:PeriodicKernelPlot}. 
The kernel has two parameters: $\rho$, which determines the length of the
periodicity, and $b$, which determines the strength and locality of
of this periodic component in computing the observation weights $w_t^h$.
In our applications, we have fixed $\rho = \pi / 52$, so that the kernel has
period of length 1 year with weekly data.  Using this periodic kernel provides a
mechanism to capture seasonality in disease incidence by allowing the
observation weights to depend on the similarity of the time of year that an
observation was collected and the time of year at which we are making a prediction.

%  In the final density estimate, $\btau$ typically includes all
%available time points, but proper subsets are used in the cross-validation
%procedures we discuss later for parameter estimation.

%In order to do this, we employ kernel density estimation.  Let $K^{\bY}(\by, \by^*,
%H^{\bY})$ and $K^{\bX}(\bx, \bx^*, H^{\bX})$ be kernel functions centered at
%$\by^*$ and $\bx^*$ respectively and with bandwidth matrices $H^{\bY}$ and
%$H^{\bX}$.  We estimate the conditional distribution of $\bY | \bX$ as follows:
%\begin{align}
%&\widehat{f}_{\bY|\bX}(\by | \bX = \bx) = \frac{\widehat{f}_{\bY, \bX}(\by, \bx)}{\widehat{f}_{\bX}(\bx)} \label{eqn:KDECondDef} \\
%&\qquad = \frac{\sum_{t \in \tau} K^{\bY, \bX}\{(\by, \bx), (\by_t, \bx_t), H^{\bY, \bX}\}}{\sum_{t \in \tau} K^{\bX}(\bx, \bx_t, H^{\bX}) } \label{eqn:KDESubKDEJtMarginal} \\
%&\qquad = \frac{\sum_{t \in \tau} K^{\bY | \bX}(\by, \by_t | \bx, \bx_t, H^{\bY, \bX}) K^{\bX}(\bx, \bx_t, H^{\bX})}{\sum_{t \in \tau} K^{\bX}(\bx, \bx_t, H^{\bX}) } \label{eqn:KDESubKDEJtMarginal} \\
%&\qquad = \sum_{t \in \tau} w_t K^{\bY | \bX}(\by, \by_t | \bx, \bx_t, H^{\bY, \bX}) \text{, where} \label{eqn:KDEwt} \\
%&w_t = \frac{ K^{\bX}(\bx, \bx_t, H^{\bX}) }{\sum_{t^* \in \tau} K^{\bX}(\bx, \bx_{t^*}, H^{\bX}) } \label{eqn:KDEWeightsDef}
%\end{align}

%In Equation~\eqref{eqn:KDECondDef}, we are making use of the fact that the
% conditional density for $\bY | \bX$ can be written as the quotient of the joint density for $(\bY, \bX)$ and the marginal density for $\bX$.  In Equation~\eqref{eqn:KDESubKDEJtMarginal}, we obtain separate kernel density estimates for the joint and marginal densities in this quotient.  In Equation~\eqref{eqn:KDEwt}, we rewrite this quotient by passing the denominator of Equation~\eqref{eqn:KDESubKDEJtMarginal} into the summation in the numerator.  We can interpret the result as a weighted kernel density estimate, where each observation $t \in \tau$ contributes a different amount to the final conditional density estimate.  The amount of the contribution from observation $t$ is given by the weight $w_t$, which effectively measures how similar $\bx_t$ is to the point $\bx$ at which we are estimating the conditional density.  If $\bx_t^{(\bl^{max})}$ is similar to $\bx_{t^*}^{(\bl^{max})}$, a large weight is assigned to $t$; if $\bx_t^{(\bl^{max})}$ is different from $\bx_{t^*}^{(\bl^{max})}$, a small weight is assigned to $t$.

%In kernel density estimation, it is generally required that the kernel
% functions integrate to $1$ in order to obtain valid density estimates.  However, after conditioning on $\bX$, it is no longer necessary that $K^{\bX}(\bx, \bx_t, H^{\bX})$ integrate to $1$.  In fact, as can be seen from Equation~\eqref{eqn:KDEWeightsDef}, any multiplicative constants of proportionality will cancel out when we form the observation weights.  We can therefore regard $K^{\bX}(\bx, \bx_t, H^{\bX})$ as a more general weighting function that measures the similarity between $\bx$ and $\bx_t$.  As we will see, eliminating the constraint that $K^{\bX}$ integrates to $1$ is a useful expansion the space of functions that can be used in calculating the observation weights.  However, we still require that $K^{\bY}$ integrates to $1$.

%In Equations \eqref{eqn:KDECondDef} through \eqref{eqn:KDEWeightsDef}, $\tau$
% is an index set of time points used in obtaining the density estimate.  In most settings, we can take $\tau = \{1 + P + L, \ldots, T\}$.  These are the time points for which we can form the lagged observation vector $\bx_t$ and the prediction target vector $\by_t$.  However, we will place additional restrictions on the time points included in $\tau$ in the cross-validation procedure discussed in Section \ref{sec:Estimation}.

%In Equation~\eqref{eqn:KCDEDefinition}, if both $K^{\bX, \bY}$ and $K^{\bX}$
%integrate to 1 with respect to $\bx$ and $y$ then the numerator is a kernel
%density estimate of the joint density of $\bX$ and $\bY$ and the denominator
%is a kernel density estimate of the marginal density of $\bX$; forming the quotient yields an
%estimate of the conditional density of $\bY | \bX$.  However, it is not strictly
%required that 

%\begin{equation}
%K^{\bX,\bY}\left\{(\bx', \by')', (\bx'_t, \by'_t)'; \bH^{\bX,\bY}\right\} = K^{\bX}\left\{\bx, \bx_t; \bH^{\bX}\right\} K^{\bY | \bX}\left\{\by, \by_t | \bx, \bx_t; \bH^{\bX,\bY}\right\}.
%\end{equation}



%With this restriction, we can rearrange Equation~\eqref{eqn:KCDEDefinition} to
%obtain
%\begin{align}
%\widehat{f}_{\bY|\bX}(\by | \bx) &= \sum_{t \in \btau} w_t K^{\bY | \bX}\left\{\by, \by_t | \bx, \bx_t; \bH^{\bX,\bY}\right\}, \text{ where} \label{eqn:KCDEDefinitionWeighted} \\
%w_t &= \frac{K^{\bX}\left\{\bx, \bx_t; \bH^{\bX}\right\}}{\sum_{t^* \in \btau} K^{\bX}\left\{\bx, \bx_{t^*}; \bH^{\bX}\right\}}.
%\end{align}

%In order to complete the formulation of the KCDE estimator, we must specify the
%kernel function.  We take this kernel to be a product of two components.  The
%first is a periodic kernel in the time at which we are making the prediction,
%and allows us to capture seasonality in disease incidence within the KCDE
%framework.  

\begin{figure}
\caption{The periodic kernel function illustrated as a function of time in
weeks with $\rho = \pi / 52$ and three possible values for the bandwidth
parameter $h$.}
\label{fig:PeriodicKernelPlot}
<<PeriodicKernelPlot, echo = FALSE, fig.height = 2>>=
plot_df <- data.frame(t=seq_len(5 * 52))

kernel_center <- plot_df$t[nrow(plot_df)]
rho <- pi / 52

h <- 0.1
plot_df$kernel_h0.1 <- exp( -0.5 * (sin(rho * (kernel_center - plot_df$t)) / h)^2)

h <- 1
plot_df$kernel_h1 <- exp( -0.5 * (sin(rho * (kernel_center - plot_df$t)) / h)^2)

h <- 10
plot_df$kernel_h10 <- exp( -0.5 * (sin(rho * (kernel_center - plot_df$t)) / h)^2)

plot_df <- melt(plot_df, id.vars = "t")
plot_df$variable <- as.character(plot_df$variable)
plot_df$bandwidth <- "0.1"
plot_df$bandwidth[plot_df$variable == "kernel_h1"] <- "1"
plot_df$bandwidth[plot_df$variable == "kernel_h10"] <- "10"

ggplot(plot_df) +
    geom_line(aes(x = t, y = value, linetype = bandwidth, colour = bandwidth)) +
    geom_vline(xintercept = kernel_center) +
    scale_colour_manual("Bandwidth",
        breaks = c("0.1", "1", "10"),
        labels = c("0.1", "1", "10"),
        values = c("#E69F00", "#56B4E9", "#009E73")
    ) +
    scale_linetype("Bandwidth") +
    ylab("Kernel Function Value") +
    xlab("Time in Weeks") +
#    ggtitle("The Periodic Kernel") +
    theme_bw(base_size = 11)
@
\end{figure}

The second component of our kernel is a multivariate kernel incorporating
all of the other variables in $\bx_t$ and $y_t^h$.  In our
applications, these variables are measures of incidence, and are
continuous in the application to Influenza and discrete case counts in
the application to Dengue fever.  In the continuous case, we have used a
multivariate log-normal kernel function.  This kernel specification automatically
handles the restriction that counts are non-negative, and approximately
captures the long tail in disease incidence that we will illustrate in the
applications Section below.

\lboxit{functional form for multivariate log-normal?  discussion of bandwidth
matrix -- locality, orientation, parameterization in terms of $\btheta$?}

In the discrete case, we obtain the kernel function by discretizing an
underlying continuous kernel function:
\begin{align*}
&K^{Incidence}\{(z_{t^* - l_1}, \ldots, z_{t^* - l_M}, z_{t^* + h}), (z_{t -l_1}, \ldots, z_{t - l_M}, z_{t + h}); \btheta^h\} \\
&\qquad = \int_{a_{z_{t^* - l_1}}}^{b_{z_{t^* - l_1}}} \cdots \int_{a_{z_{t^* + h}}}^{b_{z_{t^* + h}}} L\{(w_1, \ldots, w_{M+1}), (z_{t -l_1}, \ldots, z_{t - l_M}, z_{t + h}); \btheta^h\} \, d w_{1} \cdots d w_{M+1}
\end{align*}
Here, the $w_m$ are dummy integration variables and $L(\cdot)$ is a continuous
multivariate kernel function; in our application we have used the multivariate
log-normal kernel as above.
For each component variable in $(z_{t^* - l_1}, \ldots, z_{t^* - l_M}, z_{t^* +
h})$, we associate lower and upper bounds of integration $a_{z_j}$ and $b_{z_j}$
with each value in the domain of that random variable.  The value of the
kernel function $K$ at $\bw$ is obtained by integrating over the hyper-rectangle
specified by these bounds.
In our application, the possible values of the random variables are integer
counts and the corresponding integration bounds are the half-integers.

%Here, $L(\bw, \bw^{*} ; \bH)$ is a continuous multivariate kernel function
%defined on $\prod_{j = 1}^{J} \mathcal{E}^j$.  For each discrete variable indexed by $j
%= 1, \ldots, J^d$, we associate lower and upper bounds of integration $a_{z_j}$
%and $b_{z_j}$ with each value $z_j \in \mathcal{D}^j$.  In order to ensure that
%our final density estimate integrates to $1$, we require that these integration
%bounds form a disjoint cover of $\mathcal{E}^j$ in the sense that $\cup_{z_j \in
%\mathcal{D}^j} [a_{z_j}, b_{z_j}) = \mathcal{E}^j$ and $\cap_{z_j \in
%\mathcal{D}^j} [a_{z_j}, b_{z_j}) = \emptyset$, the empty set.  At a vector of
%values $\bz \in \prod_{j = 1}^J \mathcal{D}^j$, we define the partially
%discretized kernel as follows:
%\begin{equation*}
%K(\bz, \bz^{*} ; \bH) = \int_{a_{z_1}}^{b_{z_1}} \cdots
%\int_{a_{z_{J^d}}}^{b_{z_{J^d}}} L(\bz, \bz^{*} ; \bH) \, d z_{1} \cdots d
%z_{J^d}
%\end{equation*}

%To make this concrete, consider a $J$-dimensional random
%vector $\bW = (\bW^{d'}, \bW^{c'})'$ that is partitioned into a
%$J^d$-dimensional subvector $\bZ^d$ of discrete random variables and a
%$J^c$-dimensional subvector $\bZ^c$ of continuous random variables.  Without
%loss of generality, we assume that the discrete variables are the first $J^d$
%variables.  For each component random variable $Z_j$, $j = 1, \ldots, J$, we
%denote the set of values that $Z_j$ may take by $\mathcal{D}^j \subseteq
%\mathbb{R}$.  In the continuous cases, we take $\mathcal{D}^j = \mathbb{R}$.  In
%the discrete cases, $\mathcal{D}^j$ is a discrete set such as the positive
%integers.  Our definitions could be modified to handle a component random
%variable whose distribution comprised a combination of discrete and continuous
%parts; however, this is not required for our applications so we have not pursued
%that line here.




%\begin{figure}[height=2in]

We use cross-validation to estimate the bandwidth parameters by numerically
minimizing a cross-validation measure of the quality of the predictions obtained
from the model.  Specifically, we use the log-score.
We leave out a year of data before and after the time $t^*$.  Hart and
Vieu\cite{hart1990bandwidthEstDependentData} show that when kernel density estimation is used to estimate a marginal density with dependent observations, leaving out multiple time points
around the target time point in cross validation can yield small improvements in
the ISE under certain assumptions about the form of the dependence.
%Formally,
%\begin{align}
%&(\widehat{\bu}, \widehat{H}^{\bX}, \widehat{H}^{\bY}) \approx \argmin{(\bu, H^{\bX}, H^{\bY})} \sum_{t^* = 1 + P + L}^T Q[ \by_{t^*}, \widehat{f}(\by | \bX = \bx_{t^*} ; \bu, H^{\bX}, H^{\bY}, \{ (\by_t, \bx_t): t \in \tau_{t^*} \}) ] \label{eqn:ParamEst}
%\end{align}
%Here, $Q$ is a loss function that measures the quality of the estimated density $\widehat{f}$ given an observation $\by_{t^*}$.  We have made the dependence of this estimated density on the the parameters $\bu$, $H^{\bx}$, and $H^{\bY}$, as well as on the data $\{ (\by_t, \bx_t): t \in \tau_{t^*} \}$, explicit in the notation.  In order to reduce the potential for our parameter estimates to be affected by local correlation in the time series, we eliminate all time points that fall within one year of $t^*$ from the index set $\tau_{t^*}$ used to form the conditional density estimate $\widehat{f}(\by | \bX = \bx_{t^*} ; \bu, H^{\bX}, H^{\bY}, \{ (\by_t, \bx_t): t \in \tau_{t^*} \})$.

\lboxit{Talk about proper scoring rules and our particular choice of $Q$. 
Criticism of bandwidth estimation by likelihood crossvalidation.  Relationship
to evaluation criteria.}

\subsection{Combining Marginal Predictive Distributions with Copulas}
\label{subsec:Methods:Copulas}

The approach we take for some of the prediction targets we examine in our
applications is to obtain a joint predictive distribution for disease incidence
over a sequence of multiple prediction horizons.  We do this by
using a copula to combine marginal predictive densities for each of those
prediction horizons.  Specifically, we us the isotropic Gaussian copula
implemented in the {\tt R}\cite{RCoreLanguage} package {\tt copula}
\cite{HofertRCopulaPackage}.

This copula function is given by
\begin{equation}
c(u_1, \ldots, u_J ; \btheta_c) = \Phi_{\Sigma}(\Phi^{-1}(u_1), \ldots, \Phi^{-1}(u_J)),
\end{equation}
where $\Phi^{-1}$ is the inverse {c.d.f.} of a standard univariate Gaussian
distribution and $\Phi_{\Sigma}$ is the {c.d.f.} of a multivariate Gaussian
distribution with mean $\b0$ and covariance matrix $\Sigma$.  We set $\Sigma =
[\sigma_{i,j}^2]$, where 
\begin{equation}
\sigma_{i,j}^2 = \begin{cases} 1 \text{ if $i = j$,} \\ \rho_d \text{ if $\vert i - j \vert = d$} \end{cases}
\end{equation}
Intuitively, $\rho_d$ captures the correlation of incidence at future times that
are $d$ weeks apart.

Estimation by maximum likelihood.

\section{Simulation Study}
\label{sec:SimStudy}

In this Section, we conduct two sets of simulation studies designed to answer
two separate questions:
\begin{enumerate}
\item How much does using a kernel function with a non-diagonal bandwidth matrix
contribute to the quality of conditional density estimates relative to density
estimates obtained through KCDE using diagonal bandwidth matrices?
\item How does our method perform in the context of seasonal time series data? 
Specifically, how does the method perform relative to common alternatives, and
how much do each of our three contributions (non-diagonal bandwidth matrices for
discrete data, using a periodic function of time as predictive variable, and
use of low band-pass filtered observatiosn as predictive variables) contribute
to predictive performance?
\end{enumerate}

\subsection{Comparison of KCDE approaches}
\label{sec:SimStudiesKCDEComparison}

Our first set of simulation studies is based closely on those conducted in
\cite{duong2005crossvalidationBandwidthMultivariateKDE}; their examples
demonstrate the utility of using a fully parameterized bandwidth matrix in
kernel density estimation of continuous distributions.  We modify their
simulation study to examine the benefits of fully parameterized bandwidth
matrices in the context of conditional density estimation with discrete
variables.

We simulate observations from each of seven distributions.  The first five of
these are plotted in Figure ***.


<<SimStudyDistributionsDiscretizedDuongHazelton>>=
library(ggplot2)
library(grid)
library(plyr)
library(dplyr)
library(tidyr)
library(pdtmvn)
library(kcde)
source("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/code/sim-densities-sim-study-discretized-Duong-Hazelton.R")

## Density family bivariate-A
n_sim <- 10000
discrete_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-A-discretized") %>%
    as.data.frame()
continuous_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-A") %>%
    as.data.frame()
discrete_sample_counts <- discrete_sample %>%
    count(X1, X2)

pa <- ggplot() +
    geom_density_2d(aes(x = X1, y = X2), data = continuous_sample) +
    geom_point(aes(x = X1, y = X2, colour = n), data = discrete_sample_counts)
pa

## Density family bivariate-B
n_sim <- 10000
discrete_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-B-discretized") %>%
    as.data.frame()
continuous_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-B") %>%
    as.data.frame()
discrete_sample_counts <- discrete_sample %>%
    count(X1, X2)

pb <- ggplot() +
    geom_density_2d(aes(x = X1, y = X2), data = continuous_sample) +
    geom_point(aes(x = X1, y = X2, colour = n), data = discrete_sample_counts)
pb

## Density family bivariate-C
n_sim <- 10000
discrete_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-C-discretized") %>%
    as.data.frame()
continuous_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-C") %>%
    as.data.frame()
discrete_sample_counts <- discrete_sample %>%
    count(X1, X2)

pc <- ggplot() +
    geom_density_2d(aes(x = X1, y = X2), data = continuous_sample) +
    geom_point(aes(x = X1, y = X2, colour = n), data = discrete_sample_counts)
pc

## Density family bivariate-D
n_sim <- 10000
discrete_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-D-discretized") %>%
    as.data.frame()
continuous_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "bivariate-D") %>%
    as.data.frame()
discrete_sample_counts <- discrete_sample %>%
    count(X1, X2)

pd <- ggplot() +
    geom_density_2d(aes(x = X1, y = X2), data = continuous_sample) +
    geom_point(aes(x = X1, y = X2, colour = n), data = discrete_sample_counts)
pd

## Density family multivariate-2d
n_sim <- 10000
discrete_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "multivariate-2d-discretized") %>%
    as.data.frame()
continuous_sample <- sim_from_pdtmvn_mixt(n = n_sim, sim_family = "multivariate-2d") %>%
    as.data.frame()
discrete_sample_counts <- discrete_sample %>%
    count(X1, X2)

pd <- ggplot() +
    geom_density_2d(aes(x = X1, y = X2), data = continuous_sample) +
    geom_point(aes(x = X1, y = X2, colour = n), data = discrete_sample_counts)
pd

@

\section{Applications}
\label{sec:Applications}

In this Section, we illustrate our methods through applications to prediction
of infectious disease in two examples with real disease incidence data sets: one
with a weekly measure of incidence of influenza like illness in the United
States, and a second with a weekly measure of incidence of Dengue fever in San
Juan, Puerto Rico.  These data sets were used in two recent prediction
competitions sponsored by the United States federal government. (cite something???)

We plot the data in Figure ***.  As indicated in the figure, we have divided
each data set into two subsets.  The first period is used as a training set in
estimating the model parameters.  The last four years of each data set are
reserved as a test set for evaluating model performance.

<<LoadFluData, echo = FALSE>>=
junk <- capture.output({
    usflu <- suppressMessages(get_flu_data("national", "ilinet", years=1997:2015))
})
ili_national <- suppressWarnings(transmute(usflu,
    region.type = REGION.TYPE,
    region = REGION,
    year = YEAR,
    week = WEEK,
    weighted_ili = as.numeric(X..WEIGHTED.ILI)))
ili_national$time <- ymd(paste(ili_national$year, "01", "01", sep = "-"))
week(ili_national$time) <- ili_national$week
ili_national$time_index <- seq_len(nrow(ili_national))

## Season column: for example, weeks of 2010 up through and including week 30 get season 2009/2010;
## weeks after week 30 get season 2010/2011
ili_national$season <- ifelse(
    ili_national$week <= 30,
    paste0(ili_national$year - 1, "/", ili_national$year),
    paste0(ili_national$year, "/", ili_national$year + 1)
)

## Season week column: week number within season
ili_national$season_week <- sapply(seq_len(nrow(ili_national)), function(row_ind) {
        sum(ili_national$season == ili_national$season[row_ind] &
                ili_national$time_index <= ili_national$time_index[row_ind])
    })


## Subset to data actually used in this analysis -- up through end of 2014.
ili_national <- ili_national[ili_national$year <= 2014, , drop = FALSE]

## cutoff time for training data
ili_train_cutoff_time <- ili_national$time[max(which(ili_national$year == 2010))]
@

<<LoadDengueData, echo = FALSE>>=
dengue_sj <- read.csv("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/data-raw/San_Juan_Testing_Data.csv")

## convert dates
dengue_sj$time <- ymd(dengue_sj$week_start_date)

## cutoff time for training data
dengue_train_cutoff_time <- dengue_sj$time[max(which(dengue_sj$season == "2008/2009"))]
@

\begin{figure}
\caption{Plots of the data sets we apply our methods to.  In each case, the last
four years of data are held out as a test data set; this cutoff is indicated
with a vertical dashed line.  For the flu data set, low-season incidence was not
recorded in early years of data collection; these missing data are indicated
with vertical grey bars.}
\label{fig:IntialDataPlots}
<<InitialDataPlot, echo = FALSE>>=
#time_limits <- c(min(c(ili_national$time, dengue_sj$time)),
#    max(c(ili_national$time, dengue_sj$time)))

ili_plot <- ggplot() +
    geom_line(aes(x = as.Date(time), y = weighted_ili),
        data = ili_national) +
    geom_vline(aes(xintercept = as.numeric(as.Date(time))),
        colour = "grey",
        data = ili_national[is.na(ili_national$weighted_ili), ]) +
    geom_vline(aes(xintercept = as.numeric(as.Date(ili_train_cutoff_time))),
        colour = "red", linetype = 2) +
    scale_x_date() +
#    scale_x_date(limits = time_limits, expand = c(0, 0)) +
    xlab("Time") +
    ylab("Weighted Influenza-like Illness\n") +
    ggtitle("(a) Flu Data - National United States") +
    theme_bw(base_size = 11)

dengue_plot <- ggplot() +
    geom_line(aes(x = as.Date(time), y = total_cases),
        data = dengue_sj) +
    geom_vline(aes(xintercept = as.numeric(as.Date(dengue_train_cutoff_time))),
        colour = "red", linetype = 2) +
    scale_x_date() +
#    scale_x_date(limits = time_limits, expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 500), expand = c(0, 0)) +
    xlab("Time") +
    ylab("Total Cases") +
    ggtitle("(b) Dengue Fever Data - San Juan, Puerto Rico") +
    theme_bw(base_size = 11)

grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 1)))
print(ili_plot, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(dengue_plot, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
@
\end{figure}

There are three prediction targets for each data set, based closely
on the prediction targets that were used in those competitions.  First, for each week
in the test data, we obtain a predictive distribution for the incidence measure
in that week at each prediction horizon from 1 to 52 weeks ahead.  Second, in
each season of the test data set, we make predictions for the timing of the peak
week.  Third, we predict the incidence measure in the peak week.  In all cases,
we compare the models using log score.

We use a seasonal ARIMA model as a baseline to compare our approach to.  In
fitting this model, we first transformed the observed incidence measure to the
log scale (after adding $1$ in the Dengue data set, which included some
observations of $0$ cases); this transformation makes the normality assumptions
of the ARIMA model more plausible.  We then performed first-order seasonal
differencing, and obtained the final model fits
using the {\tt auto.arima} function in {\tt R}'s {\tt forecast}
package\cite{hyndmanRForecastPackage}; this function uses a stepwise
procedure to determine the terms to include in the model.
This procedure resulted in a 
<<ILISarimaModelFitSummary, echo = FALSE, results = "asis">>=
ili_sarima_fit <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/estimation-results/sarima-fit.rds")
temp <- capture.output(summary(ili_sarima_fit))
cat(paste0("SARIMA(", substr(temp[2], 7, 15), as.integer(substr(temp[2], 16,16)) + 1, substr(temp[2], 17, 18), ")$_{52}$"))
@
model for the influenza data and a 
<<DengueSarimaModelFitSummary, echo = FALSE, results = "asis">>=
dengue_sarima_fit <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/dengue_sj/estimation-results/sarima-fit.rds")
temp <- capture.output(summary(dengue_sarima_fit))
cat(paste0("SARIMA(", substr(temp[2], 7, 15), as.integer(substr(temp[2], 16, 16)) + 1, substr(temp[2], 17, 18), ")$_{52}$"))
@
model for the Dengue data.  We note that a different SARIMA model was
used as a baseline in the Dengue competition, but the SARIMA model we obtained
using this procedure performed slightly better on the test set than that
previous baseline model.

Discuss variations on KCDE models.

\subsection{Example 1: Influenza}

%In our first example, we apply the method for prediction of
%influenza with prediction horizons of 1 through 4 weeks.  Data on influenza
%incidence are available through {\tt R}'s {\tt cdcfluview} package.  Here we
%create a data set with a nationally aggregated measure of flu incidence
%
%
%There are several methods that we could employ to handle these missing data:
%\begin{enumerate}
%\item Impute the missing values.  They are all in the low season, so this should be relatively easy to do.
%\item Drop all data up through the last NA.
%\item Use the data that are available.
%\end{enumerate}
%Of these approaches, the first is probably preferred.  The concern with the second
%is that we are not making use of all of the available data.  The potential concern with the
%third is that in the data used in estimation, there will be more examples of prediction of values in the high season
%using values in the high season and middle of the season than of prediction of values in the high season using values in the low season.
%This could potentially affect our inference.  However, we do not expect this effect to be large,
%so we proceed with this option for the purposes of this example.

%We also plot histograms of the observed total cases on the original scale and on the log scale.
%
%<<FluDataHistogramPlotTotalCases, echo = FALSE>>=
%hist_df <- rbind(
%	data.frame(value = ili_national$weighted_ili,
%    	variable = "Weighted ILI"),
%    data.frame(value = log(ili_national$weighted_ili),
%    	variable = "log(Weighted ILI)")
%)
%
%ggplot(aes(x = value), data = hist_df) +
%    geom_histogram() +
%    facet_wrap( ~ variable, ncol = 2) +
%    xlab("Weighted ILI") +
%    theme_bw()
%@
%
%These plots demonstrate that total cases follows an approximately log-normal
%distribution.  In the application below, we will consider modeling these data on
%both the original scale and the log scale.  Intuitively, since we are using a
%kernel that is obtained from a Gaussian, modeling the data on the log scale
%should yield better performance.  On the other hand, the performance gain may be
%negligible if we have enough data.

%Finally, we plot the autocorrelation function:
%
%<<FluDataACFPlotTotalCases, echo = FALSE>>=
%last_na_ind <- max(which(is.na(ili_national$weighted_ili)))
%non_na_inds <- seq(from = last_na_ind + 1, to=nrow(ili_national))
%acf(ili_national$weighted_ili[non_na_inds],
%  lag.max = 52 * 4)
%@
%
%This plot illustrates the annual periodicity that was also visible in the
%initial data plot above.  There is no apparent evidence of longer term annual
%cycles.  We therefore include a periodic kernel acting on the time index with a
%period of 52.2 weeks (the length of the period is motivated by the fact that
%in our data, there is a year with 53 weeks once every 5 or 6 years).


%<<FluDataKernelComponentsSetup, echo = TRUE>>=
%## Definitions of kernel components.  A couple of notes:
%##   1) In the current implementation, it is required that separate kernel
%##      components be used for lagged (predictive) variables and for leading
%##      (prediction target) variables.
%##   2) The current syntax is verbose; in a future version of the package,
%##      convenience functions may be provided.
%
%## Define kernel components -- 3 pieces:
%##   1) Periodic kernel acting on time index
%##   2) pdtmvn kernel acting on lagged total cases (predictive) -- all continuous
%##   3) pdtmvn kernel acting on lead total cases (prediction target) -- all continuous
%kernel_components <- list(
%    list(
%        vars_and_offsets = data.frame(var_name = "time_index",
%            offset_value = 0L,
%            offset_type = "lag",
%            combined_name = "time_index_lag0",
%            stringsAsFactors = FALSE),
%        kernel_fn = periodic_kernel,
%        theta_fixed = list(period=pi / 52.2),
%        theta_est = list("bw"),
%        initialize_kernel_params_fn = initialize_params_periodic_kernel,
%        initialize_kernel_params_args = NULL,
%        vectorize_kernel_params_fn = vectorize_params_periodic_kernel,
%        vectorize_kernel_params_args = NULL,
%        update_theta_from_vectorized_theta_est_fn = update_theta_from_vectorized_theta_est_periodic_kernel,
%        update_theta_from_vectorized_theta_est_args = NULL
%    ),
%    list(
%        vars_and_offsets = data.frame(var_name = "weighted_ili",
%            offset_value = 1L,
%            offset_type = "horizon",
%            combined_name = "time_index_horizon1",
%            stringsAsFactors = FALSE),
%        kernel_fn = pdtmvn_kernel,
%        rkernel_fn = rpdtmvn_kernel,
%        theta_fixed = list(
%            parameterization = "bw-diagonalized-est-eigenvalues",
%            continuous_vars = "weighted_ili_horizon1",
%            discrete_vars = NULL,
%            discrete_var_range_fns = NULL,
%            lower = -Inf,
%            upper = Inf
%        ),
%        theta_est = list("bw"),
%        initialize_kernel_params_fn = initialize_params_pdtmvn_kernel,
%        initialize_kernel_params_args = NULL,
%        vectorize_kernel_params_fn = vectorize_params_pdtmvn_kernel,
%        vectorize_kernel_params_args = NULL,
%        update_theta_from_vectorized_theta_est_fn = update_theta_from_vectorized_theta_est_pdtmvn_kernel,
%        update_theta_from_vectorized_theta_est_args = NULL
%    ))#,
%    list(
%        vars_and_lags = vars_and_lags[3:5, ],
%        kernel_fn = pdtmvn_kernel,
%        rkernel_fn = rpdtmvn_kernel,
%        theta_fixed = NULL,
%        theta_est = list("bw"),
%        initialize_kernel_params_fn = initialize_params_pdtmvn_kernel,
%        initialize_kernel_params_args = list(
%            continuous_vars = vars_and_lags$combined_name[3:4],
%            discrete_vars = vars_and_lags$combined_name[5],
%            discrete_var_range_fns = list(
%                c_lag2 = list(a = pdtmvn::floor_x_minus_1, b = floor, in_range = pdtmvn::equals_integer, discretizer = round_up_.5))
%        ),
%        vectorize_theta_est_fn = vectorize_params_pdtmvn_kernel,
%        vectorize_theta_est_args = NULL,
%        update_theta_from_vectorized_theta_est_fn = update_theta_from_vectorized_theta_est_pdtmvn_kernel,
%        update_theta_from_vectorized_theta_est_args = list(
%            parameterization = "bw-diagonalized-est-eigenvalues"
%        )
%    ))
%@

<<FluDataMergePredictionResults, echo = FALSE>>=
ili_prediction_results_sarima <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/prediction-results/sarima-predictions.rds")
ili_prediction_results_kcde <- readRDS("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/prediction-results/kcde-predictions.rds")
ili_prediction_results_kcde$model <- "KCDE"
ili_prediction_results <- rbind.fill(ili_prediction_results_sarima[!is.na(ili_prediction_results_sarima$log_score), ],
    ili_prediction_results_kcde)
ili_prediction_results$AE <- unlist(ili_prediction_results$AE)

ili_prediction_results$full_model_descriptor <- paste0(ili_prediction_results$model,
    "-seasonal_lag_", ili_prediction_results$max_seasonal_lag,
#    "-filtering_", ili_prediction_results$filtering,
    "-differencing_", ili_prediction_results$differencing,
    "-periodic_", ili_prediction_results$seasonality,
    "-bw_", ili_prediction_results$bw_parameterization)

ili_prediction_log_score_diffs_from_sarima_wide <- ili_prediction_results %>%
    select(full_model_descriptor, prediction_time, prediction_horizon, log_score) %>%
    spread(full_model_descriptor, log_score)

ili_prediction_log_score_diffs_from_sarima_wide[, unique(ili_prediction_results$full_model_descriptor)] <-
    ili_prediction_log_score_diffs_from_sarima_wide[, unique(ili_prediction_results$full_model_descriptor)] -
    ili_prediction_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]

ili_prediction_log_score_diffs_from_sarima_long <- ili_prediction_log_score_diffs_from_sarima_wide %>%
    gather_("model", "log_score_difference", unique(ili_prediction_results$full_model_descriptor)) %>%
    mutate(
        seasonal_lag = grepl("seasonal_lag_1", model),
        differencing = grepl("differencing_TRUE", model),
        periodic = grepl("periodic_TRUE", model),
        bw_full = grepl("bw_full", model)
    )
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_prediction_log_score_diffs_from_sarima_long$periodic & !ili_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic Kernel"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    !ili_prediction_log_score_diffs_from_sarima_long$periodic & ili_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Full Bandwidth"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_prediction_log_score_diffs_from_sarima_long$periodic & ili_prediction_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic Kernel,\nFull Bandwidth"
ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
    factor(ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor,
        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))
@

\begin{figure}
\caption{Differences in log scores for the weekly predictive distributions among
pairs of models across all combinations of prediction horizon and prediction time in the test period.
In panel (a) positive values indicate cases when KCDE outperformed SARIMA.  In panel
(b) positive values indicate cases when the specification of KCDE with the
periodic kernel outperformed the corresponding specification without the periodic kernel.
In panel (c) positive values indicate cases when the specification of KCDE with
a fully parameterized bandwidth outperformed the KCDE specification with a diagonal
bandwidth matrix.}
\label{fig:IntialDataPlots}
<<FluDataResultsAggregatedBoxplots, echo = FALSE>>=
models_used <- unique(ili_prediction_results$full_model_descriptor[
    !ili_prediction_results$differencing & !(ili_prediction_results$max_seasonal_lag == 1)])

boxplot_sarima_contrasts <- ggplot() +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor),
        data = ili_prediction_log_score_diffs_from_sarima_long[ili_prediction_log_score_diffs_from_sarima_long$model %in% models_used, ]) +
    ylim(c(-4, 4)) +
    ggtitle("(a) Comparison of KCDE with SARIMA") +
#    xlab("Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score KCDE -\nLog Score SARIMA") +
    theme_bw(base_size = 11)# +
#    theme(axis.text.x=element_text(angle = -90, hjust = 0))



ili_contrast_periodic_kernel <- ili_prediction_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("prediction_time", "prediction_horizon", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
    spread_("periodic",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
ili_contrast_periodic_kernel$fixed_values <- "Null Model"
ili_contrast_periodic_kernel$fixed_values[ili_contrast_periodic_kernel$bw_full] <-
    "Full Bandwidth"
ili_contrast_periodic_kernel$fixed_values <-
    factor(ili_contrast_periodic_kernel$fixed_values,
        levels = c("Null Model", "Full Bandwidth"))

boxplot_periodic_kernel_contrasts <- ggplot(ili_contrast_periodic_kernel) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    ggtitle("(b) Effect of Adding Periodic Kernel to Model") +
#    xlab("Base Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
    theme_bw(base_size = 11)



ili_contrast_bw_full <- ili_prediction_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("prediction_time", "prediction_horizon", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
    spread_("bw_full",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
ili_contrast_bw_full$fixed_values <- "Null Model"
ili_contrast_bw_full$fixed_values[ili_contrast_bw_full$periodic] <-
    "Periodic Kernel"
ili_contrast_bw_full$fixed_values <-
    factor(ili_contrast_bw_full$fixed_values,
        levels = c("Null Model", "Periodic Kernel"))

boxplot_bw_full_contrasts <- ggplot(ili_contrast_bw_full) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    ggtitle("(c) Effect of Adding Fully Parameterized BW to Model") +
#    xlab("Base Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
    theme_bw(base_size = 11)


grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 3, ncol = 1)))
print(boxplot_sarima_contrasts, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(boxplot_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
print(boxplot_bw_full_contrasts, vp = viewport(layout.pos.row = 3, layout.pos.col = 1))


#ili_prediction_log_score_diffs_from_sarima_long$fixed_values <-
#    as.character(ili_prediction_log_score_diffs_from_sarima_long$reduced_model_descriptor)
#ili_prediction_log_score_diffs_from_sarima_long$contrast_value <-
#    ili_prediction_log_score_diffs_from_sarima_long$log_score_difference
#ili_prediction_log_score_diffs_from_sarima_long$contrast_type <- "Difference from SARIMA"
#ili_contrast_periodic_kernel$contrast_type <- "Effect of Adding Periodic Kernel"
#ili_contrast_bw_full$contrast_type <- "Effect of Adding Full Bandwidth"
#
#ili_contrasts_merged <- rbind.fill(
#    ili_prediction_log_score_diffs_from_sarima_long[ili_prediction_log_score_diffs_from_sarima_long$model %in% models_used, ],
#    ili_contrast_periodic_kernel,
#    ili_contrast_bw_full)
#
#ggplot(ili_contrasts_merged) +
#    geom_hline(yintercept = 0) +
#    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value)) +
#    facet_wrap( ~ contrast_type, ncol = 1) +
##    ggtitle("Effect of Adding Fully Parameterized BW to Model") +
#    xlab("") +
#    ylab("Log Score Difference") +
#    theme_bw()
@
\end{figure}

\begin{figure}
\caption{Plots of point and interval predictions from SARIMA and KCDE.}
\label{fig:FluRibbonsPredictions}
<<FluDataRibbonsPredictionPlot95Intervals, echo = FALSE>>=
ribbons_df <- ili_prediction_results %>%
    select(prediction_time,
        prediction_horizon,
        full_model_descriptor,
        model,
        interval_pred_lb_95:interval_pred_ub_50) %>%
    gather("bound_type", "predictive_value", interval_pred_lb_95:interval_pred_ub_50) %>%
    mutate(interval_type = ifelse(grepl("50", bound_type), "50", "95"),
        bound_type = ifelse(grepl("lb", bound_type), "lower", "upper")) %>%
    spread(bound_type, predictive_value)

phs_used <- c(1, 6, 13, 26)
models_used <- c("SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")

ggplot() +
    geom_ribbon(aes(x = prediction_time, ymin = lower, ymax = upper, colour = model, fill = model),
        alpha = 0.4,
        size = 0,
        data = ribbons_df[ribbons_df$prediction_horizon %in% phs_used &
                ribbons_df$full_model_descriptor %in% models_used &
                ribbons_df$interval_type == "95", ]) +
    geom_line(aes(x = time, y = weighted_ili), data = ili_national[ili_national$year %in% 2010:2014, ]) +
#    geom_point(aes(x = time, y = weighted_ili), data = ili_national[ili_national$year %in% 2010:2014, ]) +
    geom_line(aes(x = prediction_time, y = pt_pred, colour = model, linetype = model),
        size = 1,
        data = ili_prediction_results[ili_prediction_results$prediction_horizon %in% phs_used &
                ili_prediction_results$full_model_descriptor %in% models_used, ]) +
#    scale_alpha_discrete("Prediction\nInterval\nCoverage",
#        labels = c("50 Percent", "95 Percent"),
#        limits = c("50", "95"),
#        range = c(0.4, 0.2)) +
#    scale_fill_manual("Model", values = c("#0072B2", "#E69F00")) +
#    scale_colour_manual("Model", values = c("#0072B2", "#E69F00")) +
    scale_fill_manual("Model", values = c("#E69F00", "#0072B2")) +
    scale_colour_manual("Model", values = c("#E69F00", "#0072B2")) +
    scale_linetype("Model") +
    facet_wrap( ~ prediction_horizon, ncol = 1) +
    xlab("Prediction Time") +
    ylab("Weighted Influenza-like Illness") +
#    ggtitle("Point and 95% Interval Predictions") +
    theme_bw()
@
\end{figure}



<<FluDataMergePeakWeekPredictionResults, echo = FALSE>>=
data_set <- "ili_national"

prediction_save_path <- file.path("/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results",
    data_set,
    "prediction-results")

all_max_lags <- as.character(c(1L))
all_max_seasonal_lags <- as.character(c(0L, 1L))
all_filtering_values <- c("FALSE")
all_differencing_values <- c("FALSE", "TRUE")
all_seasonality_values <- c("FALSE", "TRUE")
all_bw_parameterizations <- c("diagonal", "full")

case_definitions <- expand.grid(
        data_set,
        all_max_lags,
        all_max_seasonal_lags,
        all_filtering_values,
        all_differencing_values,
        all_seasonality_values,
        all_bw_parameterizations,
        stringsAsFactors = FALSE) %>%
    `colnames<-`(c("data_set",
            "max_lag",
            "max_seasonal_lag",
            "filtering",
            "differencing",
            "seasonality",
            "bw_parameterization"))

ili_peak_week_results <- rbind.fill(
    c(
        list(
            readRDS(file.path(prediction_save_path,
                        paste0("peak-week-sarima-", data_set, ".rds"))) %>%
                mutate(model = "SARIMA")
        ),
        lapply(seq_len(nrow(case_definitions)), function(case_row_ind) {
                max_lag <- case_definitions$max_lag[case_row_ind]
                max_seasonal_lag <- case_definitions$max_seasonal_lag[case_row_ind]
                filtering <- case_definitions$filtering[case_row_ind]
                differencing <- case_definitions$differencing[case_row_ind]
                seasonality <- case_definitions$seasonality[case_row_ind]
                bw_parameterization <- case_definitions$bw_parameterization[case_row_ind]
                
                case_descriptor <- paste0(
                    data_set,
                    "-max_lag_", max_lag,
                    "-max_seasonal_lag_", max_seasonal_lag,
                    "-filtering_", filtering,
                    "-differencing_", differencing,
                    "-seasonality_", seasonality,
                    "-bw_parameterization_", bw_parameterization
                )
                
                readRDS(file.path(prediction_save_path,
                            paste0("peak-week-", case_descriptor, ".rds"))) %>%
                    mutate(model = "KCDE",
                        max_lag = max_lag,
                        max_seasonal_lag = max_seasonal_lag,
                        filtering = filtering,
                        differencing = differencing,
                        seasonality = seasonality,
                        bw_parameterization = bw_parameterization)
            })
    )
)

ili_peak_week_results$full_model_descriptor <- paste0(ili_peak_week_results$model,
    "-seasonal_lag_", ili_peak_week_results$max_seasonal_lag,
#    "-filtering_", ili_prediction_results$filtering,
    "-differencing_", ili_peak_week_results$differencing,
    "-periodic_", ili_peak_week_results$seasonality,
    "-bw_", ili_peak_week_results$bw_parameterization)

ili_peak_week_results$peak_week_log_score[ili_peak_week_results$peak_week_log_score < -50] <- -50
ili_peak_week_results$peak_height_log_score[ili_peak_week_results$peak_height_log_score < -50] <- -50
@


\begin{figure}
\caption{Differences in log scores for the predictive distributions for the peak
week and incidence at the peak week among pairs of models across all analysis
times in the test period.
In panel (a) positive values indicate cases when KCDE outperformed SARIMA.  In panel
(b) positive values indicate cases when the specification of KCDE with the
periodic kernel outperformed the corresponding specification without the periodic kernel.
In panel (c) positive values indicate cases when the specification of KCDE with
a fully parameterized bandwidth outperformed the KCDE specification with a diagonal
bandwidth matrix.  In the plot for peak week timing in panel (a), the log score
differences are not displayed for one analysis time when none of the simulated
trajectories from SARIMA peaked at the true peak week.  In that case, our
monte carlo estimate of the difference in log scores is infinity.}
\label{fig:FluPeakWeekPredictions}
<<FluDataPeakWeekPredictionBoxPlots, echo = FALSE>>=
peak_week_times <- data.frame(
    analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
    peak_week = sapply(unique(ili_peak_week_results$analysis_time_season),
        function(season_val) {
            max_incidence_in_season <-
                max(ili_national$weighted_ili[ili_national$season == season_val])
            return(ili_national$season_week[ili_national$season == season_val &
                        ili_national$weighted_ili == max_incidence_in_season])
        })
)

## Contrasts with SARIMA for peak week timing
ili_peak_timing_log_score_diffs_from_sarima_wide <- ili_peak_week_results %>%
    select(full_model_descriptor, analysis_time_season, analysis_time_season_week, peak_week_log_score) %>%
    spread(full_model_descriptor, peak_week_log_score)

ili_peak_timing_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] <-
    ili_peak_timing_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] -
    ili_peak_timing_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]

ili_peak_timing_log_score_diffs_from_sarima_long <- ili_peak_timing_log_score_diffs_from_sarima_wide %>%
    gather_("model", "log_score_difference", unique(ili_peak_week_results$full_model_descriptor)) %>%
    mutate(
        seasonal_lag = as.logical(grepl("seasonal_lag_1", model)),
        differencing = as.logical(grepl("differencing_TRUE", model)),
        periodic = as.logical(grepl("periodic_TRUE", model)),
        bw_full = as.logical(grepl("bw_full", model))
    )
ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_peak_timing_log_score_diffs_from_sarima_long$periodic & !ili_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic Kernel"
ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    !ili_peak_timing_log_score_diffs_from_sarima_long$periodic & ili_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
    "Full Bandwidth"
ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_peak_timing_log_score_diffs_from_sarima_long$periodic & ili_peak_timing_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic Kernel,\nFull Bandwidth"
ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
    factor(ili_peak_timing_log_score_diffs_from_sarima_long$reduced_model_descriptor,
        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))

ili_peak_timing_log_score_diffs_from_sarima_long$leq_peak_week <-
    ili_peak_timing_log_score_diffs_from_sarima_long$analysis_time_season_week <=
    peak_week_times$peak_week[
        sapply(ili_peak_timing_log_score_diffs_from_sarima_long$analysis_time_season,
            function(season_val) which(peak_week_times$analysis_time_season == season_val))]

models_used <- unique(ili_peak_week_results$full_model_descriptor[
        !as.logical(ili_peak_week_results$differencing) & !(ili_peak_week_results$max_seasonal_lag == 1)])

boxplot_timing_sarima_contrasts <- ggplot() +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = leq_peak_week),
        data = ili_peak_timing_log_score_diffs_from_sarima_long[
            ili_peak_timing_log_score_diffs_from_sarima_long$model %in% models_used & 
                ili_peak_timing_log_score_diffs_from_sarima_long$log_score_difference < 40, ]) +
#    ylim(c(-4, 4)) +
    ggtitle("Peak Week Timing") +
#    xlab("Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score KCDE -\nLog Score SARIMA") +
    theme_bw(base_size = 11)# +



## Contrasts with SARIMA for peak week height
ili_peak_height_log_score_diffs_from_sarima_wide <- ili_peak_week_results %>%
    select(full_model_descriptor, analysis_time_season, analysis_time_season_week, peak_height_log_score) %>%
    spread(full_model_descriptor, peak_height_log_score)

ili_peak_height_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] <-
    ili_peak_height_log_score_diffs_from_sarima_wide[, unique(ili_peak_week_results$full_model_descriptor)] -
    ili_peak_height_log_score_diffs_from_sarima_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]

ili_peak_height_log_score_diffs_from_sarima_long <- ili_peak_height_log_score_diffs_from_sarima_wide %>%
    gather_("model", "log_score_difference", unique(ili_peak_week_results$full_model_descriptor)) %>%
    mutate(
        seasonal_lag = as.logical(grepl("seasonal_lag_1", model)),
        differencing = as.logical(grepl("differencing_TRUE", model)),
        periodic = as.logical(grepl("periodic_TRUE", model)),
        bw_full = as.logical(grepl("bw_full", model))
    )
ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor <- "Null Model"
ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_peak_height_log_score_diffs_from_sarima_long$periodic & !ili_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic Kernel"
ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    !ili_peak_height_log_score_diffs_from_sarima_long$periodic & ili_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
    "Full Bandwidth"
ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor[
    ili_peak_height_log_score_diffs_from_sarima_long$periodic & ili_peak_height_log_score_diffs_from_sarima_long$bw_full] <-
    "Periodic Kernel,\nFull Bandwidth"
ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor <-
    factor(ili_peak_height_log_score_diffs_from_sarima_long$reduced_model_descriptor,
        levels = c("Null Model", "Full Bandwidth", "Periodic Kernel", "Periodic Kernel,\nFull Bandwidth"))

ili_peak_height_log_score_diffs_from_sarima_long$leq_peak_week <-
    ili_peak_height_log_score_diffs_from_sarima_long$analysis_time_season_week <=
    peak_week_times$peak_week[
        sapply(ili_peak_height_log_score_diffs_from_sarima_long$analysis_time_season,
            function(season_val) which(peak_week_times$analysis_time_season == season_val))]

models_used <- unique(ili_peak_week_results$full_model_descriptor[
        !as.logical(ili_peak_week_results$differencing) & !(ili_peak_week_results$max_seasonal_lag == 1)])

boxplot_height_sarima_contrasts <- ggplot() +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(y = log_score_difference, x = reduced_model_descriptor, colour = leq_peak_week),
        data = ili_peak_height_log_score_diffs_from_sarima_long[ili_peak_height_log_score_diffs_from_sarima_long$model %in% models_used, ]) +
#    ylim(c(-4, 4)) +
    ggtitle("Peak Week Incidence") +
#    xlab("Model") +
    xlab("") +
    ylab("") +
#    ylab("Log Score KCDE -\nLog Score SARIMA") +
    theme_bw(base_size = 11)# +



ili_timing_contrast_periodic_kernel <- ili_peak_timing_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
    spread_("periodic",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
ili_timing_contrast_periodic_kernel$fixed_values <- "Null Model"
ili_timing_contrast_periodic_kernel$fixed_values[ili_timing_contrast_periodic_kernel$bw_full] <-
    "Full Bandwidth"
ili_timing_contrast_periodic_kernel$fixed_values <-
    factor(ili_timing_contrast_periodic_kernel$fixed_values,
        levels = c("Null Model", "Full Bandwidth"))

ili_timing_contrast_periodic_kernel$leq_peak_week <-
    ili_timing_contrast_periodic_kernel$analysis_time_season_week <=
    peak_week_times$peak_week[
        sapply(ili_timing_contrast_periodic_kernel$analysis_time_season,
            function(season_val) which(peak_week_times$analysis_time_season == season_val))]


ili_height_contrast_periodic_kernel <- ili_peak_height_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
    spread_("periodic",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
ili_height_contrast_periodic_kernel$fixed_values <- "Null Model"
ili_height_contrast_periodic_kernel$fixed_values[ili_height_contrast_periodic_kernel$bw_full] <-
    "Full Bandwidth"
ili_height_contrast_periodic_kernel$fixed_values <-
    factor(ili_height_contrast_periodic_kernel$fixed_values,
        levels = c("Null Model", "Full Bandwidth"))

ili_height_contrast_periodic_kernel$leq_peak_week <-
    ili_height_contrast_periodic_kernel$analysis_time_season_week <=
    peak_week_times$peak_week[
        sapply(ili_height_contrast_periodic_kernel$analysis_time_season,
            function(season_val) which(peak_week_times$analysis_time_season == season_val))]


boxplot_timing_periodic_kernel_contrasts <- ggplot(ili_timing_contrast_periodic_kernel) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    ggtitle("Peak Week Timing") +
#    xlab("Base Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
    theme_bw(base_size = 11)


boxplot_height_periodic_kernel_contrasts <- ggplot(ili_height_contrast_periodic_kernel) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    ggtitle("Peak Week Incidence") +
#    xlab("Base Model") +
    xlab("") +
    ylab("") +
#    ylab("Log Score Model With Periodic Kernel -\nLog Score Model Without Periodic Kernel") +
    theme_bw(base_size = 11)


ili_timing_contrast_bw_full <- ili_peak_timing_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
    spread_("bw_full",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
ili_timing_contrast_bw_full$fixed_values <- "Null Model"
ili_timing_contrast_bw_full$fixed_values[ili_timing_contrast_bw_full$periodic] <-
    "Periodic Kernel"
ili_timing_contrast_bw_full$fixed_values <-
    factor(ili_timing_contrast_bw_full$fixed_values,
        levels = c("Null Model", "Periodic Kernel"))

ili_timing_contrast_bw_full$leq_peak_week <-
    ili_timing_contrast_bw_full$analysis_time_season_week <=
    peak_week_times$peak_week[
        sapply(ili_timing_contrast_bw_full$analysis_time_season,
            function(season_val) which(peak_week_times$analysis_time_season == season_val))]


ili_height_contrast_bw_full <- ili_peak_height_log_score_diffs_from_sarima_long %>%
    filter(model %in% models_used) %>%
    select_("analysis_time_season", "analysis_time_season_week", "log_score_difference",
        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
    spread_("bw_full",
        "log_score_difference") %>%
    mutate(
        contrast_value = `TRUE` - `FALSE`)
ili_height_contrast_bw_full$fixed_values <- "Null Model"
ili_height_contrast_bw_full$fixed_values[ili_height_contrast_bw_full$periodic] <-
    "Periodic Kernel"
ili_height_contrast_bw_full$fixed_values <-
    factor(ili_height_contrast_bw_full$fixed_values,
        levels = c("Null Model", "Periodic Kernel"))

ili_height_contrast_bw_full$leq_peak_week <-
    ili_height_contrast_bw_full$analysis_time_season_week <=
    peak_week_times$peak_week[
        sapply(ili_height_contrast_bw_full$analysis_time_season,
            function(season_val) which(peak_week_times$analysis_time_season == season_val))]


boxplot_timing_bw_full_contrasts <- ggplot(ili_timing_contrast_bw_full) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    ggtitle("Peak Week Timing") +
#    xlab("Base Model") +
    xlab("") +
    ylab("Log Score Difference") +
#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
    theme_bw(base_size = 11)

boxplot_height_bw_full_contrasts <- ggplot(ili_height_contrast_bw_full) +
    geom_hline(yintercept = 0) +
    geom_boxplot(aes(x = factor(fixed_values), y = contrast_value, colour = leq_peak_week)) +
#    facet_wrap( ~ fixed_values, ncol = 1) +
    ggtitle("Peak Week Incidence") +
#    xlab("Base Model") +
    xlab("") +
    ylab("") +
#    ylab("Log Score Model With Full Bandwidth -\nLog Score Model With Diagonal Bandwidth") +
    theme_bw(base_size = 11)


grid.newpage()
pushViewport(viewport(layout =
    grid.layout(nrow = 6, ncol = 2, heights = unit(rep(1, 6), rep(c("lines", "null"), times = 3)))))
grid.text("(a) Comparison of KCDE with SARIMA",
    gp = gpar(fontsize = 12),
    vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2))
print(boxplot_timing_sarima_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))
print(boxplot_height_sarima_contrasts, vp = viewport(layout.pos.row = 2, layout.pos.col = 2))
grid.text("(b) Effect of Adding Periodic Kernel to Model",
    gp = gpar(fontsize = 12),
    vp = viewport(layout.pos.row = 3, layout.pos.col = 1:2))
print(boxplot_timing_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 4, layout.pos.col = 1))
print(boxplot_height_periodic_kernel_contrasts, vp = viewport(layout.pos.row = 4, layout.pos.col = 2))
grid.text("(c) Effect of Adding Fully Parameterized BW to Model",
    gp = gpar(fontsize = 12),
    vp = viewport(layout.pos.row = 5, layout.pos.col = 1:2))
print(boxplot_timing_bw_full_contrasts, vp = viewport(layout.pos.row = 6, layout.pos.col = 1))
print(boxplot_height_bw_full_contrasts, vp = viewport(layout.pos.row = 6, layout.pos.col = 2))
@
\end{figure}



\begin{figure}
\caption{Log scores for predictions of peak week timing by predictive
model and analysis time.}
\label{fig:FluPeakWeekTimingPredictionLogScores}
<<PeakWeekTimingLogScoreByAnalysisTime, echo = FALSE>>=
## Add season and season week columns to data so that we can get from
## analysis_time_season and analysis_time_season_week to analysis_time
#ili_national$season <- ifelse(
#    ili_national$week <= 30,
#    paste0(ili_national$year - 1, "/", ili_national$year),
#    paste0(ili_national$year, "/", ili_national$year + 1)
#)
#
## Season week column: week number within season
#ili_national$season_week <- sapply(seq_len(nrow(ili_national)), function(row_ind) {
#    sum(ili_national$season == ili_national$season[row_ind] & ili_national$time_index <= ili_national$time_index[row_ind])
#})
#
#
#ili_peak_week_results$analysis_time <- ili_peak_week_results$analysis_time_season_week

#ili_peak_week_results_for_plot

models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
    "Equal Bin Probabilities")

ili_peak_week_results$reduced_model_descriptor <- "Null KCDE Model"
ili_peak_week_results$reduced_model_descriptor[
    as.logical(ili_peak_week_results$seasonality) & !(ili_peak_week_results$bw_parameterization == "full")] <-
    "Periodic Kernel"
ili_peak_week_results$reduced_model_descriptor[
    !as.logical(ili_peak_week_results$seasonality) & (ili_peak_week_results$bw_parameterization == "full")] <-
    "Full Bandwidth"
ili_peak_week_results$reduced_model_descriptor[
    as.logical(ili_peak_week_results$seasonality) & (ili_peak_week_results$bw_parameterization == "full")] <-
    "Periodic Kernel,\nFull Bandwidth"
ili_peak_week_results$reduced_model_descriptor[
    ili_peak_week_results$model == "SARIMA"] <-
    "SARIMA"

num_analysis_time_season_values <- length(unique(ili_peak_week_results$analysis_time_season))
num_analysis_time_season_week_values <- length(unique(ili_peak_week_results$analysis_time_season_week))
ili_peak_week_results <- rbind.fill(ili_peak_week_results,
    data.frame(
        full_model_descriptor = rep("Equal Bin Probabilities", num_analysis_time_season_week_values * num_analysis_time_season_values),
        reduced_model_descriptor = rep("Equal Bin Probabilities", num_analysis_time_season_week_values * num_analysis_time_season_values),
        analysis_time_season = rep(unique(ili_peak_week_results$analysis_time_season), each = num_analysis_time_season_week_values),
        analysis_time_season_week = rep(unique(ili_peak_week_results$analysis_time_season_week), times = num_analysis_time_season_values),
        peak_week_log_score = rep(log(1/31), num_analysis_time_season_week_values * num_analysis_time_season_values)
    ))
    
    
ili_peak_week_results$reduced_model_descriptor <-
    factor(ili_peak_week_results$reduced_model_descriptor,
        levels = c("SARIMA", "Null KCDE Model", "Full Bandwidth", "Periodic Kernel",
            "Periodic Kernel,\nFull Bandwidth",
            "Equal Bin Probabilities"
        ))
    
geom_hline(yintercept = log(1/31), colour = "grey", linetype = 2)

peak_week_times <- data.frame(
    analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
    peak_week = sapply(unique(ili_peak_week_results$analysis_time_season),
        function(season_val) {
            max_incidence_in_season <-
                max(ili_national$weighted_ili[ili_national$season == season_val])
            return(ili_national$season_week[ili_national$season == season_val &
                ili_national$weighted_ili == max_incidence_in_season])
        })
)

ili_peak_week_results$peak_week_log_score[ili_peak_week_results$peak_week_log_score == -50] <- NA
p <- ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used, ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
    geom_point(aes(x = analysis_time_season_week, y = peak_week_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    geom_vline(aes(xintercept = peak_week), data = peak_week_times) +
    facet_wrap( ~ analysis_time_season, ncol = 1) +
#    geom_raster(aes(x = analysis_time_season_week, y = log_score),
#        data = ili_peak_week_results) +
    theme_bw()

suppressWarnings(print(p))
@
\end{figure}



\begin{figure}
\caption{Log scores for predictions of incidence in the peak week by predictive
model and analysis time.}
\label{fig:FluPeakWeekIncidencePredictionLogScores}
<<FluPeakWeekIncidenceLogScoreByAnalysisTime, echo = FALSE>>=
## Add season and season week columns to data so that we can get from
## analysis_time_season and analysis_time_season_week to analysis_time
#ili_national$season <- ifelse(
#    ili_national$week <= 30,
#    paste0(ili_national$year - 1, "/", ili_national$year),
#    paste0(ili_national$year, "/", ili_national$year + 1)
#)
#
## Season week column: week number within season
#ili_national$season_week <- sapply(seq_len(nrow(ili_national)), function(row_ind) {
#    sum(ili_national$season == ili_national$season[row_ind] & ili_national$time_index <= ili_national$time_index[row_ind])
#})
#
#
#ili_peak_week_results$analysis_time <- ili_peak_week_results$analysis_time_season_week

#ili_peak_week_results_for_plot
 
models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")

ili_peak_week_results$peak_height_log_score[ili_peak_week_results$peak_height_log_score == -50] <- NA
ggplot(ili_peak_week_results[ili_peak_week_results$full_model_descriptor %in% models_used, ]) +
    geom_line(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, linetype = reduced_model_descriptor)) +
    geom_point(aes(x = analysis_time_season_week, y = peak_height_log_score, colour = reduced_model_descriptor, shape = reduced_model_descriptor)) +
    geom_vline(aes(xintercept = peak_week), data = peak_week_times) +
    facet_wrap( ~ analysis_time_season, ncol = 1) +
#    geom_raster(aes(x = analysis_time_season_week, y = log_score),
#        data = ili_peak_week_results) +
    theme_bw()
@
\end{figure}


<<FluObtainPeakWeekTimingPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
ili_incidence_bins <- data.frame(
    lower = seq(from = 0, to = 13, by = 0.5),
    upper = c(seq(from = 0.5, to = 13, by = 0.5), Inf))

for(bin_num in seq(from = 10, to = 40)) {
    ili_peak_week_results[, paste0("est_prob_bin_", bin_num)] <-
        apply(ili_peak_week_results[, paste0("peak_week_", seq_len(10000))],
            1,
            function(x) {sum(x == bin_num) / length(x)})
}

peak_timing_pred_dist_by_analysis_time <- ili_peak_week_results %>%
    select(full_model_descriptor,
            analysis_time_season,
            analysis_time_season_week,
            starts_with("est_prob_bin_")) %>%
    gather_("bin", "est_prob", paste0("est_prob_bin_", seq(from = 10, to = 40)))
peak_timing_pred_dist_by_analysis_time$bin <-
    as.integer(substr(peak_timing_pred_dist_by_analysis_time$bin, 14, 15))


#peak_timing_pred_dist_by_analysis_time <- ili_peak_week_results %>%
#    mutate(count_)
#    select_(c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week"))
#
#
#
#peak_timing_pred_dist_by_analysis_time <-
#    as.data.frame(expand.grid(
#            model = c(
#                "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
#                "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"),
#            analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
#            analysis_time_season_week = seq(from = 10, to = 40),
#            bin_number = seq(from = 10, to = 40),
##        incidence_bin = seq_len(nrow(ili_incidence_bins)),
#            stringsAsFactors = FALSE
#        ))
#peak_timing_pred_dist_by_analysis_time$est_bin_prob <- sapply(
#    seq_len(nrow(peak_timing_pred_dist_by_analysis_time)),
#    function(row_ind) {
#        sum(ili_peak_week_results[
#                    ili_peak_week_results$full_model_descriptor == peak_timing_pred_dist_by_analysis_time$model[row_ind] &
#                        ili_peak_week_results$analysis_time_season == peak_timing_pred_dist_by_analysis_time$analysis_time_season[row_ind] &
#                        ili_peak_week_results$analysis_time_season_week == peak_timing_pred_dist_by_analysis_time$analysis_time_season_week[row_ind],
#                    paste0("peak_week_", seq_len(10000))] ==
#                peak_timing_pred_dist_by_analysis_time$bin_number[row_ind]) / 10000
#    })
#
#
#
@

\begin{figure}
\caption{Predictive distributions for predictions of peak week timing.}
\label{fig:FluPeakWeekTimingPredictiveDistributions}
<<FluPlotPeakWeekTimingPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")

ggplot() +
    geom_raster(aes(x = analysis_time_season_week, y = bin, fill = est_prob),
        data = peak_timing_pred_dist_by_analysis_time[peak_timing_pred_dist_by_analysis_time$full_model_descriptor %in% models_used, ]) +
    scale_fill_gradientn(colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
        values = c(0, exp(seq(from = log(10^-4), to = log(1), length = 15)))) +
    facet_grid(analysis_time_season ~ full_model_descriptor) +
    theme_bw()
@
\end{figure}




<<FluObtainPeakWeekHeightPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
ili_incidence_bins <- data.frame(
    lower = seq(from = 0, to = 13, by = 0.5),
    upper = c(seq(from = 0.5, to = 13, by = 0.5), Inf))

for(bin_num in seq_len(nrow(ili_incidence_bins))) {
    ili_peak_week_results[, paste0("est_prob_bin_", bin_num)] <-
        apply(ili_peak_week_results[, paste0("peak_height_", seq_len(10000))],
            1,
            function(x) {sum(x == bin_num) / length(x)})
}

peak_height_pred_dist_by_analysis_time <- ili_peak_week_results %>%
    select(full_model_descriptor,
            analysis_time_season,
            analysis_time_season_week,
            starts_with("est_prob_bin_")) %>%
    gather_("bin", "est_prob", paste0("est_prob_bin_", seq_len(nrow(ili_incidence_bins))))
peak_height_pred_dist_by_analysis_time$bin <-
    as.integer(substr(peak_height_pred_dist_by_analysis_time$bin, 14, 15))


#peak_timing_pred_dist_by_analysis_time <- ili_peak_week_results %>%
#    mutate(count_)
#    select_(c("full_model_descriptor", "analysis_time_season", "analysis_time_season_week"))
#
#
#
#peak_timing_pred_dist_by_analysis_time <-
#    as.data.frame(expand.grid(
#            model = c(
#                "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
#                "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full"),
#            analysis_time_season = unique(ili_peak_week_results$analysis_time_season),
#            analysis_time_season_week = seq(from = 10, to = 40),
#            bin_number = seq(from = 10, to = 40),
##        incidence_bin = seq_len(nrow(ili_incidence_bins)),
#            stringsAsFactors = FALSE
#        ))
#peak_timing_pred_dist_by_analysis_time$est_bin_prob <- sapply(
#    seq_len(nrow(peak_timing_pred_dist_by_analysis_time)),
#    function(row_ind) {
#        sum(ili_peak_week_results[
#                    ili_peak_week_results$full_model_descriptor == peak_timing_pred_dist_by_analysis_time$model[row_ind] &
#                        ili_peak_week_results$analysis_time_season == peak_timing_pred_dist_by_analysis_time$analysis_time_season[row_ind] &
#                        ili_peak_week_results$analysis_time_season_week == peak_timing_pred_dist_by_analysis_time$analysis_time_season_week[row_ind],
#                    paste0("peak_week_", seq_len(10000))] ==
#                peak_timing_pred_dist_by_analysis_time$bin_number[row_ind]) / 10000
#    })
#
#
#
@

\begin{figure}
\caption{Predictive distributions for predictions of peak week timing.}
\label{fig:FluPeakWeekHeightPredictiveDistributions}
<<FluPlotPeakWeekHeightPredictiveDistributionsByAnalysisTime, echo = FALSE>>=
models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_FALSE-bw_full",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
models_used <- c(
    "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA",
    "KCDE-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")

ggplot() +
    geom_raster(aes(x = analysis_time_season_week, y = bin, fill = est_prob),
        data = peak_height_pred_dist_by_analysis_time[peak_height_pred_dist_by_analysis_time$full_model_descriptor %in% models_used, ]) +
    scale_fill_gradientn(colours = rev(c("#000000", "#111111", "#222222", "#333333", "#444444", "#555555", "#666666", "#777777", "#888888", "#999999", "#AAAAAA", "#BBBBBB", "#CCCCCC", "#DDDDDD", "#EEEEEE", "#FFFFFF")),
        values = c(0, exp(seq(from = log(10^-4), to = log(1), length = 15)))) +
    facet_grid(analysis_time_season ~ full_model_descriptor) +
    ylab("Peak incidence bin") +
    theme_bw()
@
\end{figure}














%<<FluDataRibbonsPredictionPlot95Intervals, echo = FALSE>>=
%ggplot() +
%    geom_ribbon(aes(x = prediction_time, ymin = lower, ymax = upper, colour = model, fill = model),
%        alpha = 0.4,
%        size = 0,
%        data = ribbons_df[ribbons_df$prediction_horizon %in% phs_used &
%                ribbons_df$full_model_descriptor %in% models_used &
%                ribbons_df$interval_type == "95", ]) +
%    geom_line(aes(x = time, y = weighted_ili), data = ili_national[ili_national$year %in% 2010:2014, ]) +
%#    geom_point(aes(x = time, y = weighted_ili), data = ili_national[ili_national$year %in% 2010:2014, ]) +
%    geom_line(aes(x = prediction_time, y = pt_pred, colour = model),
%        data = ili_prediction_results[ili_prediction_results$prediction_horizon %in% phs_used &
%                ili_prediction_results$full_model_descriptor %in% models_used, ]) +
%#    scale_alpha_discrete("Prediction\nInterval\nCoverage",
%#        labels = c("50 Percent", "95 Percent"),
%#        limits = c("50", "95"),
%#        range = c(0.4, 0.2)) +
%    facet_wrap( ~ prediction_horizon, ncol = 1) +
%    ggtitle("Point and 95% Interval Predictions") +
%    theme_bw()
%@


%<<FluDataPredictionsPlotViolinLogScore>>=
%library(ggplot2)
%
%ggplot() +
%    geom_violin(aes(x = factor(full_model_descriptor), y = log_score), data =
%     ili_prediction_results) + theme_bw()
%@

%<<FluDataPredictionsPlotViolinLogScoreDifference, fig.height = 8, echo = FALSE>>=
%ili_prediction_log_score_diffs_wide <- ili_prediction_results %>%
%    select(full_model_descriptor, prediction_time, prediction_horizon, log_score) %>%
%    spread(full_model_descriptor, log_score)
%
%ili_prediction_log_score_diffs_wide[, unique(ili_prediction_results$full_model_descriptor)] <-
%    ili_prediction_log_score_diffs_wide[, unique(ili_prediction_results$full_model_descriptor)] -
%    ili_prediction_log_score_diffs_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]
%#    ili_prediction_log_score_diffs_wide[, "SARIMA-seasonal_lag_NA-filtering_NA-differencing_NA-periodic_NA-bw_NA"]
%
%ili_prediction_log_score_diffs_long <- ili_prediction_log_score_diffs_wide %>%
%    gather_("model", "log_score_difference", unique(ili_prediction_results$full_model_descriptor))
%
%ggplot() +
%    geom_violin(aes(x = factor(model), y = log_score_difference), data = ili_prediction_log_score_diffs_long) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -90, hjust = 0))
%@
%
%
%<<FluDataPredictionsPlotViolinLogScoreDifferenceZoomedIn, fig.height = 8, echo = FALSE>>=
%ggplot() +
%    geom_violin(aes(x = factor(model), y = log_score_difference), data = ili_prediction_log_score_diffs_long) +
%    theme_bw() +
%    ylim(c(-6, 6)) +
%    theme(axis.text.x=element_text(angle = -90, hjust = 0))
%@
%
%<<FluDataPredictionsPlotBoxplotLogScoreDifferenceZoomedIn, fig.height = 8, echo = FALSE>>=
%ggplot() +
%    geom_boxplot(aes(x = factor(model), y = log_score_difference), data = ili_prediction_log_score_diffs_long) +
%    theme_bw() +
%    ylim(c(-6, 6)) +
%    theme(axis.text.x=element_text(angle = -90, hjust = 0))
%@
%
%
%<<FluDataPredictionsPlotStripLogScoreDifference, fig.height = 9, echo = FALSE>>=
%ggplot() +
%    geom_point(aes(x = factor(model), y = log_score_difference), size = 0.1, position = position_jitter(w = 0.2, h = 0), alpha = 0.01, data = ili_prediction_log_score_diffs_long) +
%    theme_bw() +
%    ylim(c(-6, 6)) +
%    theme(axis.text.x=element_text(angle = -90, hjust = 0))
%@
%
%
%<<FluDataPredictionsPlotViolinLogScoreDifferencePeakSeasonOnly, echo = FALSE>>=
%peak_season_test_inds_in_ili_national <- c(
%    693:704, # 2010/2011 season, starting Jan 2011
%    744:755, # 2011/2012 season
%    791:808, # 2012/2013 season
%    844:857, # 2013/2014 season
%    895:901  # 2014/2015 season, ending end of Dec 2014
%)
%peak_season_test_times <- ili_national$time[peak_season_test_inds_in_ili_national]
%
%
%
%ili_prediction_log_score_diffs_wide <- ili_prediction_results %>%
%    select(full_model_descriptor, prediction_time, prediction_horizon, log_score) %>%
%    spread(full_model_descriptor, log_score)
%
%ili_prediction_log_score_diffs_wide[, unique(ili_prediction_results$full_model_descriptor)] <-
%    ili_prediction_log_score_diffs_wide[, unique(ili_prediction_results$full_model_descriptor)] -
%    ili_prediction_log_score_diffs_wide[, "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA"]
%#    ili_prediction_log_score_diffs_wide[, "SARIMA-seasonal_lag_NA-filtering_NA-differencing_NA-periodic_NA-bw_NA"]
%
%ili_prediction_log_score_diffs_long <- ili_prediction_log_score_diffs_wide %>%
%    gather_("model", "log_score_difference", unique(ili_prediction_results$full_model_descriptor))
%
%ggplot() +
%    geom_violin(aes(x = factor(model), y = log_score_difference),
%        data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$prediction_time %in% peak_season_test_times, ]) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%
%<<FluDataPredictionsPlotViolinLogScoreDifferenceOnlyModelsWithoutFiltering, echo = FALSE>>=
%models_used <- c("kcde-filtering_FALSE-periodic_FALSE-bw_diagonal",
%    "kcde-filtering_FALSE-periodic_FALSE-bw_full",
%    "kcde-filtering_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-filtering_FALSE-periodic_TRUE-bw_full")
%
%central_stat_log_score_diff_by_model <- ili_prediction_log_score_diffs_long %>%
%    group_by(model) %>%
%    summarize(median = median(log_score_difference),
%        mean = mean(log_score_difference)) %>%
%    gather_("statistic", "value", c("median", "mean"))
%
%ggplot() +
%    geom_violin(aes(x = factor(model), y = log_score_difference),
%        data = ili_prediction_log_score_diffs[ili_prediction_log_score_diffs$model %in% models_used, ]) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    geom_point(aes(x = factor(model), y = value, colour = statistic),
%        data = central_stat_log_score_diff_by_model[central_stat_log_score_diff_by_model$model %in% models_used, ]) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@


%<<FluDataPredictionsPlotViolinLogScoreDifferenceByHorizon, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-FALSE-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%
%
%median_log_score_diff_by_model_and_horizon <- ili_prediction_log_score_diffs_long %>%
%    group_by(model, prediction_horizon) %>%
%    summarize(median = median(log_score_difference))
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_violin(aes(x = factor(prediction_horizon), y = log_score_difference)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    geom_point(aes(x = factor(prediction_horizon), y = median), colour = "blue", data = median_log_score_diff_by_model_and_horizon[median_log_score_diff_by_model_and_horizon$model %in% models_used, ]) +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@


%<<FluDataPredictionsPlotLineLogScoreDifferenceByPredictionTimeAndHorizon, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-FALSE-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%
%phs_used <- c(1, 6, 13, 26, 39, 52)
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used & ili_prediction_log_score_diffs_long$prediction_horizon %in% phs_used, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_point(aes(x = prediction_time, y = log_score_difference, colour = factor(prediction_horizon), shape = factor(prediction_horizon))) +
%    geom_line(aes(x = prediction_time, y = log_score_difference, colour = factor(prediction_horizon))) +
%    geom_hline(aes(yintercept = 0), colour = "black") +
%#    geom_point(aes(x = factor(prediction_horizon), y = median), colour = "blue", data = median_log_score_diff_by_model_and_horizon[median_log_score_diff_by_model_and_horizon$model %in% models_used, ]) +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw()# +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%<<FluDataPredictionsPlotBoxplotLogScoreDifferenceByHorizonOnlyModelsWithDifferencing, fig.height = 9, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-FALSE-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_TRUE-periodic_FALSE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_TRUE-periodic_FALSE-bw_full",
%    "kcde-seasonal_lag_0-differencing_TRUE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_1-differencing_TRUE-periodic_FALSE-bw_diagonal",
%    "kcde-seasonal_lag_1-differencing_TRUE-periodic_TRUE-bw_diagonal")
%
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = log_score_difference)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%%<<FluDataPredictionsPlotBoxplotScoreRatioByHorizonOnlyModelsWithDifferencing, fig.height = 9, echo = FALSE>>=
%%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%%#    facet_wrap( ~ model, ncol = 1) +
%%#    theme_bw() +
%%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%%
%%models_used <- c("kcde-seasonal_lag_1-FALSE-differencing_FALSE-periodic_TRUE-bw_full")
%%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%%models_used <- c("kcde-seasonal_lag_0-differencing_TRUE-periodic_FALSE-bw_full")
%%models_used <- c("kcde-seasonal_lag_0-differencing_TRUE-periodic_FALSE-bw_full",
%%    "kcde-seasonal_lag_0-differencing_TRUE-periodic_TRUE-bw_full",
%%    "kcde-seasonal_lag_1-differencing_TRUE-periodic_FALSE-bw_diagonal",
%%    "kcde-seasonal_lag_1-differencing_TRUE-periodic_TRUE-bw_diagonal")
%%
%%
%%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]) +
%%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%%    geom_boxplot(aes(x = factor(prediction_horizon), y = log_score_difference)) +
%%    geom_hline(aes(yintercept = 0), colour = "red") +
%%    facet_wrap( ~ model, ncol = 1) +
%%    theme_bw() +
%%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%%@
%
%
%<<FluDataPredictionsPlotBoxplotLogScoreDifferenceByHorizonOnlyModelsWithoutDifferencing, fig.height = 9, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-FALSE-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_TRUE-periodic_FALSE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_full")
%
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = log_score_difference)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%
%<<FluDataPredictionsPlotBoxplotScoreRatioByHorizonOnlyModelsWithoutDifferencing, fig.height = 9, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-FALSE-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_TRUE-periodic_FALSE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_FALSE-bw_full",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_full")
%
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = exp(log_score_difference))) +
%    geom_hline(aes(yintercept = 1), colour = "red") +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%<<FluDataPredictionsPlotViolinLogScoreDifferenceByHorizonPeakSeasonOnly, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
%
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
%
%median_log_score_diff_by_model_and_horizon <- ili_prediction_log_score_diffs_long %>%
%    group_by(model, prediction_horizon) %>%
%    summarize(median = median(log_score_difference))
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used & ili_prediction_log_score_diffs_long$prediction_time %in% peak_season_test_times, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_violin(aes(x = factor(prediction_horizon), y = log_score_difference)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    geom_point(aes(x = factor(prediction_horizon), y = median), colour = "blue", data = median_log_score_diff_by_model_and_horizon[median_log_score_diff_by_model_and_horizon$model %in% models_used, ]) +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%<<FluDataPredictionsPlotStripLogScoreDifferenceByHorizonPeakSeasonOnly, echo = FALSE>>=
%#ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% unique(ili_prediction_results$full_model_descriptor)[2:5], ]) +
%##    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%#    geom_point(aes(x = prediction_horizon, y = log_score_difference)) +
%#    facet_wrap( ~ model, ncol = 1) +
%#    theme_bw() +
%#    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full")
%models_used <- c("kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
%
%models_used <- c("kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_1-differencing_FALSE-periodic_TRUE-bw_diagonal",
%    "kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_full",
%    "kcde-seasonal_lag_0-differencing_FALSE-periodic_TRUE-bw_diagonal")
%
%median_log_score_diff_by_model_and_horizon <- ili_prediction_log_score_diffs_long %>%
%    group_by(model, prediction_horizon) %>%
%    summarize(median = median(log_score_difference))
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used & ili_prediction_log_score_diffs_long$prediction_time %in% peak_season_test_times, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%    geom_point(aes(x = factor(prediction_horizon), y = log_score_difference),
%        position = position_jitter(width = 0.1, height = 0)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    geom_point(aes(x = factor(prediction_horizon), y = median), colour = "blue", data = median_log_score_diff_by_model_and_horizon[median_log_score_diff_by_model_and_horizon$model %in% models_used, ]) +
%    facet_wrap( ~ model, ncol = 1) +
%    theme_bw() +
%    theme(axis.text.x=element_text(angle = -60, hjust = 0))
%@
%
%
%<<FluDataResultsPredictionHorizonSplinesPlot, fig.height = 9, echo = FALSE>>=
%library(splines)
%
%prediction_horizon_spline_basis_for_plot <- bs(1:52, df = 26, intercept = TRUE)
%prediction_horizon_spline_basis_plot_df <- prediction_horizon_spline_basis_for_plot %>%
%    as.data.frame() %>%
%    mutate(prediction_horizon = 1:52) %>%
%    gather_("spline", "value", as.character(1:26))
%
%ggplot(prediction_horizon_spline_basis_plot_df) +
%    geom_line(aes(x = prediction_horizon, y = value, colour = spline)) +
%    theme_bw()
%@


%<<FluDataResultsModelIndepBoxplot1, fig.height = 9, echo = FALSE>>=
%ili_prediction_log_score_diffs_long <- ili_prediction_log_score_diffs_long %>%
%    filter(model != "SARIMA-seasonal_lag_NA-differencing_NA-periodic_NA-bw_NA")
%
%ili_prediction_log_score_diffs_long$model_indicator <- as.integer(as.factor(ili_prediction_log_score_diffs_long$model))
%
%ili_results_fit_samples <- readRDS(
%    file = "/media/evan/data/Reich/infectious-disease-prediction-with-kcde/inst/results/ili_national/analysis-results/influenza-results-model-samples-spline-indep-fit-chains_2-iter_1000.rds")
%
%N <- nrow(ili_prediction_log_score_diffs_long) 
%M <- 16
%B_spline <- 26
%B <- B_spline + 1
%
%
%## Make boxplot by prediction horizon for one model with corresponding spline fits superimposed
%plots <- lapply(seq_len(16), function(models_used_inds) {
%#models_used_inds <- 1L
%        models_used_inds_in_log_score_diffs_long <- which(ili_prediction_log_score_diffs_long$model_indicator %in% models_used_inds)
%        models_used <- unique(ili_prediction_log_score_diffs_long$model[models_used_inds_in_log_score_diffs_long])
%        
%        
%        beta_inds <- seq_len(B) + (models_used_inds - 1) * B
%        spline_fits <-
%            data.frame(
%                prediction_horizon = seq_len(52),
%                spline_fit = cbind(
%                    matrix(1, nrow = 52),
%                    bs(seq_len(52),
%                        df = B_spline,
%                        intercept = TRUE)
%                ) %*% t(as.matrix(ili_results_fit_samples[, paste0("beta[", beta_inds, "]")]))
%            ) %>%
%            gather_("spline_fit", "fit_val", paste0("spline_fit.", seq_len(1000)))
%        
%        p <- ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]) +
%#    geom_violin(aes(x = prediction_horizon, y = log_score_difference)) +
%            geom_boxplot(aes(x = factor(prediction_horizon), y = log_score_difference)) +
%            geom_line(aes(x = factor(prediction_horizon), y = fit_val, group = spline_fit), alpha = 0.01, data = spline_fits) +
%            geom_hline(aes(yintercept = 0), colour = "red") +
%            facet_wrap( ~ model, ncol = 1) +
%            theme_bw() +
%            theme(axis.text.x=element_text(angle = -60, hjust = 0))
%        return(p)
%    })
%
%print(plots[[1]])
%@
%
%<<FluDataResultsModelIndepBoxplot2, fig.height = 9, echo = FALSE>>=
%print(plots[[2]])
%@
%
%<<FluDataResultsModelIndepBoxplot3, fig.height = 9, echo = FALSE>>=
%print(plots[[3]])
%@
%
%<<FluDataResultsModelIndepBoxplot4, fig.height = 9, echo = FALSE>>=
%print(plots[[4]])
%@
%
%<<FluDataResultsModelIndepBoxplot5, fig.height = 9, echo = FALSE>>=
%print(plots[[5]])
%@
%
%<<FluDataResultsModelIndepBoxplot6, fig.height = 9, echo = FALSE>>=
%print(plots[[6]])
%@
%
%<<FluDataResultsModelIndepBoxplot7, fig.height = 9, echo = FALSE>>=
%print(plots[[7]])
%@
%
%<<FluDataResultsModelIndepBoxplot8, fig.height = 9, echo = FALSE>>=
%print(plots[[8]])
%@
%
%<<FluDataResultsModelIndepBoxplot9, fig.height = 9, echo = FALSE>>=
%print(plots[[9]])
%@
%
%<<FluDataResultsModelIndepBoxplot10, fig.height = 9, echo = FALSE>>=
%print(plots[[10]])
%@
%
%<<FluDataResultsModelIndepBoxplot11, fig.height = 9, echo = FALSE>>=
%print(plots[[11]])
%@
%
%<<FluDataResultsModelIndepBoxplot12, fig.height = 9, echo = FALSE>>=
%print(plots[[12]])
%@
%
%<<FluDataResultsModelIndepBoxplot13, fig.height = 9, echo = FALSE>>=
%print(plots[[13]])
%@
%
%<<FluDataResultsModelIndepBoxplot14, fig.height = 9, echo = FALSE>>=
%print(plots[[14]])
%@
%
%<<FluDataResultsModelIndepBoxplot15, fig.height = 9, echo = FALSE>>=
%print(plots[[15]])
%@
%
%<<FluDataResultsModelIndepBoxplot16, fig.height = 9, echo = FALSE>>=
%print(plots[[16]])
%@
%
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime1, echo = FALSE>>=
%## Get median within model and prediction horizon
%ili_prediction_median_log_score_diffs_by_model_and_ph <-
%    ili_prediction_log_score_diffs_long %>%
%    group_by(model, prediction_horizon) %>%
%    summarize(median_by_model_and_ph = median(log_score_difference))
%
%ili_prediction_log_score_diffs_long <- 
%    ili_prediction_log_score_diffs_long %>%
%    left_join(ili_prediction_median_log_score_diffs_by_model_and_ph,
%        by = c("model", "prediction_horizon")) %>%
%    mutate(log_score_difference_residual_from_median = log_score_difference - median_by_model_and_ph)
%
%#temp <- ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model == unique(ili_prediction_log_score_diffs_long$model)[4], ]
%#temp <- temp[order(temp$prediction_horizon), ]
%
%## For each model, ...
%plots <- lapply(seq_len(16), function(models_used_inds) {
%        ## 
%        models_used_inds_in_log_score_diffs_long <- which(ili_prediction_log_score_diffs_long$model_indicator %in% models_used_inds)
%        models_used <- unique(ili_prediction_log_score_diffs_long$model[models_used_inds_in_log_score_diffs_long])
%        
%        reduced_ili_prediction_log_score_diffs_long <-
%            ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]
%        ## For each time point, get acf wrt prediction horizon
%        
%        time_names <- paste0("time_",
%            seq_along(unique(reduced_ili_prediction_log_score_diffs_long$prediction_time))
%        )
%        plot_data <- sapply(
%            unique(reduced_ili_prediction_log_score_diffs_long$prediction_time),
%            function(prediction_time) {
%                temp <- reduced_ili_prediction_log_score_diffs_long[
%                    reduced_ili_prediction_log_score_diffs_long$prediction_time == prediction_time, ]
%                temp <- temp[order(temp$prediction_horizon), ]
%                acf(temp$log_score_difference_residual_from_median, plot = FALSE)$acf
%            }) %>%
%            as.data.frame() %>%
%            `colnames<-`(time_names) %>%
%            mutate(lag_in_horizon_time_fixed = seq(from = 0, to = 17)) %>%
%            gather_("time", "residual_acf", time_names)
%        
%        acf_null_limits <- qnorm((1 + 0.95)/2)/sqrt(52)
%        
%        p <- ggplot(plot_data) +
%            geom_point(aes(x = lag_in_horizon_time_fixed, y = residual_acf), colour = "grey") +
%            geom_line(aes(x = lag_in_horizon_time_fixed, y = residual_acf, group = time), colour = "grey") +
%            geom_hline(yintercept = 0) +
%            geom_hline(yintercept = acf_null_limits, colour = "blue", linetype = 2) +
%            geom_hline(yintercept = -acf_null_limits, colour = "blue", linetype = 2) +
%            ggtitle(paste0(models_used, "\nPrediction Time Fixed")) +
%            theme_bw()
%        
%        
%        return(p)
%    })
%
%print(plots[[1]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime2, fig.height = 9, echo = FALSE>>=
%print(plots[[2]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime3, fig.height = 9, echo = FALSE>>=
%print(plots[[3]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime4, fig.height = 9, echo = FALSE>>=
%print(plots[[4]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime5, fig.height = 9, echo = FALSE>>=
%print(plots[[5]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime6, fig.height = 9, echo = FALSE>>=
%print(plots[[6]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime7, fig.height = 9, echo = FALSE>>=
%print(plots[[7]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime8, fig.height = 9, echo = FALSE>>=
%print(plots[[8]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime9, fig.height = 9, echo = FALSE>>=
%print(plots[[9]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime10, fig.height = 9, echo = FALSE>>=
%print(plots[[10]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime11, fig.height = 9, echo = FALSE>>=
%print(plots[[11]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime12, fig.height = 9, echo = FALSE>>=
%print(plots[[12]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime13, fig.height = 9, echo = FALSE>>=
%print(plots[[13]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime14, fig.height = 9, echo = FALSE>>=
%print(plots[[14]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime15, fig.height = 9, echo = FALSE>>=
%print(plots[[15]])
%@
%
%<<FluDataResultsResidualsACFByPHWithinModelAndTime16, fig.height = 9, echo = FALSE>>=
%print(plots[[16]])
%@
%
%
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH1, echo = FALSE>>=
%## Get median within model and prediction horizon
%
%#temp <- ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model == unique(ili_prediction_log_score_diffs_long$model)[4], ]
%#temp <- temp[order(temp$prediction_horizon), ]
%
%## For each model, ...
%plots <- lapply(seq_len(16), function(models_used_inds) {
%        ## 
%        models_used_inds_in_log_score_diffs_long <- which(ili_prediction_log_score_diffs_long$model_indicator %in% models_used_inds)
%        models_used <- unique(ili_prediction_log_score_diffs_long$model[models_used_inds_in_log_score_diffs_long])
%        
%        reduced_ili_prediction_log_score_diffs_long <-
%            ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used, ]
%        ## For each time point, get acf wrt prediction horizon
%        
%        ph_names <- paste0("ph_", seq_len(52))
%        plot_data <- sapply(
%            seq_len(52),
%            function(prediction_horizon) {
%                temp <- reduced_ili_prediction_log_score_diffs_long[
%                    reduced_ili_prediction_log_score_diffs_long$prediction_horizon == prediction_horizon, ]
%                temp <- temp[order(temp$prediction_time), ]
%                acf(temp$log_score_difference_residual_from_median, plot = FALSE)$acf
%            }) %>%
%            as.data.frame() %>%
%            `colnames<-`(ph_names)
%        plot_data$lag_in_time_horizon_fixed <- seq(from = 0, to = nrow(plot_data) - 1)
%        plot_data <- gather_(plot_data, "prediction_horizon", "residual_acf", time_names)
%        
%        acf_null_limits <- qnorm((1 + 0.95)/2)/sqrt(length(unique(reduced_ili_prediction_log_score_diffs_long$prediction_time)))
%        
%        p <- ggplot(plot_data) +
%            geom_point(aes(x = lag_in_time_horizon_fixed, y = residual_acf), colour = "grey") +
%            geom_line(aes(x = lag_in_time_horizon_fixed, y = residual_acf, group = prediction_horizon), colour = "grey") +
%            geom_hline(yintercept = 0) +
%            geom_hline(yintercept = acf_null_limits, colour = "blue", linetype = 2) +
%            geom_hline(yintercept = -acf_null_limits, colour = "blue", linetype = 2) +
%            ggtitle(paste0(models_used, "\nPrediction Horizon Fixed")) +
%            theme_bw()
%        
%        
%        return(p)
%    })
%
%print(plots[[1]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH2, fig.height = 9, echo = FALSE>>=
%print(plots[[2]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH3, fig.height = 9, echo = FALSE>>=
%print(plots[[3]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH4, fig.height = 9, echo = FALSE>>=
%print(plots[[4]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH5, fig.height = 9, echo = FALSE>>=
%print(plots[[5]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH6, fig.height = 9, echo = FALSE>>=
%print(plots[[6]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH7, fig.height = 9, echo = FALSE>>=
%print(plots[[7]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH8, fig.height = 9, echo = FALSE>>=
%print(plots[[8]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH9, fig.height = 9, echo = FALSE>>=
%print(plots[[9]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH10, fig.height = 9, echo = FALSE>>=
%print(plots[[10]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH11, fig.height = 9, echo = FALSE>>=
%print(plots[[11]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH12, fig.height = 9, echo = FALSE>>=
%print(plots[[12]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH13, fig.height = 9, echo = FALSE>>=
%print(plots[[13]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH14, fig.height = 9, echo = FALSE>>=
%print(plots[[14]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH15, fig.height = 9, echo = FALSE>>=
%print(plots[[15]])
%@
%
%<<FluDataResultsResidualsACFByTimeWithinModelAndPH16, fig.height = 9, echo = FALSE>>=
%print(plots[[16]])
%@

%<<FluDataResultsEmpiricalContrastsSeasonalLag, fig.height = 9, echo = FALSE>>=
%ili_contrast_seasonal_lag <- ili_prediction_log_score_diffs_from_sarima_long %>%
%    select_("prediction_time", "prediction_horizon", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("seasonal_lag",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`,
%        fixed_values = paste0("differencing_", differencing, "-periodic_", periodic, "-bw_full_", bw_full))
%
%ggplot(ili_contrast_seasonal_lag) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = contrast_value)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Seasonal Lag to Model") +
%    theme_bw()
%@




%<<FluDataResultsEmpiricalContrastsMedianSeasonalLag, fig.height = 9, echo =
% FALSE>>=
%ili_contrast_seasonal_lag_medians <- ili_contrast_seasonal_lag %>%
%    group_by(prediction_horizon, fixed_values) %>%
%    summarize(median_contrast = median(contrast_value))
%
%ggplot(ili_contrast_seasonal_lag_medians) +
%    geom_point(aes(x = factor(prediction_horizon), y = median_contrast)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Seasonal Lag to Model") +
%    theme_bw()
%@
%
%
%<<FluDataResultsEmpiricalContrastsDifferencing, fig.height = 9, echo = FALSE>>=
%ili_contrast_differencing <- ili_prediction_log_score_diffs_long %>%
%    select_("prediction_time", "prediction_horizon", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("differencing",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`,
%        fixed_values = paste0("seasonal_lag_", seasonal_lag, "-periodic_", periodic, "-bw_full_", bw_full))
%
%ggplot(ili_contrast_differencing) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = contrast_value)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Seasonal Differencing to Model") +
%    theme_bw()
%@
%
%<<FluDataResultsEmpiricalContrastsMedianDifferencing, fig.height = 9, echo = FALSE>>=
%ili_contrast_differencing_medians <- ili_contrast_differencing %>%
%    group_by(prediction_horizon, fixed_values) %>%
%    summarize(median_contrast = median(contrast_value))
%
%ggplot(ili_contrast_differencing_medians) +
%    geom_point(aes(x = factor(prediction_horizon), y = median_contrast)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Seasonal Differencing to Model") +
%    theme_bw()
%@
%
%<<FluDataResultsEmpiricalContrastsPeriodic, fig.height = 9, echo = FALSE>>=
%ili_contrast_periodic <- ili_prediction_log_score_diffs_long %>%
%    select_("prediction_time", "prediction_horizon", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("periodic",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`,
%        fixed_values = paste0("seasonal_lag_", seasonal_lag, "-differencing_", differencing, "-bw_full_", bw_full))
%
%ggplot(ili_contrast_periodic) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = contrast_value)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Periodic Kernel to Model") +
%    theme_bw()
%@
%
%<<FluDataResultsEmpiricalContrastsMedianPeriodic, fig.height = 9, echo = FALSE>>=
%ili_contrast_periodic_medians <- ili_contrast_periodic %>%
%    group_by(prediction_horizon, fixed_values) %>%
%    summarize(median_contrast = median(contrast_value))
%
%ggplot(ili_contrast_periodic_medians) +
%    geom_point(aes(x = factor(prediction_horizon), y = median_contrast)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Periodic Kernel to Model") +
%    theme_bw()
%@
%
%<<FluDataResultsEmpiricalContrastsBWFull, fig.height = 9, echo = FALSE>>=
%ili_contrast_bw_full <- ili_prediction_log_score_diffs_long %>%
%    select_("prediction_time", "prediction_horizon", "log_score_difference",
%        "seasonal_lag", "differencing", "periodic", "bw_full") %>%
%    spread_("bw_full",
%        "log_score_difference") %>%
%    mutate(
%        contrast_value = `TRUE` - `FALSE`,
%        fixed_values = paste0("seasonal_lag_", seasonal_lag, "-differencing_", differencing, "-periodic_", periodic))
%
%ggplot(ili_contrast_bw_full) +
%    geom_boxplot(aes(x = factor(prediction_horizon), y = contrast_value)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Full BW Parameterization to Model") +
%    theme_bw()
%@
%
%<<FluDataResultsEmpiricalContrastsMedianBWFull, fig.height = 9, echo = FALSE>>=
%ili_contrast_bw_full_medians <- ili_contrast_bw_full %>%
%    group_by(prediction_horizon, fixed_values) %>%
%    summarize(median_contrast = median(contrast_value))
%
%ggplot(ili_contrast_bw_full_medians) +
%    geom_point(aes(x = factor(prediction_horizon), y = median_contrast)) +
%    geom_hline(yintercept = 0, colour = "red") +
%    facet_wrap( ~ fixed_values, ncol = 1) +
%    ggtitle("Effect of Adding Full BW Parameterization to Model") +
%    theme_bw()
%@


%<<FluDataResultsGAMM>>=
%## Outcome is y_{t, h, s, d, p, b}, where
%## t = week for which y_{t, h, s, d, p, b} is a prediction.
%##     Predictions are made each week for the 4 years in the test set.
%## h = prediction horizon.  The prediction is made from h weeks before t.
%##     For each target week, we make predictions for every horizon between 1 and 52 weeks.
%## s = seasonal lag included in model.  Either 0 or 1.
%## d = differencing used?  True/False
%## p = periodic kernel used?  True/False
%## b = bandwidth parameterization:  Diagonal or Full
%## 
%## Mean structure:
%##     E(y_{t, h, s, d, p, b}) = mu_{s, d, p, b} + spline(h)_{s, d, p, b}
%##     The spline term is in the prediction horizon, with a separate spline
%##     fit for each combination of s, d, p, and b
%## 
%## Covariance structure:
%##     We want autocorrelation in t.
%##     We may want correlation in nearby h?
%##     We want different variances for different s, d, p, b.
%## y_{t, h, s, d, p, b} = E(y_{t, h, s, d, p, b}) + alpha_ + epsilon_{t, h, s, d, p, b}
%## 
%##     Var(y_{t, h, s, d, p, b}) = blah
%##     Cov(y_{t, h, s, d, p, b}, y_{t, h, s, d, p, b}) = blah
%flu_data_results_gamm_fit <- gamm4(
%#    formula = log_score_difference ~ model + s(prediction_horizon, model, bs = "fs"), # the s term gives a separate smooth for each level of model
%    formula = log_score_difference ~ model + s(prediction_horizon, by = model), # the s term gives a separate smooth for each level of model
%    random = ,
%    data = ili_prediction_log_score_diffs_long
%)
%
%plot(flu_data_results_gamm_fit$gam,pages=1)
%summary(flu_data_results_gamm_fit$gam)
%@


%<<FluDataLogScoreDiffVsTimePlot, echo = FALSE>>=
%phs_used <- c(1, 6, 13, 26, 52)
%models_used <- c("kcde-filtering_FALSE-periodic_TRUE-bw_full")
%
%ggplot(data = ili_prediction_log_score_diffs_long[ili_prediction_log_score_diffs_long$model %in% models_used &
%                ili_prediction_log_score_diffs_long$prediction_horizon %in% phs_used, ]) +
%    geom_line(aes(x = prediction_time, y = log_score_difference)) +
%    geom_point(aes(x = prediction_time, y = log_score_difference)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    facet_wrap( ~ prediction_horizon, ncol = 1) +
%    ylim(c(-4, 4)) +
%    theme_bw()
%    
%@
%
%<<FluDataLogScoreDiffVsObsIncidencePlot, echo = FALSE>>=
%ili_prediction_log_score_diffs_long_with_obs_incidence <- ili_prediction_log_score_diffs_long %>%
%    left_join(ili_national, by = c("prediction_time" = "time"))
%
%ggplot(data = ili_prediction_log_score_diffs_long_with_obs_incidence[
%            ili_prediction_log_score_diffs_long_with_obs_incidence$model %in% models_used &
%                ili_prediction_log_score_diffs_long_with_obs_incidence$prediction_horizon %in% phs_used, ]) +
%    geom_line(aes(x = weighted_ili, y = log_score_difference)) +
%    geom_point(aes(x = weighted_ili, y = log_score_difference)) +
%    geom_hline(aes(yintercept = 0), colour = "red") +
%    facet_wrap( ~ prediction_horizon, ncol = 1) +
%    ylim(c(-4, 4)) +
%    theme_bw()
%@



%<<ACFBySeasonInfluenza>>=
%pit_inc_traj_acf_by_season <- rbind.fill(lapply(
%        seq_len(11),
%        function(season_row_ind) {
%            temp <- acf(pit_incidence_trajectories[season_row_ind, ], plot = FALSE)
%            return(data.frame(
%                    season = rownames(pit_incidence_trajectories)[season_row_ind],
%                    acf = temp$acf,
%                    lag = temp$lag
%                ))
%        }
%    ))
%
%acf_null_limits <- qnorm((1 + 0.95)/2)/sqrt(max_prediction_horizon)
%
%ggplot(pit_inc_traj_acf_by_season) +
%    geom_point(aes(x = lag, y = acf), colour = "grey") +
%    geom_line(aes(x = lag, y = acf, group = season), colour = "grey") +
%    geom_hline(yintercept = 0) +
%    geom_hline(yintercept = acf_null_limits, colour = "blue", linetype = 2) +
%    geom_hline(yintercept = -acf_null_limits, colour = "blue", linetype = 2) +
%    theme_bw()
%@
%
%
%<<ACFBySeasonVsFromCopulaSimInfluenza>>=
%pit_inc_traj_acf_by_season <- rbind.fill(lapply(
%        seq_len(11),
%        function(season_row_ind) {
%            temp <- acf(pit_incidence_trajectories[season_row_ind, ], plot = FALSE)
%            return(data.frame(
%                    season = rownames(pit_incidence_trajectories)[season_row_ind],
%                    acf = temp$acf,
%                    lag = temp$lag,
%                    type = "observed",
%                    stringsAsFactors = FALSE
%                ))
%        }
%    ))
%
%acf_null_limits <- qnorm((1 + 0.95)/2)/sqrt(max_prediction_horizon)
%
%
%ggplot(pit_inc_traj_acf_by_season) +
%    geom_point(aes(x = lag, y = acf), colour = "grey") +
%    geom_line(aes(x = lag, y = acf, group = season), colour = "grey") +
%    geom_hline(yintercept = 0) +
%    geom_hline(yintercept = acf_null_limits, colour = "blue", linetype = 2) +
%    geom_hline(yintercept = -acf_null_limits, colour = "blue", linetype = 2) +
%    theme_bw()
%
%n_sim <- 11L
%
%clayton_copula_fit <- fitCopula(
%    copula = claytonCopula(dim = max_prediction_horizon),
%    data = pit_incidence_trajectories,
%    method = "ml")
%frank_copula_fit <- fitCopula(
%    copula = frankCopula(dim = max_prediction_horizon),
%    data = pit_incidence_trajectories,
%    method = "ml")
%t_copula_fit <- fitCopula(
%    copula = tCopula(dim = max_prediction_horizon, df.fixed = TRUE),
%    data = pit_incidence_trajectories,
%    method = "ml")
%ar1_normal_copula_fit <- fitCopula(
%    copula = normalCopula(dim = max_prediction_horizon, dispstr = "ar1"),
%    data = pit_incidence_trajectories,
%    method = "ml")
%toep_normal_copula_fit <- fitCopula(
%    copula = normalCopula(dim = max_prediction_horizon, dispstr = "toep"),
%    data = pit_incidence_trajectories,
%    method = "ml")
%
%sim_pit_seq_acf <- rbind.fill(lapply(
%    c(frank_copula_fit, clayton_copula_fit, t_copula_fit, toep_normal_copula_fit),
%    function(copula_fit) {
%        rbind.fill(lapply(
%            seq_len(n_sim),
%            function(sim_ind) {
%                predictive_copula <- copula_fit@copula
%                ## Note that the variance estimate for parameters is low; at least we're accounting for some uncertainty though...
%                orig_params <- predictive_copula@parameters
%                predictive_copula@parameters <- rmvnorm(1, copula_fit@estimate, sigma = copula_fit@var.est)[1, ]
%                random_params <- predictive_copula@parameters
%                if(identical(class(predictive_copula)[1], "normalCopula")) {
%                    ## randomly generated parameters above may not yield a positive definite correlation matrix; correct
%                    while(min(eigen(getSigma(predictive_copula))$values) < 0.00001) {
%                        predictive_copula@parameters <- copula:::makePosDef(getSigma(predictive_copula))[1, 1 + seq_along(predictive_copula@parameters)]
%                    }
%                }
%                
%                sim_sequence <- rCopula(1, predictive_copula)[1, ]
%                
%                temp <- acf(sim_sequence, plot = FALSE)
%                return(data.frame(
%                    sim_ind = sim_ind,
%                    acf = temp$acf,
%                    lag = temp$lag,
%                    type = class(copula_fit@copula)[[1]],
%                    stringsAsFactors = FALSE
%                ))
%            }
%        ))
%    }
%))
%
%pit_inc_traj_acf_by_season$sim_ind <- pit_inc_traj_acf_by_season$season
%combined_acfs <- rbind.fill(pit_inc_traj_acf_by_season, sim_pit_seq_acf)
%
%ggplot(combined_acfs) +
%    geom_point(aes(x = lag, y = acf), colour = "grey") +
%    geom_line(aes(x = lag, y = acf, group = sim_ind), colour = "grey") +
%    geom_hline(yintercept = 0) +
%    geom_hline(yintercept = acf_null_limits, colour = "blue", linetype = 2) +
%    geom_hline(yintercept = -acf_null_limits, colour = "blue", linetype = 2) +
%    facet_wrap(~type, ncol = 1) +
%    theme_bw()
%@


\section{Future Work}


Hall, Racine, and Li\cite{hall2004crossvalidationKCDE} show that when
cross-validation is used to select the bandwidth parameters in KCDE using product kernels, the
estimated bandwidths corresponding to irrelevant conditioning variables tend to
infinity asymptotically as the sample size increases.  They discuss the fact
that similar results could be obtained for linear combinations of
continuous variables if a full bandwidth matrix were used.  Our approach for
obtaining kernels that can be used with mixed discrete and continuous variables
opens up an opportunity to extend this analysis to that case; we have not
pursued this mathematical analysis here.

The above results regarding the inclusion of irrelevant conditioning variables
hold asymptotically as the sample size increases.  However, in practice, data
set sizes are often limited.  In other modeling settings where some conditioning
variables may not be informative, shrinkage methods are often helpful.  These
methods could be incorporated into a kernel-based approach by imposing a penalty
on the elements of the bandwidth matrix; in particular, we suggest that a
penalty on the inverse of the bandwidth matrix encouraging it to have small
eigenvalues could be helpful.  Another alternative would be to pursue the
Bayesian framework, using Dirichlet process mixtures with an informative prior
on the mixture component covariance matrices.

We could also make some tweaks to our implementation of KCDE.  Locally linear --
help address edge effects.  Cite Hyndman, Bashtannyk, Grunwald - "Estimating and
Visualizing Conditional Densities", maybe also Fan and Yim - "A crossvaildation
method for estimating conditional densities" and Fan et al. 1996 "Estimation of
conditional densities and sensitivity measures in nonlinear dynamical systems."

Ensembles -- either ensembles of KCDE and/or include as a component in an
ensemble.  Also Bayesian model averaging.  Return to discussion of bias/variance
trade-off?

Other covariates

%\bibliographystyle{plainnat}
\bibliography{kde-bib}


\end{document}